---
title: "BoW3D: Bag of Words for Real-Time Loop Closing in 3D LiDAR SLAM"
date: 2022-08-15T23:46:17.000Z
author: "Yunge Cui, Xieyuanli Chen, Yinlong Zhang, Jiahua Dong, Qingxiao Wu, Feng Zhu"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2208-07473v2.webp" # image path/url
    alt: "BoW3D: Bag of Words for Real-Time Loop Closing in 3D LiDAR SLAM" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2208.07473)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2208.07473).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/bow3d-bag-of-words-for-real-time-loop-closing).

# Abstract
- Loop closing is a fundamental part of simultaneous localization and mapping
- In the field of visual SLAM, bag of words (BoW) has achieved great success in loop closure
- However, for 3D LiDAR SLAM, the state-of-the-art methods may fail to effectively
- To address this limitation, we present a novel Bag of Words for real-time
- Our method not only efficiently recognizes the revisited loop places, but also corrects the full 6-DoF loop
- BoW3D builds the bag of words based on the 3D LiDAR feature LinK3D, which is efficient, pose-invariant and can be used for accurate
- We furthermore embed our proposed method into 3D LiDAR odometry system to evaluate loop closing performance. We test our method on

# Paper Content

## I. Introduction
- The proposed method achieves significant improvements in real-time performance.

## Feature Extraction
- The workflow of our system mainly consists of three modules: (i) Feature Extraction; (ii) Odometry and Mapping of A-LOAM; (iii) Loop Closing.
- The proposed method has been embedded to the LiDAR odometry system in practice. Experimental results show that our method can significantly eliminate the drifts and improve the accuracy of 3D LiDAR SLAM.
- There are many 2D features that have been successfully used in vision tasks, such as SIFT [24], SURF [19], BRIEF [20] and ORB [25].
- Camera SLAM usually extracts 2D features, and requires to detect the loop or perform relocalization. As a consequence, bag of words is quite suitable for camera SLAM.
- Bag of words compresses the image information into a more compact form. Moreover, it builds a tree to speed up the retrieving process of words. Both of these ensure the efficiency of the algorithm in place recognition of camera SLAM.
- For methods using 3D point cloud, Steder et al. [26] propose a place recognition method operating on range images generated from 3D LiDAR data, which uses a combination of bag-of-words and NARF-feature-based [27].
- M2DP [28] projects a point cloud to multiple 2D planes and generates a density signature for points in each of the planes. The singular value decomposition (SVD) components of the signature are then used to compute a global descriptor.
- Scan contex [29] converts the point cloud scan into a visible space, and uses the similarity score to calculate the distance between two scan contexts. However, this method can only provide relative 1-DoF yaw angle estimation of loop LiDAR pair and fails to correct the full 6-DoF pose of loops.
- PointNetVLAD [30] leverages PointNet [31] and NetVLAD [15] to generate global descriptors.
- ISC [32] proposes a global descriptor based on the geometry and intensity informations, then uses a two-stage hierarchical intensity scan context to detect loops.
- LiDAR-Iris [33] generates the LiDAR-Iris image representation to detect potential loops.
- SGPR [34] uses a semantic graph representation for the point cloud scenes by reserving the semantic and topological information of the raw point cloud.
- OverlapNet [35] adopts a siamese network to estimate an overlap of range image generated from LiDAR scans, and provides a relative yaw angle estimate of matching LiDAR pair.
- SSC [36] uses global semantic scan context to detect loops.
- OverlapTransformer [37] uses a lightweight neural network expoiting the range image representation of point cloud to achieve fast retrieval.

## III. Background Review

## A. Review of LinK3D Features
- The LinK3D feature is based on the 2D image features SIFT and ORB.
- The LinK3D descriptor is represented by a 180-dimension vector.
- Each dimension of the descriptor corresponds to a sector area.
- The LinK3D feature can be used to achieve accurate point-to-point matching.

## B. Review of Bag of Words
- Bag of words (BoW) is used to recognize the revisited place by retrieving the 2D features (such as SIFT [24], ORB [25], etc.).
- In particular, the database of BoW for binary ORB feature has successfully applied to real-time place recognition task.
- BoW creates a visual vocabulary as a tree structure, in an offline step over a set of descriptors extracted from a training image dataset.
- When processing a new image, the vocabulary converts the extracted features of the image into a low-dimensional vector, containing the term frequency and inverse document frequency (tf-idf) [9] score.
- The tf-idf score is computed by: where the n wi represents the number of word w in image I i , n i represents the total number of words in I i , N is the total number of images seen so far, and n w represents the number of images containing word w.
- The idea of idf is that the less times a word appears in all images, the higher the final score will be, which indicates that the word has a higher discrimination.
- If the score of a word is high enough, the similarity between the word and the words in the database is computed.
- If there are similar words in the database, then the invert index is used to search the corresponding images.

## IV. Methodology
- The proposed loop closure system
- Based on BoW3D
- Extracts LinK3D features in raw point clouds
- Closes the loops in raw point clouds using the BoW3D
- Verifies the performance of the loop closure system

## A. BoW3D Algorithm
- In this section, we introduce the proposed BoW3D algorithm.
- As introduced in Section III-A, each dimension of LinK3D descriptor represents a specific keypoint in the corresponding area, which makes LinK3D descriptor quite discriminative.
- As a result, our method needs no further conversion for features by building a tree-structured vocabulary in an offline step. Therefore, our BoW3D does not require to load additional vocabulary file, which is more convenient for users.
- The structure of the database in memory is shown in Fig. 3, the hash table is used to build a one-to-one mapping between the word and the places where the word has appeared.
- The computational cost of hash table is O(1) theoretically, which makes it be suitable for efficient retrieval.

## Place Set1
- The data structure of BoW3D is a hash table.
- The word of BoW3D consists of the non-zero (Dim-value) in the descriptor and the corresponding dimension (Dim-ID).
- Each word corresponds to a place set, in which the word has appeared.
- The place also consists of two parts, one is frame ID, the other is the descriptor ID in the frame.
- Given the point set {S } c of current frame and the matching point set {S } l of loop frame, we compute the loop by minimizing the following cost function:
- where s i l ∈ {S } l and s i c ∈ {S } c are the corresponding matching points.
- R l,c and t l,c are the rotation and the translation of T l,c transformation respectively.
- T l,c is defined as follows:
- We first calculate the centroid s l and s c from {S } l and {S } c .
- Let ŝi l and ŝi c be the coordinates of the corresponding point s i l and s i c , which removes the centriod s l and s c respectively.
- Then we calculate the matrix:
- Find the SVD decomposition of W ,
- If W is full rank, we will get the solution of R l,c and t l,c by:
- This allows us to correct the loop pose.
- Moreover, the loop pose is also used for the geometry verification of candidate loop frame, and we set distance threshold T h dis to verify wether the candidate loop is valid.

## B. Loop Optimization
- After correcting the loop pose, the pose graph for the loop frames is built
- The vertexs of pose graph are the global poses to be optimized
- Edges (connections between the vertexs) of pose graph are the observation constraints, which consist of the relative poses between the sequential frames, and the corrected loop poses
- We define the residual between frame i and j as:
- The pose graph is optimized by minimizing the following cost function:
- where S is the set of all sequential edges and L is the set of all loop closure edges
- We use the Levenberg-Marquadt method implemented in the graph optimizer g2o [38] to solve the optimization
- After poses have been optimized, we update the local map of mapping thread. Specifically, the points in local map are updated based on the optimized global poses, which are more accurate.

## V. Experiments
- To comprehensively evaluate the performance of our algorithm, we perform experimental evaluation from four aspects: (i) Evaluate place recognition performance; (ii) Evaluate the performance of our method when integrated in 3D LiDAR SLAM; (iii) Test the hyperparameters and analyze the robustness of our method; (iv) Test the runtime for each part of the system.
- We perform experimental verification on KITTI [39] dataset which contains data from different street environments ranging from inner cities to suburb areas.
- The point clouds in KITTI were collected by a Velodyne HDL-64E S2 at the sensor rate of 10 Hz.
- There are 11 sequences (i.e., from 00 to 10) with ground truth poses, which are used to determine the number of true loops. Furthermore according to [40], some ground truth poses in KITTI involve large errors, and we do also find that the ground truth pose of sequence 02 and 08 involve large errors in experiment.
- Therefore, we use the more consistent poses refined by ICP to determine if there is a loop closure in sequence 02 and 08.
- Similar to SGPR [34], two point cloud scenes are regarded as a true positive loop pair if the Euclidean distance between them is less than 3 m and the time difference is greater than 30 s.
- These sequences (00, 02, 05, 06, 07 and 08) with loop closures are selected for the evaluation.

## A. Place Recognition Performance
- Our method outperforms the state-of-the-art LiDAR loop closure detection and place recognition methods, including M2DP, Scan context, Point-NetVLAD, Intensity Scan Context (ISC), LiDAR Iris, SGPR, OverlapNet, and SSC.
- The F 1 score is a measure of the performance of a place recognition system, and our method achieves high F 1 scores on most sequences.
- The Extended Precision is a measure of the performance of a place recognition system, and our method achieves high EP scores on most sequences.
- The comparison methods cannot be used to correct the full 6-DoF loop pose, which limits subsequent loop optimization in 3D LiDAR.

## B. Performance on LiDAR-based SLAM
- The loop closing system can effectively correct the cumulative errors
- The loop closing system is better than the original pose estimation results

## C. Hyperparameters Setup and Robustness Analyzation
- In this section, we provide more studies on parameter settings about T h r and T h f in Algorithm 1 through experiment
- For a wide test, we set eight parameters about T h r , and it starts from 2.5 to 4.25 with an interval of 0.25
- T h f starts from 4 to 10 with an interval of 1.
- The F 1 score and the average detection time of BoW3D are used to measure the performance of different parameter settings.
- The results are shown in Fig. 6.

## D. System Runtime
- KITTI 00 is used for the evaluation
- T h r = 4, T h f = 5
- Number of closer features set as 5 when add them to the database, and set as 3 when retrieve from the database
- Operates separately in different threads
- Takes overall less than 100 ms to process one frame, which ensures the realtime performance of the system when BoW3D applied to 3D LiDAR SLAM

## VI. Conclusion
- The proposed BoW3D algorithm exploits the LinK3D features to build the bag of words.
- The hash table is used as the overall structure of the database in BoW3D, which enables to retrieve efficiently.
- Compared with the state-of-the-art methods, BoW3D not only achieves competitive results, but also corrects the full 6-DoF relative loop pose in real time.
- Compared with deep-learning-based methods, our method does not require pre-training and GPU resources.
- In addition, we also embed the proposed BoW3D to LiDAR odometry system to verify its performance in practice.
