---
title: "Neural Story Planning"
date: 2022-12-16T21:29:41.000Z
author: "Anbang Ye, Christopher Cui, Taiwei Shi, Mark O. Riedl"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2212-08718v1.webp" # image path/url
    alt: "Neural Story Planning" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2212.08718)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2212.08718).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/neural-story-planning).

# Abstract
- Automated plot generation is the challenge of generating a sequence of events that will be perceived by readers as the plot of a coherent story.
- Traditional symbolic planners plan a story from a goal state and guarantee logical causal plot coherence but rely on a library of hand-crafted actions with their preconditions and effects.
- This closed world setting limits the length and diversity of what symbolic planners can generate.
- On the other hand, pre-trained neural language models can generate stories with great diversity, while being generally incapable of ending a story in a specified manner and can have trouble maintaining coherence.
- In this paper, we propose to use commonsense knowledge extracted from large language models to recursively expand a story plot in a backward chaining fashion. Specifically, our system infers the preconditions for events in the story and then events that will cause those conditions to become true.
- We performed automatic evaluation to measure narrative coherence as indicated by the ability to answer questions about whether different events in the story are causally related to other events. Results indicate that our proposed method produces more coherent plotlines than several strong baselines.

# Paper Content

## Introduction
- Automated plot generation is the challenge of generating a sequence of events that will be perceived by readers as the plot of a coherent story.
- Early solutions to story generation included symbolic planning (Meehan 1977;Lebowitz 1985;Porteous and Cavazza 2009;Riedl and Young 2010;Ware and Young 2011), and case-based reasoning (Pérez y Pérez and Sharples 2001; Gervás et al. 2005).
- These techniques explicitly represent and reason about the causal relationship between events.
- In particular, symbolic planners infer causal relations between events and through these causal relations, the logical soundness of a plan could be guaranteed.
- Story planners extended generic symbolic planners in a number of ways to create character believability (Riedl and Young 2010), character conflict (Ware and Young 2011), theory of mind (Ware and Siler 2021), etc.
- In story generators, logical soundness corresponds with the concept of plot coherence where each event-and the goal state-is justified by preceding events or the initial world state.
- Narrative psychologists note the importance of plot coherence in reader comprehension, avoiding confusion, acceptance of stories, and memory of stories (Trabasso and van den Broek 1985;Graesser, Lang, and Roberts 1991).
- Unfortunately provable plot coherence comes at a cost. Symbolic planners require libraries of hand-crafted schemas that describe what actions (called events when planning stories) are available.
- Among other things, action schemas define preconditions-logical statements that must be true for an event to be executable-and effects-logical statements that describe how the state of the world is changed if an action succeeds in execution.
- While planned stories are highly causally coherent, the reliance on hand-crafted libraries of action schemas and pre-existing symbols for characters, objects, and locations, limits the length and diversity of plots.
- Neural language model based approaches to story generation, on the other hand, can generate more diverse stories about any number of topics included in the training data (Martin et al. 2017;Roemmele and Gordon 2018;Fan, Lewis, and Dauphin 2018;Yao et al. 2019;Goldfarb-Tarrant, Feng, and Peng 2019;Rashkin et al. 2020).
- This is especially true for large, pre-trained neural language models that have been trained on, amongst other things, large corpora of stories.
- Neural story generators create stories by sampling from the probability distribution P (w n |w 1 , w 2 , ..., w n−1 ; θ) where θ are the parameters of the language model. Sampling from this learned distribution emulates human patterns of language, including that found in stories.
- However, when addressing novel combinations of topics and circumstances sampling is not guaranteed to provide causal coherence.
- Other limitations of neural text generation, such as repetition and generic responses, have also been documented (Holtzman et al. 2019).
- In this paper, we seek to unify the strengths of symbolic planning and neural text generation to achieve causally coherent, ending-guided, story plotlines.
- To this end, we have developed a story planner based on partial-order causal link planning (POCL) (Penberthy and Weld 1992) to generate story plotlines.
- However, instead of using a library of handcrafted action schemas and world state symbols, our planner uses a large pre-trained language model (specifically GPT-J-6B) to infer events and their preconditions.
- In this way, the story planner is able to operate without pre-specifiying actions, characters, world locations, or objects in the world.
- Yet the planner can still identify causal relations between events and ensure causal coherence of stories.
- Our planner works via ends-means chaining-working backward from a given story ending. Given a text description of the ending of the story as well as an optinal set of initialstate conditions that describe elements of the story world that can be assumed true, the system queries the language model to generate preconditions that must be satisfied for the given ending to occur.
- For example (see Figure 1), the event, "Sally buys a gun from the gun store" will produce preconditions that include "Sally is at the story" and "Sally has money".
- Each of these preconditions describe a partial world state that must come into...

## Background and Related Work
- A planner finds a sequence of actions that transforms the initial world state into one in which a goal situation holds.
- Story and plot generation using symbolic planning (Meehan 1977;Lebowitz 1985;Porteous and Cavazza 2009;Riedl and Young 2010;Ware and Young 2011;Ware and Siler 2021) is known to result in causally coherent plotlines but at the expense of story diversity and length due to reliance on hand-crafted action schemas and symbols.
- Several story planners (Riedl and Young 2010; Ware and Young 2011) use a form of symbolic planning called partial order causal link planning (POCL) (Penberthy and Weld 1992).
- POCL planners search plan-space where every node in the space constitutes an unique partially-ordered plan and the planner transitions from one plan to the next by adding an action or resolving a logical causal flaw due to partial ordering.
- A plan is represented as a tuple P = A, C, O .
- A is a set of actions instantiated from a library of action schema templates that specify preconditions effects.
- C is a set of causal links of the form a 1 c − → a 2 where a 1 , a 2 ∈ A and c is a predicate condition that unifies with an effect of a 1 and a precondition of a 2 .
- O is a set of temporal ordering constraints a 1 → a 2 that indicates that a 1 must be temporally ordered before a 2 .
- At every iteration, the planner selects a plan on the fringe of the plan-space and an action in that plan with an unsatisfied precondition (or the goal state).
- An unsatisfied precondition is one in which there does not exist a causal link that points to the action that has a matching the condition.
- A new successor plan is generated for each way of satisfying the action precondition-either by adding a new action and causal link, or by identifying an existing, preceding action with a matching effect (or the initial state)-and extending a causal link between them.
- Other operations not summarized here ensure logical soundness.
- Planning terminates when a plan is found with no actions with unsatisfied preconditions.

### Neural Story Generators
- Early attempts at neural story generation used language models trained on story corpora to generate stories (Roemmele and Gordon 2018) or plots (Martin et al. 2017).
- However, such vanilla use of language models were found to have trouble maintaining coherent context.
- Guan et al. (2020) further fine-tunes a pre-trained language model on commonsense datasets to help increase the coherence of stories.
- Attempts to control the coherence of stories and plots include conditioning (e.g., Rashkin et al. (2020)) or hierarchical generation (Fan, Lewis, and Dauphin 2018;Yao et al. 2019;Fan, Lewis, and Dauphin 2019).
- Hierarchical generation is similar to greedy planning by first generating a "sketch" or "skeleton" at a higher level of abstraction.
- Language models are not generally aware of, or able to drive toward, a given story ending.
- Tambwekar et al. (2018) fine-tuned language models to be goal-aware.
- The EDGAR system (Castricato et al. 2021) generates stories backward using language model based question-answering to iteratively ask how the story state came to be.
- This is similar to our approach, but does not explicitly reason about causality.
- C2PO (Ammanabrolu et al. 2021) conducts a bidirectional search, querying story events that can possibly follow or possibly precede events using the COMET (Bosselut et al. 2019) model of commonsense inference.
- C2PO is the closest to our approach in terms of conducting a search through event space.
- C2PO relations between events are referred to as soft causal links because the capture inferred (probabilistic) event relationships, whereas our system uses hard causal links that capture explicit conditional relations between events as in POCL planning.
- The TattleTale system (Simon and Muise 2022) uses a classical symbolic planner to generate a totally ordered sequence of actions and then uses this sequence to condition a language model to generate natural language stories.

## Neural Story Planner
- The proposed technique generates causally coherent story plans using the concepts of causal links from POCL plan-"Sally shot John."
- "The gun needs to be loaded"
- "Sally had an argument with John at Sally's house"
- "John drove to get to Sally's house"
- "John was at John's home"
- "John drove to get to John's home"
- "John has a car"
- "Sally loaded the gun at Sally's house"
- "Sally drove to get to Sally's house"
- "Sally has a car"
- "Sally had an argument with John at Sally's house"
- "Sally buys a gun from the gun store"
- "Sally has money"
- "There is a gun for sale at the store"
- "Sally walked to get to the store"
- "John is at Sally's house"
- "Sally is at the store"
- "Sally is at Sally's house"
- "Sally has a gun"
- The proposed technique generates causally coherent story plans using the concepts of causal links from POCL plan-"Sally shot John."
- "The gun needs to be loaded"
- "Sally had an argument with John at Sally's house"
- "John drove to get to Sally's house"
- "John was at John's home"
- "John drove to get to John's home"
- "John has a car"
- "Sally loaded the gun at Sally's house"
- "Sally drove to get to Sally's house"
- "Sally has a car"
- "Sally had an argument with John at Sally's house"
- "Sally buys a gun from the gun store"
- "Sally has money"
- "There is a gun for sale at the store"
- "Sally walked to get to the store"
- "John is at Sally's house"
- "Sally is at the store"
- "Sally is at Sally's house"
- "Sally has a gun"

### Precondition Generation
- We use the few-shot capabilities of large language models to infer the preconditions of events.
- We designed prompts based on psychological theories of reading comprehension that indicate that readers actively track different types of relations between events (Trabasso and van den Broek 1985;Graesser, Lang, and Roberts 1991).
- Consequence relations are equivalent to causal links and indicate that the latter event cannot occur unless the former occurs. Thus consequence relations also capture whether one event enables another to be possible.
- Reason relations capture the goals of characters that explain why they are doing something.
- Outcome relations capture which events satisfy which goals.
- Initiate relations capture when an event causes a character to form a goal.
- We break preconditions into six different classes and have developed a prompt for each.
- The first four classes capture consequence relations:
- Item Need. What item(s) must the character possess for an action to execute? E.g., in order for one character to drive somewhere they must have a car. What item must [P erson] possess to [Action]?
- Answer: Where must the character be in order to carry out an action? E.g., for one character to buy something from a store the character must be in the store. Where is [P erson]? : [Answer]
- The context consists of all events that are ancestors of the current event; even though they will come later in the story, they bias the LM toward reusing locations.
- The hint, which is optional, is filled with any location information that is heuristically extracted from the event.
- • Item state. What must be true about an item for an action to be performed? E.g., in order to shoot someone, the gun must be loaded. [Event] What can we tell about the [item] other than how [P erson] obtained it? [Answer]
- • How. What needed to have happened for something to be achievable now? E.g., "John became a pro wrestler" would have a how-precondition that could be satisfied by another event such as "John trained for one year".
- The next precondition class aligns with initiates relations. Our version focuses on character-character interactions.
- • Interactions with others. What must have happened between two characters for an action to be peformed? For example, a character might perform a violent action toward another character if first there was an argument.
- The final class of precondition is the reason, which can be satisfied by an event that causes a character to have a goal:
- • Reason. What serves as the reason for an event? E.g., the event "John was arrested" would have a reasonprecondition that could be satisfied by an event such as "John stole a car".
- Each prompt consists of seven few-shot examples and the 8th leaves the answer blank to be completed by the LM.
- When the inference is a short phrase, as is the case in all of our precondition classes, but especially true for Item Need preconditions, querying a LM suffers from surface form competition (Holtzman et al. 2021) in which very common responses can be favored over those that are more responsive to the prompt.
- For example, to the question "What does John need to clean the table?" a LM would prefer the answer "nothing" over the correct answer "cleaning cloth" because GPT-J has seen the former more often than the latter in its training corpus.
- We adapt the Domain Conditional Pointwise Mutual Information (PMI DC ) rescoring method of Holtzman et al. (2021) to address the surface form competition issue.
- We use P M I DC = P (y|x,domain) P (y|domain) ,...

### Event Generation
- Preconditions are satisfied by the effects of events.
- We directly infer events such that they satisfy a precondition.
- For how, interaction with others, and reason preconditions, we directly copy the sentence from the precondition to make a new event because the nature of those precondition inferences produce sentences that are also events.
- These suggest pairs and chains of events that go together naturally, similar to scripts (Schank and Abelson 2008).
- For item need, location and item state preconditions we use specialized prompts for each precondition type:
- What event occurred so that the character obtained the required item? E.g., the item need precondition "John has gun" could be satisfied by "John bought a gun from the store".
- As with precondition generation, each prompt has seven examples and the eighth has the answer blank.
- When an event is generated to satisfy a precondition on another event, we create a causal link, which is a directed arc from the new event to the precondition, indicating that (a) the precondition is satisfied, and (b) the new event is a temporal predecessor.
- The plot is thus represented as a directed acyclic graph, as shown in Figure 1.
- We make a greedy assumption that if more than one event has the same precondition then the same event will satisfy both preconditions.
- We define two preconditions to be the same if (1) they are associated with the same character, and (2) the cosine similarity of the two preconditions surpass certain threshold (0.75 for item need and location and 0.8 for other categories).
- Thus, before generating a new event, we check to see if an existing event can be used and a causal link extended from the already existing event to the precondition.
- This corresponds to the concept of action re-use in POCL planning.
- The exception to this rule is when the new causal link causes a cycle in the graph.
- When duplicate events are generated, as determined by cosine similarity, we record an event has having multiple possible phrasings.
- The phrasing with the highest count is presented as part of the plan.
- Ties are broken by taking the phrase with the lowest perplexity.
- Additionally, we also discard the generated precondition if it is identical to its parent event.
- Note, we do not do this for the reverse, where the generated event is identical to the precondition, as shown in Figure 1 in the "Sally had an argument with John in Sally's house" precondition and event.
- Preconditions that match the initial state conditions I are never used to generate events since these are conditions given by the user.
- We do not model negative effects of events.

### Final Total Ordering
- The final step in POCL planning is to produce a total ordering of the events in the plot graph.
- In POCL planning, any two events that are not ancestors or descendant of each other are considered partially ordered.
- Any topological sort that doesn't violate any temporal ordering constraints is valid.
- Because of our open-world assumptions, we implement a topological sort that prefers certain orderings over others.
- Whenever there are two events e i , e j that are neither descendants nor ancestors, we order them e i > e j when type(e i ) > type(e j ) and type(•) is a function that maps an event to the type of precondition it satisfies.

## Evaluation
- We evaluate the extent to which our planning technique generates coherent plots
- Psychological studies of human reader comprehension measure reader comprehension by reader ability to answer questions about a story
- In our setting, we prompt GPT-3 (Brown et al. 2020) to answer enablement questions about generated plots
- 2 e use GPT-3 (text-davinci-002) as an estimate of the ease by which questions can be answered about generated stories, and thereby an estimate of the extent to which generated stories support question-answering for reader comprehension
- We evaluated our system and all baselines by generating plotlines that were seeded from randomly chosen stories from the test split of ROCStories dataset (Mostafazadeh et al. 2016)
- The ROCStories dataset contains plot-like common everyday stories with titles for each story
- We randomly sampled 50 story titles from the test split of ROCStories to seed our system and the baselines
- We generate a story plotline for each title and then assess whether the plotline is coherent
- Systems are scored by the percentage of the time that GPT-3, appropriately prompted, can determine that a given event in a story is enabled by any prior events in the story
- We do not evaluate systems using perplexity or variants of BLEU score

### Coherence Measure
- To measure whether the generated stories support enablement comprehension, we pose questions to GPT-3 in the form "What's the action, if any, enabled ACTION?" along with the sentences from the earlier parts of the story plan for GPT-3 to choose from.
- Since the first sentence of a story is not enabled by default, we excluded the first sentence in our evaluation.
- We set temperature = 0.7.
- We consider an enablement question answerable if the answer is found in the earlier part of the story and is different from (percentage of overlapped 1-gram ≤ 0.7 ) the queried event.
- If the question yields no answer, GPT-3 will respond with "none".
- We include negative few-shot examples in the prompt that are answered with "none" so that GPT-3 knows it is a valid response.
- To validate our measure, we apply the measure to 100 stories randomly sampled from the test split of the ROCStories dataset.
- Stories in the dataset are assumed to be coherent.
- In half of the stories, we force incoherence by randomly replacing the queried event with a random even taken from a different story in the dataset. That is, half of the stories should be answerable and half of the stories should produce "none" when prompted with our above enablement prompt.
- Our measure yields an 85.39% response rate on unaltered stories and correctly predicts "none" 71% of the time when presented with an incoherent story. Thus our measure has an overall accuracy of 78.20%.
- ROCStories do not always contain explicitly enabling events. It is also sometimes possible for a randomly inserted event to appear to have an enabling predecessor action. Thus some degree of error is expected, and we deem our measure to be sufficient to produce a relative assessment between plot generation systems that produce story plotlines with similar styles.

### Models and Baselines
- GPT-J-6B is a model that is allowed to generate an entire story, but is only prompted with few-shot examples pulled randomly from the ROCStories dataset
- C2PO is a model that uses bidirectional interpolation and is conditioned on leading context
- plan-write-revise is a model that is fine-tuned on ROCStories and is parsed to remove non-action sentences that give declarative statements about fact about the story world and characters
- Our model is capable of generating more than one object precondition for a given event
- We only include methods with outputs that have a similar style and structure as our story plots

### Results and discussion
- The results are shown in Table 3.
- Our planner achieves the highest percentage of answerable enablement questions by a considerable margin.
- This can be partially explained by the fact that our planner is intentionally introducing events to the story that enable future events.
- The preconditions and linkages between events are not present in the final rendering of a plotlines and any enablement relations are still implicit.
- Our evaluation metric is likely sensitive to this type of structure.
- In that sense, the metric can be seen as a measure of the ease with which enablement questions can be answered about a story.
- C2PO and comGen use commonense inferences from COMET (Bosselut et al. 2019) that have the potential to create explicit enablement relations.
- C2PO in particular generates commonense inteferences about "wants", what is expected to come after an event, and "needs", what is expected to precede each event in a story.
- As noted by Ammanabrolu et al. (2021) these commonsense relations between events are very similar to causal links though the exact nature of the relation is implicit.
- We repeat the ROCStories response rate of 85.39% in Table 3 for completeness.

### Conclusions
- The Neural Planner can generate coherent story plotlines
- The Neural Planner can generate story plotlines that are also comprehensible
- The Neural Planner can generate story plotlines that are also answerable to questions about causal enablement relations
