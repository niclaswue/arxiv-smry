---
title: "Language Models are Drummers: Drum Composition with Natural Language Pre-Training"
date: 2023-01-03T15:47:53.000Z
author: "Li Zhang, Chris Callison-Burch"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2301-01162v1.webp" # image path/url
    alt: "Language Models are Drummers: Drum Composition with Natural Language Pre-Training" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2301.01162)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2301.01162).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/language-models-are-drummers-drum-composition).

# Abstract
- Automatic music generation with artificial intelligence typically requires a large amount of data which is hard to obtain for many less common genres and musical instruments
- To tackle this issue, we present ongoing work and preliminary findings on the possibility for deep models to transfer knowledge from language to music, by finetuning large language models pre-trained on a massive text corpus on only hundreds of MIDI files of drum performances
- We show that by doing so, one of the largest, state-of-the-art models (GPT3) is capable of generating reasonable drum grooves, while models that are not pre-trained (Transformer) shows no such ability beyond naive repetition.
- Evaluating generated music is a challenging task, more so is evaluating drum grooves with little precedence in literature. Hence, we propose a tailored structural evaluation method and analyze drum grooves produced by GPT3 compared to those played by human professionals, exposing the strengths and weaknesses of such generation by language-to-music transfer. Our findings suggest that language-to-music transfer learning with large language models is viable and promising.

# Paper Content

## Introduction
- Music understanding and generation using artificial intelligence has a long history (Roads 1985)
- Symbolic representation of music and language share many similarities, such as notes, measures, and sections
- Most work in data-driven music processing requires a large amount of symbolic music data, which is difficult to obtain
- Low-resource symbolic music processing remains highly challenging
- In this work, we propose a textual representation of a drum performance that can be used to generate nontrivial drum grooves without requiring a large amount of music data.

## The Drum Set
- The drum set is a compound musical instrument consisting of many sub-instruments, including drums and cymbals
- The performance on a drum set can be notated as sheet music, a human-readable symbolic representation, or as MIDI, which records the when each drum is hit at what velocity

## Dataset
- The Groove dataset is the largest and most highquality dataset of drum performances to date
- The drum performances are either grooves, long sequences of rhythmic ideas, or fills, short bursts of freeflowing expressions
- As we focus on drum generation or composition throughout a long sequence, we only consider the grooves in the dataset
- Each MIDI is marked with the style (e.g., rock, funk, gospel, etc.), the tempo (in beats per minute, BPM), and the time signature
- For simplicity, we only consider those in the time signature of 4/4
- We follow the train-development-test splits in the dataset
- The statistics of the filtered Groove dataset are shown in Figure 1
- LLMs have demonstrated extremely strong few-shot transfer learning ability from one textual task to other
- To possibly exploit this in music, it is necessary to come up with a textual representation of the drum grooves
- We propose a pianoroll-like representation (Brunner et al. 2018), referred to as a drumroll, that is essentially a multi-line string where each row corresponds to a 16-th note in the time sequence, and each character in a line corresponds to whether a drum is hit.

### Task
- The model is given the first 2 measures of a groove and must complete the rest.
- This is analogous to conditioned story generation in NLP.

### Model
- The two naive baselines are randomly choosing whether to play a note and repeating the second given measure.
- We then finetune a state-of-the-art LLM, OpenAI's GPT3 Davinci with 175 billion parameters, on the training set.
- In each file of a drum groove, the input (prompt) is the first 2 measures and the output (completion) is the remaining 14 measures.
- The temperature is set to 0.85 to encourage creativity.
- Finetuning the model on the training set costs $38.33 and takes around 30 minutes using OpenAI's API.
- To ascertain the role model size plays in drum generation, we further consider a smaller GPT3 Ada model with 350 million parameters, which has been pre-trained on the same corpus and we use the identical settings as the larger Davinci model.
- Finetuning the model on the training set costs $0.51 and takes around 5 minutes using OpenAI's API.
- Both GPT3 models are later found to be able to generate nontrivial drum grooves.
- The ascertain the role language pre-training plays in drum generation, we set the control to be an un-pre-trained GPT3 model, namely a Transformer (Vaswani et al. 2017) with the same size as GPT3.
- Because our computing resources cannot accommodate a model as big as Davinci, and also because merely 373 text files each with 256 lines in the training set are likely insufficient to converge the training loss, we finetune a smaller, un-pre-trained Transformer with 85 million parameters, the same magnitude as GPT3 Ada.

## Evaluation
- The drum grooves generated by GPT3 are good.
- The drum grooves were evaluated using both objective/automatic and subjective/human evaluation.
- The findings were based on the test set.

### Objective Evaluation
- The established methods of automatic evaluation of symbolic music generation are unsuitable for our task
- We propose a structural evaluation called the pattern and fill analysis
- We assume that often a good drum groove minimally satisfies the following criteria: 1. There exists one or more consistent patterns of some rhythmic idea and occasional change-ups known as fills. 2. The measures in a pattern are sufficiently similar, but ideally not identical. 3. The measures in a fill are sufficiently different from those in adjacent patterns.
- Later, we verify that the human-performed grooves mostly satisfy these criteria.

### Subjective Evaluation
- The objective evaluation is clearly informative but insufficient.
- Hence, we conduct a listening test and perform an er-Figure 5: The sheet music of a satisfactory drum groove generated by GPT3 (above), juxtaposed with the groove with the same first 2 measures played by human from the dataset (below). We annotate each measure as either a pattern or a fill.
- For the grooves performed by human, most are judged as consistent and most include at least one fill which is sufficiently different from the rest of the rhythmic patterns.
- In comparison, grooves generated by GPT3 Davinci is only slightly less consistent with desirable variations among measures, but significantly less of them contain any fills, rendering the grooves less interesting and more predictable overall.
- For the smaller GPT3 Ada model, the observation holds to a larger extent, with more inconsistent grooves and less fills.

### Case Study and Takeaways
- The LLMs demonstrate an impressive ability to write good drum grooves given only hundreds of training examples without any knowledge of what features to pay attention to.
- From our objective and subjective evaluation above, we have observed that both LLMs and human are able to compose drum grooves with a structure and some variations.
- However, models' drum composition still worse than human's. We postulate several factors.
- One source of the lack of musicality in machine-generated drum grooves stems from the misplacement of back-beats, which are steadily accented beats in a measure, usually the 2nd and the 4th in 4/4 in many genres of music. Human drummers, when playing variations, tend to respect the back-beat placements, while models tend to disregard such concept.
- Another source of the lack of musicality is the lack of drum fills. While human drummers often inherently think about the cycle between patterns and fills to give a captivating performance, models are yet to realize the importance of those occasional deviations.
- To qualitatively examine these claims, we showcase two sets drum grooves composed by GPT3, one showcasing its strengths and one its weaknesses, along with the human performed grooves with the same first 2 measures.
- A positive example is shown in Figure 5. Clearly, both grooves produced by human and GPT3 alike contain consistent patterns interspersed with fills, a prototypical structure that is expected and desired by most audience.
- Closely examining the pattern groupings, both grooves vary the place-ment of the bass drum and the snare drum, known as syncopation, while keeping the back-beats at the 2nd and 4th quarter note in tact.
- Besides the ability to conforming to human drummers' standard practice, this example also showcases LLMs' ability to be creative.
- While the human-performed groove closely adheres to the template of 3 measures of patterns followed by 1 measure of fill, the GPT3-generated groove does not. Instead, it employs multi-measure fills, and more interestingly, grouping of an odd number of patterns followed by fills, which is uncommon in the genre.
- Two negative examples are shown in Figure 6, representing two common problems of GPT3-generated drum grooves.
- This first case is referred to as displaced measures. When human drummers play a pattern, they often fit each measure with some rhythmic idea. In other words, the boundaries between two measures are often clear.
- In our drumroll representation, each measure, 16 lines of texts, is followed by a newline of 'SEP' to denote such boundary. However, GPT3 Ada sometimes fail to respect these boundaries and displaces the measures, thus having more "chaotic" patterns as reported in Table 3.
- In comparison, GPT3 Davinci makes a lot less such mistakes.
- The repetition of drum grooves is accepted in some music genres such as pop, dance, or rock, but frowned upon in most others as they are often thought to be mechanical.
- As of now, we have taken a model-free approach where the LLMs are only trained on some drum groove data without any additional information or priors.
- To reinforce the strengths and alleviate the weaknesses discussed before, we suggest future work to take a modular approach instead of tackling the task in an end-to-end fashion.

### Improvisation or Recitation?
- LLMs are able to create new and unseen drum grooves
- Only a small portion of generated measures are duplicates of any seen measures during finetuning

## Related Work
- Automatic music generation has a long history
- Most modern work in automatic music generation leverages model architectures that have shown to be effective in computer vision or NLP
- In a supervised setting, which greatly limits its application to lesser known genres or specific instruments
- While there is yet to be a pre-trained music generation model as versatile as its counterpart in NLP such as GPT3, we believe the exploration of language-to-music transfer is necessary but uncharted
- Automatic drum generation has a small body of existing work
- Similar to music generation in general, the drum generation task can happen in various settings
- In more practical settings, a long sequence of drum composition is generated conditioned on musical signals such as the basslines
- While this line of work is most similar to ours which by far only deal with drum solo performance, all the work above has used drum composition data with limited size and variations as well as models (such as LSTM) that are relatively outdated in the AI com-munity
- Nevertheless, a direct comparison would be beneficial in future work

## Conclusion and Future Work
- Pre-trained large language models (LLMs) can learn to generate music non-trivially
- The model size and the presence of language pre-training are both important factors in this ability
- We hope this observation inspires research efforts in not only low-resource music generation, but also exploration of extraordinary potentials of LLMs
- We also attempt to pioneer the automatic evaluation of drum grooves which we hope to facilitate future work in drum generation with AI
