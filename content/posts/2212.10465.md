---
title: "SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization"
date: 2022-12-20T17:38:47.000Z
author: "Hyunwoo Kim, Jack Hessel, Liwei Jiang, Ximing Lu, Youngjae Yu, Pei Zhou, Ronan Le Bras, Malihe Alikhani, Gunhee Kim, Maarten Sap, Yejin Choi"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2212-10465v1.webp" # image path/url
    alt: "SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2212.10465)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2212.10465).


# Abstract
- We present SODA, a million-scale high-quality social dialogue dataset.
- SODA is composed of 1.5M socially-grounded dialogues distilled from a pre-trained language model.
- Human evaluation shows that dialogues in SODA are more consistent, specific, and natural than prior human-authored datasets.
- Extensive evaluations show that COSMO is significantly more natural and consistent on unseen datasets than best-performing dialogue models.

# Paper Content

## Introduction
- The lack of diversity, scale, and quality of training corpora has hindered progress on true open-domain social dialogue agents.
- SODA is a million-scale dialogue dataset covering a wide variety of social interactions that goes beyond specific skill-focused dialogues.
- Human evaluation shows that SODA surpasses existing human-authored dialogue corpora across axes like consistency, specificity, and (surprisingly, even) naturalness.
- To make SODA, we propose CO 3 , a framework for COntextualizing COmmonsense for distilling COnversations from a PLM.
- Our goal is to obtain natural conversations covering a wide variety of social interactions.

### Background
- At its core, conversation is a fundamental form of social interaction
- These experiences are abstracted into narratives or scripts
- Eventually, social experiences form our knowledge for explaining everyday events and inferring the mental states of others
- This inference is coined attribution in social psychology
- Inspired by cognitive science, we reverse the abstraction process, starting from social commonsense knowledge in symbolic forms

### Commonsense Knowledge Graph
- The paper discusses a method for creating a condensed knowledge graph from narratives
- The knowledge graph is represented by symbolic triples
- The knowledge graph is based on Atomic 10x, a large-scale set of triples
- The PLM is able to write narratives in sentence form that are more detailed than the original commonsense

### From Narrative to Conversation
- Inferring who is speaking in the dialogue is easier in cases where narratives contain the person variables (i.e., PersonX and PersonY); we set those two as the interlocutors for these cases.
- For narratives that include only one person (e.g., "David goes to an amusement park..." from above), we prompt the PLM to predict the other interlocutor.
- For the example story with David, "his friend Sarah" will be a plausible interlocutor.
- The generated narratives act as the scene description or background context, and the speakers are the actors in the scene.
- We append the first speaker as an utterance prefix to the prompt.
- An example of the final prompt is "[narrative] The following is a long in-depth conversation happening in the scene between David and his friend Sarah with multiple turns.\nDavid:".

### Validating Narratives and Conversations with Commonsense Knowledge

### Postprocessing the Conversations
- Basic filtering: 2.2 million conversations were distilled from the Instruct-GPT dataset
- Safety filtering: conversations with dangerous and harmful contents were filtered out
- Commonsense filtering: the seed commonsense triple was inferred from all remaining SODA instances
- Name bias mitigation: all names in conversations were randomly replaced with Top-10K names of US SSN applicants
- High quality: human raters judge SODA as better in quality compared to both DailyDialog and BlendedSkillTalk across all axes
- Time-efficient: collecting SODA via our contextualization framework is significantly more time and cost efficient

### Contextualization is Important
- humans prefer context-grounded conversations significantly more than ones generated without context
- conversations sampled without context are not only less specific and less interesting, but also exhibit lower lexical diversity than conversations from our framework
- COSMO is trained on top of LM-adapted T5 (Raffel et al., 2020;Lester et al., 2021), which achieves strong benchmark performance across various classification/generation tasks

### Out-of-domain Setting
- COSMO outperforms all other existing models with a significant margin across all aspects
- Human judges prefer COSMO's responses even over the original gold responses in the dataset, suggesting that dialogue models trained on SODA can lead to high generalizability and naturalness

### One-sided Out-of-domain Setting
- COSMO outperforms BlenderBot on BlenderBot's training domain (BlenderBot also shows relatively low performance on SODA)
- SODA contains patterns not present in existing dialogue datasets

### In-domain Setting
- COSMO is more specific and hence more favored than the responses from its teacher model.
- COSMO is on par with ChatGPT in this setting in terms of overall quality.
- Although ChatGPT's responses are much more specific, it lacks naturalness compared to COSMO.

## Related Work
- Existing dialogue datasets generally derive from one of the three sources: (1) Online learning websites/textbooks (Li et al., 2017) or movie/drama scripts (Danescu-Niculescu-Mizil and Lee, 2011);dialogues for language learners may lack complex language usage and movie scripts may depict less natural scenes compared to day-to-day scenarios.
- Crowdsourcing (Rashkin et al., 2019;Zhou et al., 2021;Tran et al., 2022): instructing human annotators to write dialogues is a process potentially prone to collecting responses that are somewhat short/dull due to incentive misalignment between researchers and crowdworkers (Zhou et al., 2022).
- Noisy web conversations such as Reddit comments (Baumgartner et al., 2020) and Twitter (Ritter et al., 2011); while widely used in dialogue agent pre-training stage due to their scale, these may represent different conversational frames vs. dyadic social conversations.
- SODA contributes meaningfully to the suite of existing corpora via improved scale, quality, and contextualization.
- Augmented Dialogue Datasets with PLMs. Several studies have used pre-trained large language models (PLM) to augment dialogue datasets.
- Blended Skill BotsTalk by letting multiple agents grounded in target skills engage for multi-skill dialogues. GPT-3 has also been used to help simulate task-oriented dialogues (Li et al., 2022) on a small scale.
- Others also augment dialogues with additional annotations -e.g., commonsense inferences (Zhou et al., 2022) or task-specific labels (Kulh√°nek et al., 2021;Chen et al., 2022).
- Compared to existing works, we generate full conversations from scratch by contextualizing social commonsense knowledge in a significantly large-scale, rather than adding new responses/annotations to existing dialogues.

## Conclusion
- We presented SODA, the first million-scale dialogue dataset covering a wide range of social interactions.
- Our dataset is not only orders of magnitude larger than several popular dialogue datasets; it is also perceived to be significantly better than them across multiple aspects (e.g., naturalness, specificity, consistency).
- With SODA, we trained a conversation model COSMO that can generalize significantly better than existing models to unseen dialogues; and generate responses that are even more preferred than ground-truth responses of existing dataset.
- We hope our work can alleviate the data scarcity issue in the dialogue field and expand it by exploring more diverse conversation distillation methods in the era of large-scale pre-trained language models.

## Ethical and Societal Considerations & Limitations
