---
title: "SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization"
date: 2022-12-20T17:38:47.000Z
author: "Hyunwoo Kim, Jack Hessel, Liwei Jiang, Ximing Lu, Youngjae Yu, Pei Zhou, Ronan Le Bras, Malihe Alikhani, Gunhee Kim, Maarten Sap, Yejin Choi"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2212-10465v1.webp" # image path/url
    alt: "SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2212.10465)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2212.10465).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/soda-million-scale-dialogue-distillation-with).

# Abstract
- We present SODA, a million-scale high-quality social dialogue dataset.
- Using SODA, we train COSMO, a generalizable conversation agent outperforming previous best-performing agents on both in- and out-of-domain datasets.
- In contrast to most existing crowdsourced, small-scale dialogue corpora, we distill 1.5M socially-grounded dialogues from a pre-trained language model (InstructGPT; Ouyang et al., 2022).
- Dialogues are distilled by contextualizing social commonsense knowledge from a knowledge graph (Atomic10x; West et al., 2022).
- Human evaluation shows that dialogues in SODA are more consistent, specific, and (surprisingly) natural than prior human-authored datasets - e.g., DailyDialog (Li et al., 2017), BlendedSkillTalk (Smith et al., 2020).
- In addition, extensive evaluations show that COSMO is significantly more natural and consistent on unseen datasets than best-performing dialogue models - e.g., GODEL (Peng et al., 2022), BlenderBot (Roller et al., 2021), DialoGPT (Zhang et al., 2020). Furthermore, it is sometimes even preferred to the original human-written gold responses.

# Paper Content

## Introduction
- Progress on true open-domain social dialogue agents has been hindered by the lack of diversity, scale, and quality of training corpora
- Most dialogue agents are either trained on large amounts of unfiltered conversations scraped from internet forums (e.g., Reddit, WebText; Zhang et al., 2020;Peng et al., 2022), or on highly curated/specialized crowdsourced dialogues (e.g., persona-based or empathetic chit-chat; Zhang et al., 2018;Rashkin et al., 2019).
- However, these dialogue agents still suffer from issues of unnaturalness, toxicity, incoherence, blandness, and a lack of commonsense
- We introduce SODA (SOcial DiAlogues), a million-scale dialogue dataset covering a wide variety of social interactions as a step to address these issues. SODA goes beyond specific skill-focused dialogues and features more general conversations as a result of being grounded on rich social commonsense and narratives.
- Our dataset includes 1.5 million dialogues distilled from a large language model (in our case, InstructGPT; Ouyang et al., 2022) resulting in more than 11 million utterances with 300 million tokens: SODA is the largest publicly available open-domain conversation dataset.
- Human evaluation shows that SODA surpasses existing human-authored dialogue corpora across axes like consistency, specificity, and (surprisingly, even) naturalness
- To make SODA, we propose CO 3 , a framework for COntextualizing COmmonsense for distilling COnversations from a PLM -i.e., adding situational information in multiple small steps
- (1) Retrieve social commonsense from symbolic commonsense knowledge graph, (2) convert it into sentence form, (3) generate narrative from the sentence, (4) infer the speakers from the narrative, and finally (5) derive contentful conversation grounded in the narrative and speakers.
- Figure 1 illustrates the high-level steps of our framework.
- Anchoring the PLM in commonsense knowledge for deriving conversations offers two key advantages: (1) minimizing nonsensical conversations and (2) maximizing diversity.
- Since PLMs are prone to hallucinations (Weidinger et al., 2021), the seed commonsense knowledge can help them stay on a sensible generation path. Furthermore, it offers a means of validating whether the generated conversation does include the commonsense
- We also find sampling naively from a PLM without context can result in redundant and generic conversations
- Commonsense knowledge triples in knowledge graphs cover a wide range of everyday situations while being softly unique
- Hence, they provide a diverse set of starting points for our distillation.
- With SODA, we train a conversation model, COSMO. Human evaluation results suggest COSMO generalizes better to unseen out-of-domain conversations than existing dialogue models, winning by more than 65% on average in head-to-head comparisons
- Moreover, human judges prefer responses of COSMO even over ground-truth responses of the unseen dataset
- We also test COSMO on another out-of-domain dataset and find that it significantly outperforms even the model trained directly on the target dataset.
- Despite COSMO being 10x smaller than the teacher model, COSMO's responses are more favored than responses from our teacher model InstructGPT-3, when tested on SODA.
- Lastly, empirical results demonstrate COSMO is on par with the contemporaneous ChatGPT (OpenAI, 2022) for overall quality on SODA and significantly outperforms ChatGPT in terms of naturalness

### Background
- At its core, conversation is a fundamental form of social interaction
- These experiences are abstracted into narratives or scripts
- Eventually, social experiences form our knowledge for explaining everyday events and inferring the mental states of others
- This inference is coined attribution in social psychology
- Inspired by cognitive science, we reverse the abstraction process, starting from social commonsense knowledge in symbolic forms

### Commonsense Knowledge Graph
- The paper discusses a method for creating a condensed knowledge graph from narratives
- The knowledge graph is represented by symbolic triples
- The knowledge graph is based on Atomic 10x, a large-scale set of triples
- The PLM is able to write narratives in sentence form that are more detailed than the original commonsense

### From Narrative to Conversation
- Inferring speakers from the narrative
- Inferring who is speaking in the dialogue is easier in cases where narratives contain the person variables (i.e., PersonX and PersonY); we set those two as the interlocutors for these cases.
- But for narratives that include only one person (e.g., "David goes to an amusement park..." from above), we prompt the PLM to predict the other interlocutor.
- For the example story with David, "his friend Sarah" will be a plausible interlocutor.
- Generating conversations grounded in narratives
- With the narrative and speakers as input, we prompt the PLM to generate a likely conversation happening in the scene.
- The generated narratives act as the scene description or background context, and the speakers are the actors in the scene.
- We append the first speaker as an utterance prefix to the prompt.
- An example of the final prompt is "[narrative] The following is a long in-depth conversation happening in the scene between David and his friend Sarah with multiple turns.\nDavid:".

### Validating Narratives and Conversations with Commonsense Knowledge
- We perform an automatic validation of the generated dialogues to check whether or not the seed commonsense triple is meaningfully implied by the narrative+conversation.
- We ask the PLM itself to judge whether or not the seed commonsense triple is implied by the conversation.
- We collect SODA (SOcial DiAlogues), a large-scale highquality conversation dataset covering a wide range of social interactions.

### Postprocessing the Conversations
- Basic filtering: Uses lexical pattern matching to filter out conversations with erroneous patterns, such as repetition and omission of speaker prefixes.
- Safety filtering: Discards all conversations marked as needing intervention (usually critical situations, e.g., crimes, emergencies).
- Commonsense filtering: The automatic evaluation described in §2.5 is run over all remaining SODA instances: 66%, 95%, and 68% of filtered conversations are identified by InstructGPT as containing the full commonsense triple, the head event, and the relation-tail event, respectively: in total, 1,003,595 conversations are identified as fully encapsulating the seed commonsense knowledge.
- Name bias mitigation: Replaces all names in conversations with Top-10K names of US SSN applicants.
- High quality: Human raters judge SODA as better in quality compared to both DailyDialog and BlendedSkillTalk across all axes by a margin, see Figure 2.

### Contextualization is Important
- SODA is a model that is trained to generate conversations that are more interesting and specific than conversations that are generated without context.
- The effect of contextualization is significant, and human evaluators prefer conversations that are generated with context over conversations that are generated without context.
- COSMO is a model that is trained to generate conversations that are more natural and consistent than conversations that are generated without context.
- COSMO is also more specific than conversations that are generated without context.
- COSMO is able to outperform other conversational agents on social conversation datasets.

### Out-of-domain Setting
- COSMO outperforms all other existing models with a significant margin across all aspects
- Human judges prefer COSMO's responses even over the original gold responses in the dataset, suggesting that dialogue models trained on SODA can lead to high generalizability and naturalness

### One-sided Out-of-domain Setting
- COSMO outperforms BlenderBot on BlenderBot's training domain (BlenderBot also shows relatively low performance on SODA)
- SODA contains patterns not present in existing dialogue datasets

### In-domain Setting
- COSMO is more specific and hence more favored than the responses from its teacher model.
- COSMO is on par with ChatGPT in this setting in terms of overall quality.
- The focus of our work is on modeling natural human conversations rather than knowledge-enhanced responses for informativeness.

## Related Work
- Existing dialogue datasets generally derive from one of the three sources: (1) Online learning websites/textbooks (Li et al., 2017) or movie/drama scripts (Danescu-Niculescu-Mizil and Lee, 2011);dialogues for language learners may lack complex language usage and movie scripts may depict less natural scenes compared to day-to-day scenarios.
- Crowdsourcing (Rashkin et al., 2019;Zhou et al., 2021;Tran et al., 2022): instructing human annotators to write dialogues is a process potentially prone to collecting responses that are somewhat short/dull due to incentive misalignment between researchers and crowdworkers (Zhou et al., 2022).
- Noisy web conversations such as Reddit comments (Baumgartner et al., 2020) and Twitter (Ritter et al., 2011); while widely used in dialogue agent pre-training stage due to their scale, these may represent different conversational frames vs. dyadic social conversations.
- SODA contributes meaningfully to the suite of existing corpora via improved scale, quality, and contextualization.
- Augmented Dialogue Datasets with PLMs. Several studies have used pre-trained large language models (PLM) to augment dialogue datasets. GPT-3 has also been used to help simulate task-oriented dialogues (Li et al., 2022) on a small scale.
- Others also augment dialogues with additional annotations -e.g., commonsense inferences (Zhou et al., 2022) or task-specific labels (Kulhánek et al., 2021;Chen et al., 2022).
- Compared to existing works, we generate full conversations from scratch by contextualizing social commonsense knowledge in a significantly large-scale, rather than adding new responses/annotations to existing dialogues.

## Conclusion
- We presented SODA, the first million-scale dialogue dataset covering a wide range of social interactions.
- Our dataset is not only orders of magnitude larger than several popular dialogue datasets; it is also perceived to be significantly better than them across multiple aspects (e.g., naturalness, specificity, consistency).
- With SODA, we trained a conversation model COSMO that can generalize significantly better than existing models to unseen dialogues; and generate responses that are even more preferred than ground-truth responses of existing dataset.
- We hope our work can alleviate the data scarcity issue in the dialogue field and expand it by exploring more diverse conversation distillation methods in the era of large-scale pre-trained language models.
- Potential future directions include applying CO 3 to multi-party conversations, task-oriented dialogues, and training more generalizable dialogue evaluation methods on top of the distilled conversations.
- Precautions taken during dataset construction. Mining content from PLMs might surface or even amplify harmful content within these models, such as biases and private information.
- With the goal of mitigating such danger, we take particular precautions to vet the safety of the distilled conversations. First, previous studies have shown that human names commonly associated with certain gender and/or ethnicity result in biases in conversations produced by state-of-the-art dialog systems (Smith and Williams, 2021), such as BlenderBot (Roller et al., 2021). To diversify the name representations, we draw a wide range of common names representative of different gender and race identities from the US SSN name repository. Furthermore, to minimize potential harmful content from PLMs, we filter generated dialogues by Canary, a dialogue safety detector model (Kim et al., 2022a), and Rewire API, a publicly available API for toxic content detection,12 to remove dialogues with potentially toxic and dangerous content.
- Our methods to pre-empt potential harmful content may not catch everything. For example, even with our diverse pool of names, there is still a focus on common names across gender and race, running the risk of misrepresenting marginalized groups. Similarly, no existing dialogue safety module or off-the-shelf toxicity detector is perfect at capturing all potentially harmful content.
- We strongly encourage future research along these directions to push the boundary of safe and responsible application usage of PLMs.
- During manual validation of commonsense and human evaluation, we compensate workers with hourly wage of $15.
- Limitation of the current dataset and future work. Here, we note some limitations of our work and suggest future directions. First, the dialogues in SODA are two-party only for now; because our framework also allows multi-party dialogue generation, we plan to explore this promising direction in the future. Additionally, because annotator biases might arise from the pool of annotators we recruit: we subselected annotators from a specific platform using specific filters which may cause unintended biases. We hope future work will extend human evaluation to have potentially more annotator diversity. Finally, our choice of pre-trained LM (Instruct-GPT) will likely affect the types of dialogues created. Future investigation may look into other potential PLM as sources to diversify the types and content of dialogues being generated.
- Intent of technology and AI regulation. We want to stress that the intention of our work is not to build AI systems to replace humans. Instead, we want to build better assistive technologies, as chatbots are increasingly used in user-AI interactions and augment/assist human-human conversations.
