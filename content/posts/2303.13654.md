---
title: "NEWTON: Neural View-Centric Mapping for On-the-Fly Large-Scale SLAM"
date: 2023-03-23T20:22:01.000Z
author: "Hidenobu Matsuki, Keisuke Tateno, Michael Niemeyer, Federic Tombari"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2303-13654v1.webp" # image path/url
    alt: "NEWTON: Neural View-Centric Mapping for On-the-Fly Large-Scale SLAM" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2303.13654)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2303.13654).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/newton-neural-view-centric-mapping-for-on-the).

# Abstract
- Neural field-based 3D representations are used in SLAM systems.
- SLAM systems rely on a world-centric map representation.
- Prior knowledge of the scene is required for world-centric representation.
- NEWTON is a view-centric mapping method that dynamically constructs neural fields.
- NEWTON enables camera pose updates and scene boundary updates.
- NEWTON outperforms existing world-centric neural field-based SLAM systems.

# Paper Content

## Introduction
- Real-time scene capture is essential for scene understanding and interaction.
- Neural field-based representations have enabled progress in 3D vision applications.
- Existing approaches rely on world-centric representations which cannot handle large-scale real-world scenarios.
- NEWTON is a view-centric neural field-based representation which can handle dynamic input data streams in real-time.
- NEWTON combines mapping system with camera tracker of a loop-closable SLAM system.

## Related work
- Neural fields are used for 3D reconstruction and view synthesis
- Recent works propose to use spatially-distributed grid features with MLPs
- Visual SLAM systems can be classified into world-centric and view-centric approaches
- World-centric approaches assume rich scene information is provided
- View-centric representations construct the scene on a per-view basis
- Neural fields can be used as local models for view-centric representations

## Method
- Memory size of iMAP is 1.02 MB
- Memory size of NICE-SLAM is 12.0 MB
- Unbounded Instant-NGP can be used for camera pose tracking
- Performance of Unbounded Instant-NGP is less affected by loop closure than the baseline model

### Camera tracking
- Proposed neural field-based mapping approach runs in combination with camera tracking component
- Input RGB or RGB-D stream is fed to tracking component which returns camera poses and co-visibility graph
- ORB-SLAM used as it provides reliable pose estimation regardless of scene scale and domain
- Mapping system takes input keyframe poses and images as training frames and assigns them to NeRF models
- Each model is defined in local coordinate system of selected keyframe, can be flexibly adjusted to pose update

### Scene representation
- Represent scenes with multiple NeRF models in local coordinate system of keyframes
- Represent NeRF models as multi-resolution feature grid in spherical coordinate system
- Convert input location from Cartesian to spherical coordinates
- Allocate features evenly in inverse depth space
- Representation not limited by frustum boundary
- Representation can capture unbounded scenes
- Use classic volume rendering techniques to render pixel color
- Train NeRF models by minimizing MSE loss against ground truth color
- Incorporate distortion regularization and proposal network

### Dynamic neural field allocation and training
- When a new keyframe is created, covisibility between the keyframe and existing training frames is checked.
- Each training frame is assigned to a single model ID.
- If the input keyframe is further away than a distance threshold, a new model is created.
- Feature information from the previous model is propagated to the new one.
- For novel view synthesis, multiple NeRF models are queried and images are blended in 2D image space.

### Experimental setup
- Evaluated performance when dynamic pose updates are required
- Baseline comparison against 3 state-of-the-art neural field-based SLAM systems
- Ablation study of various components of the method
- Trained on single NVIDIA RTX3090Ti GPU
- 7 real-world scenes used for testing
- Metrics reported for predicted appearance and geometry

### On-the-fly mapping
- NEWTON is compared to a world-centric variant of the approach with a single NeRF model
- Input for both representations is ORB-SLAM's trajectory from RGBD
- 10% of ORB-SLAM's localized keyframes are used as test frames and excluded from training
- Reconstruction metrics of all test views are measured for a certain interval
- NeRFStudio's preprocessing pipeline is used and the scene is rescaled to fit the default model and ray parameters
- Quantitative and qualitative results show that NEWTON is minimally affected by loop closure while the World-Centric Single Model's performance drops significantly
- Time series plot shows stronger robustness of NEWTON to dynamic pose update and lower deviation values compared to the baseline

### Baseline comparison
- Compare method to state-of-the-art neural field based SLAM methods
- No drift correction by loop closure
- Use ORB-SLAM trajectory as ground truth for evaluation
- Better performance than other methods
- View synthesis quality is significantly better
- Limitations of existing world-centric neural field-based mapping approaches
- Can use large-scale Monocular SLAM system with RGB streams as input
- Feature propagation improves all metrics
- Flexible loop closure handling and effective feature allocation
- Robustness and flexibility to large pose updates by loop closure
- Superior performance on real-world large-scale scenes
