---
title: "Large Language Models as Corporate Lobbyists"
date: 2023-01-03T16:25:52.000Z
author: "John J. Nay"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2301-01181v4.webp" # image path/url
    alt: "Large Language Models as Corporate Lobbyists" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2301.01181)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2301.01181).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/large-language-models-as-corporate-lobbyists).

# Abstract
- The autoregressive large language model (OpenAI's text-davinci-003) determines if proposed U.S. Congressional bills are relevant to specific public companies and provides explanations and confidence levels.
- For the bills the model deems as relevant, the model drafts a letter to the sponsor of the bill in an attempt to persuade the congressperson to make changes to the proposed legislation.
- We use hundreds of novel ground-truth labels of the relevance of a bill to a company to benchmark the performance of the model, which outperforms the baseline of predicting the most common outcome of irrelevance.
- We also benchmark the performance of the previous OpenAI GPT-3 model (text-davinci-002), which was the state-of-the-art model on many academic natural language tasks until text-davinci-003 was recently released. The performance of text-davinci-002 is worse than simply always predicting that a bill is irrelevant to a company.

# Paper Content

## I. INTRODUCTION
- Law-making should be exclusively reserved for the human-driven democratic processes expressing uniquely human values.
- Part of that process currentlylike it or notinvolves human lobbying.
- A novel concern we raise is that, with additional advancements in Artificial Intelligence (AI) capabilities and agentic deployments of AI systems (even without the agents having instrumental power-seeking goals per se) influencing law through lobbying may be the first crack in AI influence on public policy.
- For sufficiently advanced AI, law serves as a goldmine of insights on how to behave.
- Law provides detailed examples of the application of shared principles, generalizable precedents with explanations, and legal experts to solicit model fine-tuning feedback to embed in AI a comprehension of societal goals.
- As a data source to learn automatically updated and verified societal values, law provides the blueprint for how AI agents can take actions aligned with human preferences.
- If AI begins to influence law in a manner that is not a direct extension of human intentions, this threatens the critical role that law as information could play in aligning AI with humans.
- This paper explores how this is increasingly a possibility.
- Initially, AI is being used to simply augment human lobbyists. However, there may be a slow creep of less and less human oversight over automated assessments of the pros and cons of policy ideas, and the persuasive AI-generated written communication to regulatory agencies and Congressional staffers.
- The most ambitious goal of research at the intersection of AI and law should be to computationally encode and embed existing legal concepts and standards into AI.
- We should stop short of AI making law.
- The positive implications of this normative stance on the scope of the AI & Law intersection are that our laws encapsulate human views and can thus be used to inform AI what humans value and how to be aligned.
- ut how do we define "making law"?
- These are all open legal questions, but we wanted to first see how close we are to AI lobbyists being a real concern.

## II. EXAMPLE: GPT AS LOBBYIST

## CONFIDENCE: 95
- The LLM is prompted to write letters on behalf of the company
- The company supports the bill
- The bill includes provisions that would provide additional incentives for pharmaceutical companies to negotiate with the CMS
- The company believes that this would help to ensure that the prices of drugs are kept in check and that Medicare beneficiaries have access to the medications they need

## Sincerely, [Name], General Counsel Alkermes Plc

## III. A PROBLEM FOR SOCIETY-AI ALIGNMENT
- AI may reduce human time spent on rote tasks, freeing up human effort for higher-level tasks such as strategizing on the best means to implement policy goals in legislation and regulation.
- AI may reduce the costs of lobbying-related activities in a way that makes them differentially more affordable to non-profits and individual citizens relative to well-funded organizations, which could "democratize" some aspects of influence (arguably campaign donations are more influential than any natural-language-based task discussed in this paper).
- There are obvious potential downsides if AI systems develop instrumental power-seeking goals and use lobbying as a means to effectuate misaligned policies.
- The potential, less obvious, downside we focus on here is that extended LLM capabilities may eventually enable AI systems to influence public policy toward outcomes that are not reflective of citizen's actual preferences.
- This does not imply the existence of a strongly goal-directed agentic AI. Rather, this may be a slow drift, or otherwise emergent phenomena.
- AI lobbying activities could, in an uncoordinated manner, nudge the discourse toward policies that are unaligned with what traditional human-driven lobbying activities would have pursued.
- This is problematic in itself, but also insofar as it disrupts the process of the only democratically determined knowledge base of societal values (law) informing AI what not to do.
- Policy-making embeds human values into rules and standards.
- Legislation expresses information about the values of citizens, "for example, by banning employment discrimination against LGBT workers, the legislature may communicate pervasive attitudes against such employment practices."
- And, "the Endangered Species Act has a special salience as a symbol of a certain conception of the relationship between human beings and their environment, and emissions trading systems are frequently challenged because they are said to 'make a statement' that reflects an inappropriate valuation of the environment."
- egislation is currently largely reflective of citizen beliefs.
- The second-best source of citizen attitudes is arguably a poll, but polls are only conducted on mainstream issues and the results are highly sensitive to their wording and sampling techniques.
- Legislation expresses higher fidelity, more comprehensive, and trustworthy information because the legislators "risk their jobs by defying public opinion or simply guessing wrong about it. We may think of legislation therefore as a handy aggregation of the polling data on which the legislators relied, weighted according to their expert opinion of each poll's reliability."
- Legislation and associated agency rule-making also express a significant amount of information about the risk preferences and risk tradeoff views of citizens, "for example, by prohibiting the use of cell phones while driving, legislators may reveal their beliefs that this combination of activities seriously risks a traffic accident."
- In many ways, public law provides the evolving information AI systems need for societal alignment.
- However, if AI significantly influences the law itself, the only available democratically legitimate societal-AI alignment process would be corrupted.
