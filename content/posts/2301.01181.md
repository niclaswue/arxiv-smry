---
title: "Large Language Models as Corporate Lobbyists"
date: 2023-01-03T16:25:52.000Z
author: "John J. Nay"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2301-01181v4.webp" # image path/url
    alt: "Large Language Models as Corporate Lobbyists" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2301.01181)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2301.01181).


# Abstract
- The autoregressive large language model (OpenAI's text-davinci-003) determines if proposed U.S. Congressional bills are relevant to specific public companies and provides explanations and confidence levels.
- For the bills the model deems as relevant, the model drafts a letter to the sponsor of the bill in an attempt to persuade the congressperson to make changes to the proposed legislation.
- We use hundreds of novel ground-truth labels of the relevance of a bill to a company to benchmark the performance of the model, which outperforms the baseline of predicting the most common outcome of irrelevance.
- We also benchmark the performance of the previous OpenAI GPT-3 model (text-davinci-002), which was the state-of-the-art model on many academic natural language tasks until text-davinci-003 was recently released. The performance of text-davinci-002 is worse than simply always predicting that a bill is irrelevant to a company.

# Paper Content

## I. INTRODUCTION

## II. EXAMPLE: GPT AS LOBBYIST

## CONFIDENCE: 95
- The LLM is prompted to write letters on behalf of the company
- The company supports the bill
- The bill includes provisions that would incentivize pharmaceutical companies to negotiate with the CMS
- The company believes that this would help to ensure that the prices of drugs are kept in check and that Medicare beneficiaries have access to the medications they need.

## Sincerely, [Name], General Counsel Alkermes Plc

## III. A PROBLEM FOR SOCIETY-AI ALIGNMENT
- Artificial intelligence may reduce the amount of time spent on rote tasks, freeing up human effort for higher-level tasks such as strategizing on the best means to implement policy goals in legislation and regulation.
- This may reduce the costs of lobbying-related activities in a way that makes them differentially more affordable to non-profits and individual citizens relative to well-funded organizations, which could "democratize" some aspects of influence (arguably campaign donations are more influential than any natural-language-based task discussed in this paper).
- There are obvious potential downsides if AI systems develop instrumental power-seeking goals and use lobbying as a means to effectuate misaligned policies.
- The potential, less obvious, downside we focus on here is that extended LLM capabilities may eventually enable AI systems to influence public policy toward outcomes that are not reflective of citizen's actual preferences.
- This does not imply the existence of a strongly goal-directed agentic AI. Rather, this may be a slow drift, or otherwise emergent phenomena.
- AI lobbying activities could, in an uncoordinated manner, nudge the discourse toward policies that are unaligned with what traditional human-driven lobbying activities would have pursued. This is problematic in itself, but also insofar as it disrupts the process of the only democratically determined knowledge base of societal values (law) informing AI what not to do.
- Policy-making embeds human values into rules and standards. Legislation expresses information about the values of citizens, "for example, by banning employment discrimination against LGBT workers, the legislature may communicate pervasive attitudes against such employment practices."
- And, "the Endangered Species Act has a special salience as a symbol of a certain conception of the relationship between human beings and their environment, and emissions trading systems are frequently challenged because they are said to 'make a statement' that reflects an inappropriate valuation of the environment."
- Legislation is currently largely reflective of citizen beliefs.
- The second-best source of citizen attitudes is arguably a poll, but polls are only conducted on mainstream issues and the results are highly sensitive to their wording and sampling techniques.
- Legislation expresses higher fidelity, more comprehensive, and trustworthy information because the legislators "risk their jobs by defying public opinion or simply guessing wrong about it. We may think of legislation therefore as a handy aggregation of the polling data on which the legislators relied, weighted according to their expert opinion of each poll's reliability."
- Policy-making also expresses a significant amount of information about the risk preferences and risk tradeoff views of citizens, "for example, by prohibiting the use of cell phones while driving, legislators may reveal their beliefs that this combination of activities seriously risks a traffic accident."
- In many ways, public law provides the evolving information AI systems need for societal alignment.
- However, if AI significantly influences the law itself, the only available democratically legitimate societal-AI alignment process would be corrupted.
