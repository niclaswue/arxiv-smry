---
title: "ImMesh: An Immediate LiDAR Localization and Meshing Framework"
date: 2023-01-12T18:43:16.000Z
author: "Jiarong Lin, Chongjiang Yuan, Yixi Cai, Haotian Li, Yuying Zou and 2 others"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2301-05206v1.webp" # image path/url
    alt: "ImMesh: An Immediate LiDAR Localization and Meshing Framework" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2301.05206)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2301.05206).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/immesh-an-immediate-lidar-localization-and).

# Abstract
- Proposed framework for simultaneous localization and meshing in real-time
- Framework consists of four tightly-coupled modules
- Key contribution is meshing module which uses hierarchical voxels structure
- Meshing operation uses dimension reduction and incremental reconstruction of triangle facets
- Code publicly available on GitHub

# Paper Content

## I. introduction
- 3D applications such as metaverse, VR/AR, video games, and physical simulator have enriched human lifestyle and boosted productive efficiency
- Triangle mesh is a fundamental tool for objects modeling in most existing 3D applications
- Triangle mesh simplifies the process and boosts the speed of rendering and raytracing, and plays an irreplaceable role in collision detection, rigid-body dynamics, dense mapping and surveying, sensor simulation, etc.
- Most existing mesh is manufactured by skillful 3D modelers with the help of computer-aided design (CAD) software
- Developing an efficient mesh method that could reconstruct large scenes in real-time is a hot topic in the community of 3D reconstruction
- Performing mesh reconstruction in real-time is important for data collection, productivity, and real-time applications
- A novel system is proposed that can estimate the sensor pose and reconstruct the mesh of the surrounding environment both online
- The system implements a novel mesh reconstruction approach that efficiently reconstructs the mesh in an incremental manner
- The system is evaluated with four public datasets and compared against existing baselines
- Two practical examples are presented to demonstrate how real-time meshing can be applied in potential applications
- The system is made publicly available on GitHub

## Ii. related works
- Mesh reconstruction based on 3D point cloud
- Two classes of methods: offline and online

## A. offline mesh reconstruction
- Offline methods require a global map in prior
- Poisson surface reconstruction is used to build the mesh
- Delaunay triangulation and graph cut are used to generate the mesh
- Ball-pivoting algorithm is not the first choice due to lower precision and worse efficiency
- ImMesh can perform online in an incremental manner

## B. online mesh reconstruction 1) voxel volume-based methods (tsdf-based):
- Online mesh reconstruction method is predominated by TSDF-based methods
- TSDF-based methods represent scene in voxel volumetric theme
- Two-step pipeline: SDF update followed by mesh extraction
- Popularized by KinectFusion
- ImMesh reconstructs mesh in one step
- Outputs mesh in scan-rate
- Real-time performance on standard CPU
- Exploits high-accuracy LiDAR points
- Surfel-based mesh reconstruction also popular
- ImMesh reconstructs triangle mesh in incremental manner
- Real-time performance in large-scale scenes
- Delicately designed for efficiency

## Iv. map structures
- Designed four data structures
- Structure of meshing vertices
- Structure of triangle facets
- Incremental kd-Tree for kNN search and downsampling
- Hierarchical-voxels structure representing 3D space

## A. mesh vertices
- Mesh vertices are points that make up the shape of a mesh
- Mesh vertices are stored in a global list
- Each entry in the list contains the 3D position of the vertex, its index, and a list of pointers to triangles that contain the vertex

## B. triangle facets
- Triangle facets describe small surfaces in the reconstructed scene.
- Triangle facets contain the indices of three points, the center and normal (both in the global frame).

## C. incremental kd-tree (ikd-tree)
- Maintain an incremental kd-tree for fast kNN search of mesh vertices
- Update tree with newly coming points in an incremental manner
- Use ikd-Tree to downsample point cloud density and enable vertex dilation operation

## D. hierarchical voxels

## V. receiver and localization
- Receiver module processes and packages input sensor data
- Data is converted to unified format compatible with different LiDARs
- IMU measurements are packaged within LiDAR frame
- Localization module estimates 6 DoF sensor poses and registers points to map
- Mesh is not used in localization module due to efficiency and accuracy

## A. voxel map construction
- Representing the environment with a probabilistic representation
- Constructing voxel-volumetric maps in a coarseto-fine adaptive resolution manner
- Real-time reconstructing the triangle mesh of the scene
- Motion distortion compensated with an IMU backward propagation
- LiDAR points stored in voxels
- Distribution of points inside voxel calculated with a covariance matrix
- If minimum eigenvalue of points covariance matrix is less than a specified threshold, points form a planar feature
- Representing planar feature with its normal vector and a point that lies in the plane

## B. state estimation

## C. point cloud registration
- Perform point cloud registration to transform each measurement point from LiDAR frame to global frame
- Registered point cloud used for: publishing to other applications, updating probabilistic voxel map, and appending to map structure
- Update voxel map by updating point distributions, planar parameters, and correspondent uncertainties
- Append mesh vertices by downsampling registered LiDAR point cloud and using ikd-Tree to keep minimum distance between meshing points
- Status flag of voxel set as activated to notify meshing module for re-meshing operation

## Vi. meshing
- Meshing module reconstructs triangle mesh from 3D registered LiDAR points
- LiDAR points have high positional accuracy and shape the mesh's geometry

## A. goals and requirements
- Problem of online mesh reconstruction is to seek a way to reconstruct triangle facets with a growing 3D point set
- Require precision, hole-less mesh, avoid sliver triangles, and be computationally efficient
- Sliver triangles cause errors in numerical analysis and loss of accuracy in calculating pixel values near sharp angles

## B. challenges and approaches
- Proposed system based on deep analysis of challenges
- Challenges and corresponding scientific approaches
- Incremental mesh reconstruction with mechanism similar to git
- Retrieve data of voxels with new mesh vertices
- Efficient voxel-wise meshing algorithm
- Perform meshing operation in 2D
- Perform 3D point cloud dilation to erode gaps between voxels

## D. dimensional reduction by projection

## 3d meshing

## E. voxel-wise meshing with pull, commit and push
- Pull step retrieves triangle facets from map structure
- Pull step uses Algorithm 2 to calculate center of triangle facets

## 9
- Add a pointer to triangle list of points Vα, V β , Vγ
- Remove pointer from triangle list of points Vα, V β , Vγ

## 13
- Find L1-Voxel V1 with CenterpT Gjq
- Set status flag of V1 to Sync-required

## F. parallelism
- Implemented parallelism to improve real-time performance
- Localization module and meshing module can run in parallel, except for point cloud registration
- Meshing operations of different voxels are standalone and do not conflict

## G. the full meshing algorithm
- Algorithm 5 outlines the full meshing processes
- Algorithm 5 is the conclusion of the paper

## Algorithm 5: the full meshing process of each update of lidar scan
- Set of L2-Voxels is inputted
- V2 is used to represent the set of L2-Voxels

## Vii. broadcaster
- Broadcaster module publishes state estimating and mapping results
- Broadcaster module can rasterize triangle meshes into depth image with user-defined resolution and FoV

## A. broadcast of odometry
- 6-dof sensor pose is published with LiDAR frame starting timestamp at LiDAR sampling rate
- Odometry is published from IMU preintegration at IMU sampling rate if IMU source is available

## B. broadcast of triangle facets
- Triangle facets stored in unstructured hash table
- Background thread copies triangle facets from hash table to structured array for broadcasting
- Sync-required voxels marked as synced after copying
- Triangle facets published to other applications

## C. rasterization of depth image
- Utilizes triangle facets to rasterize a depth image
- Unprojecting 3D points from depth image to reinforce LiDAR point cloud

## Viii. experiments and results
- ImMesh performance is evaluated extensively
- Localization module is built on previous work with no modifications
- Results from previous work can be referred to for localization accuracy
- Experiments evaluate meshing ability, focusing on runtime performance and accuracy

## A. experiment-1: immesh for immediate mesh reconstruction

## B. experiment-2: extensive evaluation of immesh on public datasets with various types of lidar in different scenes
- ImMesh achieves real-time performance on a standard multi-core CPU
- Tested on four public datasets with different scenarios and LiDARs
- Parameters adjusted for mechanical and solid-state LiDARs
- Time consumption closely related to density of input LiDAR scan
- Average time consumption of localization and meshing bounded in acceptable value

## C. experiment-3: quantitative evaluation of meshing accuracy
- Experiment to compare ImMesh with existing mesh reconstruction methods
- Used simulated data with 4 zones of equal size
- 3 trajectories with different sampling poses
- Evaluation criteria: point-to-plane distance and re-rendering depth error
- Experiment setup: desktop PC with Intel i7-9700K CPU, 64Gb RAM, and Nvidia 2080 Ti GPU
- ImMesh and TSDF used online, Delaunay triangulation and graph cut and Poisson surface reconstruction used offline
- Results: ImMesh and TSDF had comparative runtime performance, Del and Poi had two orders of magnitude larger
- Evaluation of meshing accuracy: ImMesh had highest computation efficiency

## 4) result and analysis of meshing accuracy:
- All candidates show satisfying accuracy in reconstructing simple planar and curvy models
- Accuracy drops in complex scenes
- Accuracy drops as point cloud resolution decreases, especially for TSDF-based method
- Poi shows bad accuracy in complex scenes due to unwanted facets
- Del achieves best precision with lowest depth error
- ImMesh performs closely to Del, followed by Poi and TSDF
- TSDF accuracy decreases sharply with lower resolution due to holes in mesh
- Del is best choice for offline applications, ImMesh is best choice for real-time applications

## D. application-1: immesh for lidar point cloud reinforcement
- ImMesh can reconstruct triangle mesh in real-time
- Depth images can be rasterized from the reconstructed facets
- Point clouds of a regular pattern can be retrieved with wider FoV and denser distribution
- LiDAR point reinforcement process demonstrated with Livox Avia LiDAR
- Reinforced points of denser density and wider FoV enable navigation algorithms to achieve better planning performance
- Provides unified point cloud outputs neglecting scanning patterns of different LiDARs
- ImMesh used for rapid, lossless texture reconstruction with a DJI M300 drone platform
- Reconstruction cost only 686s, with 328s for ImMesh, 330s for R3 LIVE++ and 28s for texturing
- Lossless texture reconstruction method, preserving geometry structure of very high accuracy

## Ix. conclusions and future work
- Proposed novel meshing framework ImMesh for simultaneous localization and meshing in real-time
- First work to reconstruct triangle mesh of large-scale scene in incremental manner in real-time
- Localization module uses iterated Kalman filter to maximize posterior
- Meshing module uses hierarchical voxel data structure to find voxels containing newly appended vertices
- Meshing problem converted to 2D by performing dimension reduction
- Triangle facets incrementally reconstructed with pull, commit, and push steps
- Verified overall performance with live video demonstrations
- Extensively tested ImMesh with four public datasets
- Horizontally evaluated meshing performance of ImMesh
- ImMesh applied for LiDAR point cloud reinforcement and texture reconstruction of scenes
- Code publicly available on GitHub
- Future work to make ImMesh and R 3 LIVE work in more tightly combined style
- Future work to integrate loop detection based on LiDAR point cloud
