---
title: "How to disagree well: Investigating the dispute tactics used on Wikipedia"
date: 2022-12-16T09:01:19.000Z
author: "Christine de Kock, Tom Stafford, Andreas Vlachos"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2212-08353v1.webp" # image path/url
    alt: "How to disagree well: Investigating the dispute tactics used on Wikipedia" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2212.08353)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2212.08353).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/how-to-disagree-well-investigating-the).

# Abstract

# Paper Content

## Introduction
- Disagreements are pervasive in online communication
- While usually perceived as a negative phenomenon, research in psychology has shown that debate and disagreement can promote beliefs that are better supported by evidence
- Hallsson and Kappel (2020) argue that, in the ideal case, a range of arguments are considered for both sides, increasing the participants' ability to find good arguments in defence of a view and to critique reasons against it, and thereby forcing one to interact with reasoning and evidence which may otherwise be discarded due to confirmation bias
- Prior work in NLP has investigated detecting negative artefacts of online disagreements such as personal attacks or hate speech
- e.g. Wulczyn et al. (2017) and Waseem and Hovy (2016)
- Research in argumentation mining instead looks at identifying argument structures (Lawrence and Reed, 2020) and inferring the quality of arguments (Habernal and Gurevych, 2016), often focusing on classical theories of argumentation (e.g. Aristotelian) which do not include less desirable aspects such as personal attacks
- However, real world disagreements often contain both well-structured arguments and attacks, in addition to other dialogue acts, such as asking for and providing clarification
- In this work, we propose a framework of dispute tactics consisting of rebuttal and coordination strategies, denoting the role of a particular utterance in the context of a disagreement discussion
- We build on the disagreement hierarchy proposed by Graham (2008), which includes a preferential ordering between different rebuttal tactics
- We introduce WikiTactics 1 : a set of 213 disputes (comprising 3,865 utterances) on Wikipedia Talk pages, manually annotated with the dispute tactics employed in the process of resolving a disagreement between editors
- These multiturn, multiparty conversations are sourced from the WikiDisputes dataset (De Kock and Vlachos, 2021) which is annotated according to whether the dispute was resolved without the need for a moderator
- An example of such a conversation is shown in Fig 1
- Using this framework and data, we investigate a number of research questions related to disagreements
- Firstly, we find that a lower mean rebuttal level in a disagreement is correlated with less constructive dispute resolutions
- Individual users are found to utilise a range of rebuttal levels more often than adhering to only 1
- We quantify the use of mirroring in disagreements by observing how users deviate from their own mean rebuttal level depending on the rebuttal level used in a conversation, finding that mirroring takes place in 57% of cases
- We further develop models for predicting the dispute tactics used in an utterance as a multilabel classification task, experimenting with both the binary relevance and label powerset approaches, as well as models with and without conversation context
- Our best model is a transformer-based model which uses a label powerset approach and context
- A statistically significant improvement is gained by taking into account the preferential ordering of the rebuttal tactics defined in our scheme using multi-task training
- Finally, we illustrate that these annotations can be leveraged to improve performance on the task of predicting whether a dispute will be resolved without escalating to a moderator

## Online disagreements
- Wikipedia Talk pages are a popular source for NLP studies of goal-oriented discussions
- The Talk pages are linked to specific articles and are used to coordinate edits and in some cases to resolve disputes
- WikiDisputes (De Kock and Vlachos, 2021) is a dataset of Talk page discussions tagged as "disputes" by editors
- The dataset provides an "escalation" label for each dispute: under the Wikipedia dispute resolution policy, disputes which cannot be resolved by editors themselves are escalated to mediation, which is considered to be a proxy for constructiveness
- Wikipedia recommends the hierarchy of disagreement formulated by Graham (2008) as a guide for constructive dispute resolution
- Graham's hierarchy has been used as a framework for research in various fields, including healthcare (Cope, 2015), education (Phelps et al., 2019) and sociology (Neven et al., 2019)
- Within NLP, Tang and Wang (2017) have used this taxonomy in combination with LDA topic models to distantly annotate and analyse the rationality of online discussions
- Despite its popularity, this hierarchy has not been verified empirically
- Individual levels of this hierarchy have been considered in prior work
- For instance, name-calling and ad hominem attacks (levels 0 and 1) can be considered subsets of personal attacks (Waseem and Hovy, 2016;Chang and Danescu-Niculescu-Mizil, 2019)
- Counterarguments (level 4) and refutations (level 5) are described in terms of arguments and evidence, a topic that has received extensive attention in the field of argumentation mining, which seeks to categorise different elements of an argument as claim or premise (see, e.g. Lawrence and Reed (2020))
- Contradiction (level 3), described as stating the opposing case, is related to the task of stance detection (Küçük and Can, 2020)
- Graham's hierarchy combines these different concepts and proposes that there is an preferential ordering among them which correlates with more favourable disagreement outcomes
- Walker et al. (2012) also focus on online disagreements and introduced the Internet Arguments Corpus (IAC)
- This corpus contains utteranceresponse pairs annotated for the degree of agreement as well as whether the response is emotional versus factual, respectful versus insulting, asking questions vs asserting, and negotiating versus attack
- Some of these markers can be mapped to Graham's hierarchy; however, Walker et al. (2012) consider pairs of utterances whereas our aim is to understand disagreements as a multiturn conversation
- Notable is their taxonomy illustrating that different disagreement markers can be used in combination: an utterance may be insulting and attacking while still being factual. It also captures the fact that within a disagreement, all discussion is not necessarily aimed at countering a proposition by an opponent; negotiating compromises and asking questions plays an important part in how disputes are resolved
- Another taxonomy that considers concepts related to Graham's hierarchy is that of Benesch et al. (2016), on the topic of counterspeech
- For instance, "presentation of facts to correct misstatements or misperceptions" is similar to refutation, the top level of the rebuttal hierarchy
- "Denouncing hateful speech" is similar to contradiction, and "hostile denouncing" is similar to name-calling and ad hominem attacks

### Disagreement annotation schema
- In this work, we distinguish between two broad categories of dispute tactics: utterances aimed at countering the point of an opponent (which we term rebuttal tactics) and attempts to promote understanding and consensus (referred to as coordination tactics).
- For rebuttal tactics, Graham's hierarchy provides a useful basis. We expand the original taxonomy to include categories for "repeated argument" and "attempted derailing or off-topic comments".
- The taxonomy of Ferschke et al. (2012) contains the "information content" class which encapsulates providing, seeking or correcting information; similarly, we annotate both asking questions and providing information.
- As conversations on this platform are inherently goal-oriented, some discussion is often expended on coordinating edits (Viegas et al., 2007;Schneider et al., 2011); we include a class to capture this.
- We further use contextualisation to describe the "opening statement" of a dispute on Wikipedia).
- As discussed in Sec 2, the IAC also accounts for negotiating compromises, which is encouraged by the platform's dispute resolution policy.
- We also annotate for this category.
- Finally, we annotate three "retreat" moves: saying I don't know, conceding or recanting of a position, and giving up or bailing out. Full definitions for these classes are contained in Table 4 in App C.

### Data annotation
- A set of 213 disputes were annotated
- The median conversation length is 21 utterances (minimum 5, maximum 44), with an average utterance length of 54 tokens
- The average number of speakers is 4
- Three initial rounds of pilot annotation were carried out to determine the appropriateness of the taxonomy for the data
- During each round, five disputes (totalling 194 utterances) were annotated independently by an experienced professional annotator and one of the authors
- Following each round, the annotations were compared and definitions expanded to reduce uncertainty
- The agreement scores after each round are shown in Table 5 in App D
- The Cohen's κ improved after each pilot round, as did the Pearson's r
- Frequent label combinations are discussed in Sec 4.2

## Analysing dispute tactics
- Does the mean rebuttal level in a conversation correlate with escalation?
- Which tactics co-occur with personal attacks?
- What effect do personal attacks have on a conversation?
- Do individual users adhere to certain levels of the rebuttal hierarchy?

### Correlation with escalation
- We are interested in how informative the dispute tactics are in predicting the outcome of a dispute.
- We consider the escalation tags provided in WikiDisputes and calculate their Spearman correlation with the mean observed rebuttal level in a conversation.
- We use the micro-averaged mean over all rebuttal scores assigned during the conversation (ie. excluding coordination utterances).
- Let C = [(u 1 , r 1 , c 1 ), ..., (u n , r n , c n )] denote a disagreement consisting of utterances u, rebuttal labelsets r and coordination labelsets c.
- l represents a mapping of rebuttal labelsets to the numeric values of their levels, as set out in Table 1 (RH0 -RH7).
- We then calculate:
- This yields a weak negative correlation (ρ = −0.19, P = 0.005).
- We also experimented with a macro-averaged mean, which averages first at the This concept of stateless nation only applies to Sri Lankan Tamils who are demanding Tamil Eelam NOT Indian Tamils. Some political movements in Tamil Nadu may support Eelam nation but that does not mean we want to leave India. There is difference between Indian Tamils and Sri lankan-Tamils when it comes to politics, we are fully absorbed into Indian identity and society and have always been. Same can't be said about Sri Lankan-Tamils and Sinhalese in modern times."
- Tamils as a whole are a stateless nation. Tamil claim to be a nation but there is no sovereign Tamil state. If Tamils consider themselves a nation and somewhere in the world exists a movement for a Tamil state, then Tamils as whole are a stateless nation. To claim that Sri Lankan Tamils are stateless nation and India Tamils not, makes no sense, because both are the same ethnic group and so also the same nation.

### The context of personal attacks
- Level 1 attacks are the third most common label in the dataset
- They are associated with low levels of toxicity
- They co-occur with credibility attacks more than credibility attacks alone

### The effects of personal attacks
- Personal attacks are more frequent in escalated conversations
- Recovery is more likely in non-escalated disputes
- Revenge attacks are more common in disputes with personal attacks

### Individual user rebuttal levels
- WikiTactics contains utterances by 734 individuals
- For users with more than 1 utterance (535 users), the median difference between the highest and lowest rebuttal level employed is 4
- 167 users were found to only use levels 4 and higher whereas 18 used only levels 3 and below
- Mirroring (Meltzoff and Prinz, 2002) refers to a social phenomenon where speakers reflect the behaviour of others in a conversation
- To identify whether this occurs in our data, we identify users who participated in more than one dispute (66 users)
- To determine whether a user u is mirroring the rebuttal levels of others in a dispute c, we calculate: where ru represents a user's mean rebuttal level overall, ru,c denotes the user's mean in dispute c, and rc is dispute c's mean rebuttal level excluding contributions from user u. m u,c represents the extent to which an individual's deviation from their own mean in a conversation is explained by the setting, and takes on a positive value if the changes are in the same direction. In our data, a positive m u,c is observed in 57% of cases, indicating that mirroring does take place.

### Multilabel classification
- Multilabel classification is a task that can be done for each utterance, where a subset of labels (referred to as a labelset) can be assigned
- A vector representation for a labelset can be constructed by taking y k = [y k1 , y k2 , ..., y kl ] where y kj = 1 ⇐⇒ the j-th of L labels is relevant to the k-th example x k and 0 otherwise
- A simple method for multilabel modelling is binary relevance (BR) classification, under which a set of L binary classifiers are trained to each predict independently whether a label applies or not
- Another variation of the problem, referred to as the label powerset (LP) method, frames it as a multiclass classification problem over the powerset of all possible label combinations
- Both of these approaches have been found to perform well in practice

### Metrics
- Simple accuracy (EMR):
- Exact match ratio (EMR):
- Hamming loss:
- Jaccard score:
- Calculates the fraction of samples for which the full labelset are predicted correctly (Sorower, 2010).
- Seen as a midpoint between Hamming and EMR as two extremes (Park and Read, 2018).

## Experimental setting
- Truncated LP is a popular modelling choice for multilabel classification
- In our case, a large number of labels are being considered relative to the number of samples, thus we do not use the full set of all label combinations, but instead consider only the 20 most commonly applied label sets in the training set
- This method provides a coverage of 85% of samples in the dataset
- To allow for comparison between model types, we cast the predictions made by the LP model back to the multilabel setting for evaluation
- Incorporating conversation context while labels are assigned at the utterance level, some of the classes we aim to predict require knowledge of the preceding conversation context; for instance, "repeated argument" and "refutation" both occur in relation to another utterance
- We experiment with both the context-agnostic method (to provide a baseline) and with models that incorporate the preceding context
- Predicting ordinality The abovementioned models do not incorporate knowledge of the preferential ordering of the rebuttal tactics
- To include this signal, we add an auxiliary task which predicts the direction of the rebuttal level of the current utterance relative to the previous level, if a rebuttal tactic is used
- Using Fig 2 as an example, for utterance 2 the model would need to predict both level 4 (main task) and a downward transition (auxiliary task) relative to utterance 1.
- Further labels are added for upwards and same level transitions, as well as a separate class for coordination strategies which have no ordering.
- For the first utterance, level 3 is used as the reference level.
- If an utterance has multiple rebuttal labels, as indicated by the vertical lines in the figure, the maximum value was used as the reference point.
- The following models are evaluated in our experiments: • BoW: A bag-of-words encoding of an utterance is processed by a two-layer multilayer perceptron.
- • LSTM: A recurrent neural network with long short-term memory (Hochreiter and Schmidhuber, 1997) is used to process word embeddings (GloVe, Pennington et al., 2014).
- To incorporate conversation context, a hierarchical attention network (HAN; Yang et al., 2016) is used, which incorporates dialogue structure by encoding word embeddings using an LSTM layer followed by an attention mechanism to build up utterance embeddings.
- Utterance embeddings are similarly combined to form a context embedding.
- • BERT: Two fully-connected layers are added to a pretrained transformer-based language model (Devlin et al., 2018) and finetuned for our classification task.
- We use the "BERT-BASE-CASED" model from HUGGINGFACE.
- For the context-aware model, the preceding utterances are concatenated and encoded with a longformer model (Beltagy et al., 2020; "ALLENAI/LONGFORMER-BASE-4096").
- We split the data into train, test and validation sets with a ratio of 70-20-10, and employ early stopping based on the validation loss.
- In the case of LP classification, the label with the largest score can be considered as the predicted class.
- In the BR setting a threshold must be set to determine whether a given label should be assigned. This is calibrated using a development set.
- All models are implemented in Keras.
- All models use dropout (Srivastava et al., 2014) with p = 0.5 and the Adam optimiser (Kingma and Ba, 2014) with learning rate 0.001; except for the transformerbased models which use a learning rate of 2e-5.

## Results
- The experimental results are shown in Table 2.
- The models described in Sec 6, using both context-agnostic and context-aware settings, with binary relevance and the truncated LP formulations.
- As per Sec 5.2, we report the Jaccard score, the Hamming loss and the EMR, but we prioritise the Jaccard score.
- As expected, the LSTM and BERT models tend to outperform the BoW models.
- Adding conversation context improves performance in all models on the Jaccard score.
- The best performing model on the Jaccard metric is the BERT model with context.
- The truncated LP method achieves better results for the majority of models and metrics compared to the binary relevance formulation, despite truncating the label powerset and ignoring 15% of the training data.
- This can be attributed to the fact that there are certain classes with stronger co-occurrence relations (e.g. personal attacks with higher level arguments) which benefits the LP method.
- To gain a better understanding of model performance, we calculate the proportion of the test set with at least one label correctly predicted, yielding 0.395 on the best model (an increase of 0.11 over the EMR).
- The label most frequently correctly predicted is coordinating edits (111 of 137 cases), which is also the most common label in the training set.
- The next most correctly predicted label, proportionally, is contextualisation (75%, or 24 of 32 cases), despite not being a commonly used label. This is likely due to the additional positional information available to the model, since this label is often applied to the first utterance in a conversation.
- On the other hand, refutation and refuting the central point are never correctly predicted (out of 44 cases), with counterargument often mistakenly predicted instead. This is likely because of similarities between the classes and the latter being the second most common label in the training set.
- We build on the best performing model to evaluate the effect of including the ordinality prediction auxiliary task.
- Using this model, we obtain a statistically significant improvement (P = 0.03, using the permutation test on the Jaccard score) over the best model that is not aware of the ordering of the rebuttal tactics, providing further evidence of the usefulness of the rebuttal hierarchy.
- We also train models using the median and minimum rebuttal levels of each utterance, and find that while these do provide an increase in the Jaccard score, the difference is not significant (P = 0.32 and P = 0.13).

## Predicting escalation
- Based on the findings of Sec 4, we believe that the dispute tactic annotations provided in the Wiki-Tactics dataset can provide useful additional learning signals for the task of predicting escalation
- To add the dispute tactic classification as an auxiliary task, we modify the contextaware LSTM model
- Using this model, a PR-AUC score of 0.487 is obtained, indicating that knowledge of these dispute tactics is useful for tasks beyond classifying the tactics employed.

## Conclusion
- In this work, we introduced a framework and dataset for dispute tactics, consisting of rebuttal and coordination strategies.
- We used these annotations to analyse how different tactics are used in disagreements and by different individuals, providing insights on the context in which personal attacks occur and the extent to which users alter their own tactics to mirror the level of rebuttal used in a conversation.
- We further develop multilabel models for classifying the dispute tactics used in an utterance, experimenting with both binary relevance and label powerset methods.
- We further illustrate that knowledge of these tactics increases accuracy on the task of predicting escalation, indicating that the framework and dataset can be of use to researchers working on other aspects of disagreements online.
- Conversations on Wikipedia have been recognized for being goal-oriented (Niculae and Danescu-Niculescu-Mizil, 2016), constructive (De Kock and Vlachos, 2021) and exhibiting low levels of toxicity (Wulczyn et al., 2017).
- Learnings and models from Talk pages may therefore not transfer well to other domains.
- Another limitation of this work is the size of the dataset, which is in part due to the difficulty of the task.
- Future work may look into creating larger datasets using this framework; however, as we have illustrated, the annotations can provide useful additional training signals for other conversation-based tasks such as predicting escalation.
