---
title: "McNet: Fuse Multiple Cues for Multichannel Speech Enhancement"
date: 2022-11-16T12:25:54.000Z
author: "Yujie Yang, Changsheng Quan, Xiaofei Li"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "/home/niclas/arxiv-smry/arxiv-smry/static/thumbnails/2211-08872v1.webp" # image path/url
    alt: "McNet: Fuse Multiple Cues for Multichannel Speech Enhancement" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2211.08872)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2211.08872).


# Abstract
- Spectral and spatial information are both vital for speech recognition
- There is still an interesting research problem to fully exploiting these two types of information
- A proposed network named McNet exploits these two types of information by cascading four modules
- Each module has its own unique contribution and outperforms other state-of-the-art methods

# Paper Content

## METHOD
- Multichannel speech signals can be written in the short-time Fourier transform (STFT) domain
- Speech enhancement in this work aims to recover a single reference channel (denoted as r) of clean speech, i.e., S r (t, f ), given the noisy multichannel signals.

### Network architecture
- Fig. 1: Diagram of the proposed network
- Each module exploits different information types
- The network cascades four modules to exploit four different types of information
- The first two modules exploit multichannel spatial information, while the last two exploit single-channel spectral information
- Next, we will present the four modules one by one
- The second module exploits narrow-band spatial information
- The third module exploits sub-band spectral information
- The fourth module exploits full-band spectral information
- The last module exploits the temporal context of the previous modules

### Network configurations
- The proposed network can perform both online and offline speech enhancement
- For the first and fourth modules that run the LSTM recurrence along the frequency axis, bidirectional LSTM is applied for both online and offline processing
- For the second and third modules that run the LSTM recurrence along the time axis, unidirectional and bidirectional LSTMs are used for online and offline processing, respectively
- The noisy multichannel signals are normalized before being processed by the network
- Specifically, X m (t, f ) is normalized with the magnitude mean µ of reference channel as X m (t, f )/µ.
- For offline processing, µ is simply computed as L+1 is set to approximate a L-long smoothing window.

## EXPERIMENTS

### Experimental setup

### Speech enhancement results
- Table 1: Offline speech enhancement results
- Table 2: Online speech enhancement results
- The proposed model achieves excellent results even better than the offline results of comparison methods
- Ablation studies show that the four modules are important

## CONCLUSION
- The multi-cue fusion network McNet is proposed
- It cascades four modules dedicated to exploiting the full-band spatial, narrow-band spatial, sub-band spectral, and full-band spectral information
- It achieves excellent speech enhancement performance, especially for the online case
- Fig. 1. Diagram of McNet
