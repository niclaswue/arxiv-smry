---
title: "InPars-v2: Large Language Models as Efficient Dataset Generators for Information Retrieval"
date: 2023-01-04T20:58:43.000Z
author: "Vitor Jeronymo, Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, Roberto Lotufo, Jakub Zavrel, Rodrigo Nogueira"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2301-01820v1.webp" # image path/url
    alt: "InPars-v2: Large Language Models as Efficient Dataset Generators for Information Retrieval" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2301.01820)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2301.01820).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/inpars-v2-large-language-models-as-efficient).

# Abstract

# Paper Content

## Introduction and Background
- Data augmentation has been a reliable tool to improve the effectiveness of AI models in the face of the scarcity of high-quality in-domain training data
- Previous work by Bonifacio et al. [1] and Dai et al. [2] successfully leveraged the few-shot capabilities of LLMs to generate reliable synthetic training data for information retrieval models
- These training data helped their models achieve state-of-the-art (SOTA) results on the BEIR benchmark [6]
- Bonifacio et al. [1] propose InPars where they generate queries from documents in the corpus using LLMs. Similarly to Bonifacio et al. [1], the recently published Promptagator [2] model also feeds prompts to LLMs in order to generate alternative queries for a given document in an unsupervised manner. It differs primarily from InPars in that it uses dataset-specific prompts, a larger LLM to generate queries, and a fully trainable retrieval pipeline with smaller models.
- We also use an open-source query generator as opposed to the proprietary one used by Bonifacio et al. and provide the source code and data to reproduce our results on TPUs. We refer to Bonifacio et al. [1] model as Inpars-v1 and the model presented in this paper as Inpars-v2.

## Methodology
- InPars-v2 uses a different model to estimate relevancy, called monoT5-3B.
- It takes on average 30 hours to generate 100k synthetic queries.
- Once the synthetic queries are generated, a filtering step is applied to select relevant query-document pairs.
- InPars-v1 used a top 10k query-document pairs with the highest log probabilities of generating a query given the 3-shot examples and the document as input.
- InPars-v2 uses monoT5-3B already finetuned on MS MARCO for one epoch to estimate a relevancy score for each of the 100k query-document pairs.
- Then, only the top 10k pairs with the highest scores are kept for training.
- Evaluation is performed using the following pipeline: first, Pyserini's flat indexes are used to retrieve a thousand documents for each query using BM25 with default parameters (k1=0.9, b=0.4), for each dataset.
- Then, the finetuned monoT5-3B models are used to rerank these documents.

## Results
- Table 1: Results of BM25, monoT5-3B finetuned on MS MARCO, monoT5-3b finetuned on MS MARCO and further finetuned on InPars-v1, and monoT5-3B finetuned on MS MARCO and then finetuned on InPars-v2 data.
- Compared to InPars-v1, our approach is substantially better on TREC-News, Climate-FEVER, Robust and Touche.
- Additionally, we compare our method with Promptagator [2] and RankT5 [10]. Taking into account the average of all BEIR datasets, these results represent a new state of the art on BEIR.

## Conclusion
- InPars-v2 is an improved version of InPars
- It uses a publicly available language model to generate queries and a better query-document pair selection process
- Our results show that we achieve effectiveness on par with the state of the art on BEIR
- The synthetic data and finetuned models were publicly released
