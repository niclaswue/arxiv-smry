---
title: "ALIKE: Accurate and Lightweight Keypoint Detection and Descriptor Extraction"
date: 2021-12-06T10:10:30.000Z
author: "Xiaoming Zhao, Xingming Wu, Jinyu Miao, Weihai Chen, Peter C. Y. Chen, Zhengguo Li"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2112-02906v2.webp" # image path/url
    alt: "ALIKE: Accurate and Lightweight Keypoint Detection and Descriptor Extraction" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2112.02906)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2112.02906).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/alike-accurate-and-lightweight-keypoint).

# Abstract
- Existing methods detect keypoints in a non-differentiable way
- To address this issue, we present a partially differentiable keypoint detection module
- Output accurate sub-pixel keypoints
- Proposed reprojection loss is then used to directly optimize these sub-pixel keypoints
- Extract descriptors in a sub-pixel way
- Trained with the stable neural reprojection error loss
- Lightweight network designed for keypoint detection and descriptor extraction

# Paper Content

## I. INTRODUCTION
- Sparse representations are compact representations for efficient image matching.
- Early handcrafted algorithms were built upon limited human heuristics.
- Neural networks are explored for this task in recent years.
- Early neural network based methods mainly focus on descriptor extraction from image patches.
- Later, many excellent methods address the keypoint detection and descriptor extraction with a single network.
- Some of them treat the keypoint detection as a score map estimation problem.
- And then they train the intermediate score map with the synthetic ground truth score map and/or the similarity of score patches.
- Others define the score map based on the spatial and/or channel variation of dense feature map.
- However, both of them have to detect the keypoints on score map with Non-Maximum-Suppression.
- The NMS simply chooses the pixel with maximum local score, it is nondifferentiable and the gradients can not backward though.
- So the position of detected keypoints can not be optimized directly.
- We observed that a keypoint is supported by its local score patch.
- The score distribution in the patch would influence the keypoint position, even if the position of maximum score remains unchanged.
- This allows us to accurately capture subtle changes of local score distribution.
- To this purpose, we adopt the score map based pipeline for Differentiable Keypoint Detection.
- The DKD applies the softargmax operation on local score patches.
- Thus the gradients can backward from keypoints to score map.
- We present the keypoint reprojection loss to train the sub-pixel keypoints detected from DKD, which directly minimizes the reprojection distance of detected keypoints between images.
- Inspired by the peak loss [13], [20], a dispersity peak loss is further introduced to avoid blob scores on score map, which forces the score map to be accurately "peaky" at the keypoint position.
- Besides the sub-pixel keypoints from score map, the de-scriptors are also sampled in a sub-pixel way from the dense descriptor map.
- The widely use method to train sparse descriptors is the triplet loss.
- However, our experiments indicate that the training of sub-pixel sparse descriptors with triplet loss is tricky and unstable, as they only cover the sampled keypoints of entire descriptor map.
- Inspired by sparse-to-dense matching methods [26]-[29], we adopt the recent proposed neural reprojection error (NRE) loss [29].
- A lightweight network aggregating hierarchical features is designed for efficient keypoint detection and descriptor extraction, which can run at 95 FPS (frame per second) on a commercial GPU while achieving comparable performances to state-of-the-art (SOTA) approaches.
- The rest of this paper is organized as follows. Section II reviews the deep learning based methods. Section III introduces the lightweight network, proposes the differentiable keypoint detection module, and presents the training losses. In section IV, we first analyze each part of the proposed method, then conduct the evaluation and discussion on different tasks. Finally, a conclusion is given in section V.

## II. RELATED WORKS
- Deep learning methods can be roughly divided into three categories: the patch-based, score map based, and the description-and-detection methods.
- The patch-based methods are based on the idea of training a neural network on a large number of pre-defined patches.
- The score map based methods are based on the idea of training a neural network on a large number of feature maps.
- The description-and-detection methods are based on the idea of training a neural network on a large number of descriptions of objects.

## A. Patch-based methods
- The Matchnet estimates similarity of descriptors
- TFeat introduces the triplet loss for patch descriptors
- L2-Net presents a progressive sampling strategy for triplet sampling
- LIFT mimics the SIFT
- HardNet and SOSNet introduce the hardest negative triplet and second order similarity of descriptors
- However, the patchbased methods only focus on descriptors extraction, and their receptive field is limited in the image patch.

## B. Score map based methods
- Tilde [18] first trains the score map on webcam dataset with SIFT [6] keypoints as ground truth.
- Quad-networks [19] trains the score map by ranking scores to eliminate the need of ground truth labeling.
- And KeyNet [34] estimates the score map with the handcrafted and learned features, it extracts keypoints from score map with softargmax [23].
- Besides pure keypoint detection, recent methods estimate both the score map and descriptor map.
- LFNet [17] also uses softargmax [23], but it still trains on score map rather than keypoints.
- SuperPoint [12] first trains a MagicPoint model on synthetic dataset, and then bootstraps the score map on real images with homographic adaption strategy, and its descriptors are trained with triplet loss.
- This strategy is also adopted in MLIFeat [31] and SEKD [20].
- R2D2 [13] identifies keypoints as reliable and repeatable positions in image and trains reliability through AP loss [35].
- HDD-Net [36] weights the features with softargmax scores in grids to train the score map and feature map simultaneously.
- DISK [37] and reinforced SP [38] relax the keypoint detection and descriptor matching as probabilistic processes and train the network with reinforcement learning.
- However, all these methods except KeyNet [34] train on intermediate score map rather than directly on keypoints, as they are extracted with non-differentiable NMS.
- Our DKD is most similar to KeyNet [34] and also utilizes softargmax. But our method dose not require handcrafted features and any pseudo keypoint annotations.

## C. Description-and-detection methods
- D2Net [14] first proposes this concept
- ASLFeat [15] improves it with channel-wise and spatial-wise peakiness on multi-layer feature maps
- UR2KiD [22] computes the score map with the L2 response of features
- And D2D [21] selects the absolute and relative salient points from feature map as keypoints
- Unlike score map based methods (detection-thendescription), description-and-detection methods recognize keypoints as distinctive positions in an image and generate the score map by computing distinctiveness of the descriptor map or feature maps.
- D2Net [14] first proposes this concept
- ASLFeat [15] improves it with channel-wise and spatial-wise peakiness on multi-layer feature maps
- UR2KiD [22] computes the score map with the L2 response of features
- And D2D [21] selects the absolute and relative salient points from feature map as keypoints

## III. METHODS
- The network estimates a score map and descriptor map
- Sub-pixel keypoints are detected with the DKD from the score map
- The training losses for accurate keypoints and discriminative descriptors are presented.

## A. Network architecture
- The network is designed to be as lightweight as possible
- It only has a basic encoder for feature extraction
- Then the feature aggregation module assembles multi-level features
- For accurate localization performance, the feature extraction head estimates the score map S and descriptor map D under original image resolution
- The score map S is initialized to be zero, and the descriptor map D is initialized to be the identity matrix
- The feature localization module uses the estimated position and size to estimate the descriptor map D′
- The descriptor map D′ is a 2 × 2 matrix that is initialized to be the identity matrix
- The feature localization module uses the estimated descriptor map D′ to estimate the position and size of the object in the original image I′
- The position is estimated using the following equation: (x, y) = argmax{D′[x], D′[y]}

## B. Differentiable keypoint detection module
- The NMS is a widely used method for detecting keypoints in a score map.
- The NMSed score map is first obtained by suppressing the non-maximum scores s = S(u, v) in local N × N windows.
- Then, a threshold th is applied on the NMSed score map to filter out low response scores.
- The softmax normalizes x as The s (i, j) indicates the probabilities of [i, j] T to be the keypoint.
- Thus the expectation position of keypoint in the local window can be given by integral regression.

## C. Learning accurate keypoints

## D. Learning discriminative descriptor
- descriptor discriminativeness is trained using triplet loss
- the triplet loss only optimizes the sparse descriptors sampled from keypoints, so the dense descriptor map cannot be fully constrained
- to address this issue, we adopt the NRE loss to train with the dense descriptor map
- the matching probability map is given as the softmax normalization of the similarity map

## E. Learning reliable keypoint
- The reprojection and dispersity peak loss provide accurate and repeatable keypoints.
- However, the spatial properties of descriptor map are not taken into account, so the keypoints might be unreliable.
- To address this issue, we introduce a reliability loss based on the matching probability map in the NRE loss.
- First, the matching probability map is obtained by normalizing the similarity map C dp A ,D B ∈ R H×W in equation ( 15) where t rel controls the sharpness.
- Then the reliability of keypoint p A is defined as where bisampling(M , p) is the bilinear sampling at position p ∈ R 2 on probability map M ∈ R H×W .
- Intuitively, r p A assesses the matching quality of p A .
- If p A is in unreliable low texture or repetitive region, the overall similarities in that region will be higher. As a result, the normalized similarity map C dp A ,D B has lower values, and the sampled score r p A is small, indicating that p A is unreliable.
- Considering all valid keypoints in image A, we define their reliability loss similar to D2Net [14] and ASLFeat [15] L where N A is the number of keypoints in the image A.
- For each keypoint p A in image A, p AB is its corresponding projection keypoint in image B (equation ( 7)). And s p denotes the score value of keypoint p in its corresponding image.
- Similarly, the reliability loss is also given in a symmetric way as IV.

## A. Datasets
- MegaDepth dataset includes tourist photos on famous sites and 3D maps built by COLMAP
- We adopt the image pairs generated in DISK to train our model
- With co-visibility heuristics, it generates image pairs from the scenes except those overlapped with IMW2020 validation and test sets, resulting 135 scenes with 63k images in total
- HPatches dataset contains planar images of 57 illumination and 59 viewpoint scenes
- Each scene has 5 image pairs with ground truth homography matrices
- Following D2Net, eight unreliable scenes are excluded
- We conducted the ablation studies and homography estimation on this dataset
- IMW2020 is also built with tourist photos using COLMAP
- It provides a standard pipeline for camera pose estimation, which we used to compare the proposed method to existing methods

## B. Training details
- We used the DKD to detect 400 keypoints and randomly sampled another 400 keypoints on non-salient positions.
- In reprojection loss, the th gt = 5 and the normal factor p = 1.
- The overall loss is where w rp = 1, w pk = 1, w rl = 1, and w de = 5.

## 2) Training setups:
- The images were cropped and resized to 480 × 480
- The network was trained using the ADAM optimizer
- The learning rate started at zero and warmed up to 3e −3 in 500 steps before remaining at 3e −3
- Under these settings, the proposed model converges on NVIDIA Titan RTX in about two days

## C. Evaluation metrics
- The number of co-visible keypoints is defined as N cov = (N A + N B )/2.
- Among them, we get N gt ground truth keypoint pairs with the reprojection distance less than three pixels.
- On the other hand, N putative matches are obtained with mutual matching of the descriptors.
- And N inlier inlier matches are acquired by assessing the reprojection distance within different pixels threshold.
- Following previous works [12], [46], we adopt the following metrics:
- Rep = N gt /N cov .
- M S = N inlier /N cov .
- M M A = N inlier /N putative .
- M HA = the percentage of correct image corners with the estimated homography matrix.
- We conduct ablation studies on HPatches dataset [46] with single-scale.
- The score threshold th in the DKD module is 0.2.
- Up to 5000 keypoints are detected.
- We evaluate the M M A@3 and M HA@3 without loss of...
