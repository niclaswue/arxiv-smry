---
title: "High-resolution canopy height map in the Landes forest (France) based on GEDI, Sentinel-1, and Sentinel-2 data with a deep learning approach"
date: 2022-12-20T14:14:37.000Z
author: "Martin Schwartz, Philippe Ciais, Catherine Ottlé, Aurelien De Truchis, Cedric Vega, Ibrahim Fayad, Martin Brandt, Rasmus Fensholt, Nicolas Baghdadi, François Morneau, David Morin, Dominique Guyon, Sylvia Dayau, Jean-Pierre Wigneron"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2212-10265v1.webp" # image path/url
    alt: "High-resolution canopy height map in the Landes forest (France) based on GEDI, Sentinel-1, and Sentinel-2 data with a deep learning approach" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2212.10265)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2212.10265).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/high-resolution-canopy-height-map-in-the).

# Abstract
- In intensively managed forests, a high spatial resolution (10-20 meters) is needed to capture the differences in canopy height
- In this work, a deep learning model is developed based on multi-stream remote sensing measurements to create a high-resolution canopy height map over the "Landes de Gascogne" forest in France
- The model uses Sentinel-1 and Sentinel-2 images with composite time averages as input to predict tree height
- The evaluation is performed with external validation data from forest inventory plots and a stereo 3D reconstruction model based on Skysat imagery
- Seven different U-net models are trained based on a combination of Sentinel-1 and Sentinel-2 bands
- The model outputs allow us to generate a 10 m resolution canopy height map of the whole "Landes de Gascogne" forest area for 2020 with a mean absolute error of 2.02 m on the Test dataset

# Paper Content

## Introduction
- Forest biomass plays a crucial role in the global carbon cycle
- Forest biomass can be estimated from top canopy height
- Airborne LiDAR can scan a forest and provide accurate height estimations consistent with forest inventory measurements at a high spatial resolution
- Combinations of GEDI and Sentinel-2 have already been proposed for mapping crop height and forest canopy height
- Machine learning has proven some solid results for forest parameter estimations in previous remote sensing studies

## Materials & Methods
- The study relies on the use of GEDI sensor data to measure canopy height
- The study used a deep learning U-Net to provide a gridded map of the Landes de Gascogne area
- Fig. 1 describes the general workflow

## Study area
- GEDI data from the Global Ecosystem Dynamics Investigation (GEDI) is used as a reference variable to model a continuous height map at 10 m resolution.
- GEDI is operated by NASA and produces high-resolution LiDAR observations of the Earth's vertical structure (Dubayah et al., 2020).
- This spaceborne infrared LiDAR, deployed in December 2018 on the ISS, provides energy return waveforms (L1B product) and derived metrics such as canopy relative height (RH) and plant area index (L2A/L2B product) that describe the vertical forest structure within 25 m diameter circular footprints.
- The instrument acquires data over eight tracks with a footprint spacing of 60 m along the track and 600 m across tracks.
- Due to the ISS orbit, it covers latitudes between 51.6° South and 51.6° North.
- The precision of the horizontal footprint location, initially around 20 m, has been improved in GEDI's second release to a value of 10 m, as shown in Appendix 1 (Dubayah et al., 2021).
- The GEDI L2A product provides RH metrics representing the height relative to the ground of n% (RH n with n in the 0 to 100 range) of the total returned energy between the top of the canopy and the signal end.
- These metrics are extracted from the raw waveforms with six different algorithms representing different combinations of thresholds and smoothing settings.
- They can vary from one algorithm to another depending on the forest type (Adam et al., 2020).
- In our study area, most footprints had the same RH values for most algorithms. Hence, we chose to use the algorithm selected by NASA in the "selected_algorithm" variable in GEDI data, which corresponds mainly to algorithm 1 over our study area.
- In theory, RH 100 should represent the top of canopy height. Still, this metric is affected by noise from atmospheric disturbances, uncertainties on the position of the detected ground return, vegetation, and ground variability. Here, we used RH 95, as it has showed a better correlation with other height sources and has been used as a proxy for height in previous studies (Fayad et al., 2021b;Potapov et al., 2021) even though other similar metrics such as RH 98 have also been used (Lang et al., 2022b).
- Due to the LiDAR properties, this measure is intended for vegetation and may represent confusing results for bare soil or water bodies (Beck et al., 2020).
- In total, 526,449 footprints from the GEDIv002 L2A product (Dubayah et al., 2021) were downloaded from NASA's EarthDataSearch website (https://search.earthdata.nasa.gov/search) for this study, covering the entire area of interest for 2020.
- After these operations, 175,511 GEDI valid waveforms (33%) were kept in 2020.
- These GEDI footprints were then spatially separated into Train, Validation, and Test datasets.
- The temporal distribution of the data is uneven and some months (July, ~ 16% of the data) are more represented than others (January, ~ 4% of the data).
- The spatial distribution of the data is also uneven due to the ISS trajectory and the northern tiles of the study area contain more footprints than other tiles.

## Sentinel-1
- Sentinel-1 is a C-band SAR mission composed of 2 satellites
- The Sentinel-1 data set provides backscattering coefficients (dB) which are a measure of the backscattered microwave radiations (backward direction) emitted by the radar system
- Using the Google Earth Engine (GEE) online platform, we selected 280 images covering the entire area of interest over a five-month period in 2020 (2020-05-01 to 2020-10-01)
- We then separated them between ascending and descending orbits (140 images per category) and calculated the per-pixel median of these image time series, thus creating a single composite image of 4 layers: VV_ascending, VH_ascending, VV_descending, and VH_descending at 10 m resolution
- Each pixel of the composite image corresponds to the median value of pixels from ~25 images at different dates
- The median is little influenced by extreme values and reduces the potential soil and vegetation moisture-related effect that could be observed on raw S1 images

## Sentinel-2
- Sentinel-2 is a mission of the European Space Agency's Copernicus program for Earth Observation
- The Sentinel-2A and Sentinel-2B satellites were launched in 2015 and 2017, respectively
- The Sentinel-2 L2A product provides multispectral images of the Earth surface reflectance with a low revisit interval of ~ 5 days
- The L2A product comprises 13 spectral bands ranging from 10 m to 60 m resolution in visible, near-infrared (NIR), and short-wave infrared (SWIR)
- After applying a cloud mask, a single composite image is created by taking the per-pixel median value over the image time series
- The ten following spectral bands (10 and 20 m resolution) were kept and resampled to 10 m if necessary
- The input data of a neural network should be on a similar scale to help stabilize the gradient descent step in the training phase

## Evaluation Datasets
- To compare our height predictions with independent sources, we used three complementary datasets covering different spatial scales
- We compared our predictions to canopy height maps computed from previous local and global studies using other techniques or data sources

## Forest inventory data
- The comparison with the GLORIE dataset (Fig. 9a) shows a good correlation between predicted height and measurements
- The IFN dataset (Fig. 9b) is also well correlated to our canopy height retrievals (R² = 0.71, ME = -1.18 m, MAE = 2.67 m, RMSE = 3.55 m)
- Broadleaved forests show a lower correlation and poorer error metrics: R² = 0.38, RMSE = 5.74 m

## Stereo 3D reconstruction from Skysat imagery
- The Skysat constellation of optical sub-meter resolution satellites provides high-resolution imagery in panchromatic, visible, and infrared bands.
- The geolocation accuracy of Skysat is 3.4 m for all images, but it should be better on the cloud-free images used here.
- The stereo 3D height reconstruction technique of de Franchis et al. (2014) uses multiple image acquisitions with different view angles to reconstruct 3D objects with a dispersion error of ~ 0.5 m.
- Here, we applied this technique to reconstruct canopy height in a small area of 11 km² and compared it to our model outputs.
- We first created a digital surface model (DSM) at 0.8 m resolution from point-cloud 3D reconstruction based on Skysat images acquired in 2021.
- Then we used a cloth simulation algorithm (Zhang et al., 2016)) to select ground points from the 3D point cloud.
- Finally, we used a Laplace interpolation to create a terrain model from those points that we subtracted from the raw DSM to obtain a canopy height model (CHM).
- To compare it to our model, we resampled this CHM to a 10 m grid aligned with our prediction map.
- For this, we took the maximum value of the CHM within each 10m x 10m grid cell, which corresponds to the top canopy height and is thus relevant for a comparison with our RH 95 -based model.

## Canopy height maps from previous studies
- We compared our model predictions to three canopy height maps from independent studies
- Maps from Potapov et al. (2021) and Lang et al., (2022a) 2019) is a local canopy height product specific to maritime pine homogeneous plantations in the Landes forest.
- Contrary to the two previous maps that used GEDI, reference height measurements were based on a small local forest inventory of maritime pine only (GLORIE inventory, see 2.3.1).
- These forest inventory measurements were used with remote sensing data (Sentinel-2, Sentinel-1, ALOS-PALSAR…) and a machine learning model (Support vector machine) to produce a canopy height map of the Landes forest in 2016, only valid for maritime pine plantations.

## Methodology

## U-Net model description
- Pixel-wise regression is the process of attributing a particular value (tree height) to each pixel instead of attributing a label to the whole image
- This task can be addressed by fully convolutional networks (FCNs) (Long et al., 2015) that have been adapted from classical CNNs.
- Here, we use a U-Net model adapted from Milesi (2022) which is a FCN that outperformed previous models in speed and accuracy and requires fewer training examples thanks to its U-shape architecture (Ronneberger et al., 2015).
- The final layer consists of a 1x1 convolution that creates an output image with the same height and width as the input image.
- After the training process, this output will represent the canopy height map derived from the input image.

## Training process
- The objective of the training process was to adjust all the weights of the FCN model so that when the FCN model takes a multi-channel image composed of S1 and S2 layers as input, it outputs the corresponding canopy height map.
- One single FCN model was trained on all the Train tiles.
- To achieve this, we followed the process described in Fig. 5: (1) We randomly selected one of the 91 Train tiles. This random selection was weighted by the number of GEDI footprints in each tile. (2) We took a random 2560x2560 m subset from this tile with at least one GEDI footprint inside. This technique increases the number of different images used as input of the model and contributes to reduce model overfitting. (3) The corresponding 256x256 pixels image composed of S1 and S2 layers was used as input of the U-Net. In the case where we chose to use all S1 and S2 bands, this image was composed of 14 layers. (4) The GEDI RH 95 values in this 2560x2560 m subset were rasterized on a 10 m grid aligned with S1 and S2. To do so we used the Rasterio.features.rasterize function from the Rasterio library in python.
- For each footprint, the RH 95 value was rasterized on the pixel where the center of the circular footprint was located. As the GEDI footprints correspond to 25 m diameter circles with a 10 m uncertainty on their location, we acknowledge that our rasterization process at 10 m could create label noise, especially in forests with a very heterogeneous canopy. Still, training at 10 m was shown to give better results than training at 20 m.
- The FCN model output was compared to the reference height from the rasterized GEDI data with a mean absolute error (MAE) loss only for pixels where a RH 95 height value was available.
- The gradient of this loss was calculated with respect to each of the model weights and weights were then adjusted accordingly. This process is called "loss backpropagation" and is a key element in the training of neural networks.
- After ~100 epochs, which corresponded to ~2 hours, this validation loss was stabilized and we manually stopped the training process. We also tried other types of learning rate schedulers but this one led to faster convergence and similar results.

## Training scenarios
- To understand the importance of each spectral and polarization information, we designed seven training scenarios based on combinations of different spectral and polarization layers.
- The first FCN model was trained on all layers (10 from S2 and 4 from S1). The second and third FCN models were based on one source of data only (either S2 or S1). The other FCN models were trained on subsets of S2 (only 10m resolution bands or only B8 (NIR band)) and S1 bands (only descending orbit, only VV polarization for descending orbit) respectively.

## Used metrics
- Mean Absolute Error (MAE)
- Root Mean Squared Error (RMSE)
- Mean Error (ME)
- Determination coefficient (R²)
- Decomposed Mean Squared Error (MSE)
- Squared Bias (SB), Squared Difference between Standard Deviations (SDSD), and Lack of Correlation weighted by the Standard deviations (LCS)

## Results

## Canopy height model
- The FCN model was able to predict a continuous canopy height map, where forest structures and other landscape features are recognizable and look similar to the image input.
- The FCN model was able to retrieve high height differences between forest from non-forest areas.
- The FCN model was able to capture within-stand and across-stand heterogeneity well.

## GEDI Test set evaluation
- The FCN model has a slight tendency to underestimate higher heights
- The FCN model has a better prediction than the RH 95 values for the Test dataset

## Evaluation with independent datasets

## Figure 9. Comparison between the predicted height from the FCN model (Scenario 1) for the year 2020 with the forest inventory dominant height from the GLORIE project (measurements made in 2016) (a), and with French National Forest Inventory (NFI, measurements made over 2017-2020) (b). For both graphs, the dotted line represents the x=y axis. The predicted height corresponds to the mean height of the pixels within the forest plot area. The French NFI (b) dataset is colored by year of sample and separated into broadleaved and coniferous forests. Red circles indicate plots that are not considered in the calculation of the error metrics because of forest clear-cuts between the date of the forest inventories and the date of the S1 and S2 images.

## 3D reconstruction from stereo satellite acquisition
- The pixel distribution in height of the FCN model follows globally the same pattern as the 3D reconstruction canopy height model (referred to as 3D CHM in the following).
- The number of low height pixels between 5 m and 10 m is higher for 3D CHM while the FCN model has a higher number of pixels for all heights above 4 m, especially for heights around 16 m.
- The comparison at forest stand level (Fig. 10b) reveals a very good correlation (R² = 0.90, MAE = 1.17 m) with no bias (ME = -0.03 m) between the 3D CHM and the FCN predictions of forest heights.
- Visually, the 3D reconstruction (Fig. 10c) presents sharper delimitations between the different forest units compared to the FCN model (Fig. 10d). This is confirmed by the height profile (Fig. 10e) which reveals that the FCN model tends to smooth the transitions between forest units.

## Influence of Sentinel-1 and Sentinel-2 bands on height predictions
- The results presented above are all retrieved from our best training scenario (Scenario 1: based on all S1 and S2 layers).
- Overall, the two first scenarios (1: All bands, 2: All Sentinel-1 bands) perform better, with a lower RMSE value when compared to any of the four evaluation datasets (e.g. 3.55 m and 3.76 m when compared to the French NFI while the results obtained for the other scenarios led to a RMSE > 4 m).
- Scenarios including only Sentinel-2 bands have lower performances (Scenarios 3, 4, and 7) but still, lead to relatively good error metrics.
- Similar results are observed between Scenarios 3 (all S2 bands), 4 (only 10m resolution i.e., 4 bands: RGB+NIR), and 5 (VV and VH descending from S1) except for the GLORIE dataset where Scenario 5 is better with no bias and lower SDSD.
- Lastly, Scenarios 6 and 7, respectively based on one Sentinel-1 (VV descending) and one Sentinel-2 (B8: NIR) band lead to larger errors for all validation datasets (RMSE > 3 m when compared to 3D CHM while other scenarios lead to a RMSE < 2.5 m).

## Comparison with other canopy height maps
- The FCN model predicts a higher homogeneity within the forest stands while the two other models (P21 and M19) show a higher variability between adjacent pixels.
- The FCN model has a better error metrics except for broadleaved forests.
- L22 (RMSE = 5.01 m), P21 (RMSE = 6.57 m), and M19 (6.75 m) show higher errors.
- L22 has better performances over broadleaved forests (RMSE = 5.26 m, R² = 0.42, Fig. 13c) compared to the FCN model (RMSE = 5.74, R² = 0.38).
- For coniferous forests, the FCN model, along with M19 shows a much lower bias (almost null for the 3D CHM) than the two global canopy height maps (P21 and L22).
- L22 has a high SB value (high bias) when compared to the GLORIE forest inventory and to the Skysat 3D CHM but still has a good correlation with these datasets (R² = 0.81 for GLORIE with a low LCS).

## Discussion
- Forest border errors: The visual analysis of the FCN height predictions shows higher errors at the forest borders. These errors are likely related to the GEDI uncertainty of ~ 10 m for the ground location.
- The opposite phenomenon (low predictions for high RH 95 values) is observed less often, which is likely due to the fact that the GEDI Test dataset we used only contains footprints that are located within forests.
- As the GEDI's footprint diameter is 25 m, small gaps in the canopy that are invisible in the S1 and S2 images cannot be reflected in GEDI's RH 95 and cannot explain these high prediction errors.

##  Smoothness
- The border of landscape units seems to have a smoothing effect on the predictions
- This can be particularly observed in the comparison with the 3D reconstruction from stereo Skysat images
- Contrary to a per pixel prediction, as performed in P21 for instance, each pixel of the FCN canopy height map is the result from multiple convolutions involving the surrounding pixels
- Pixels close to forest borders have neighbor pixels from forest and bare soil which could lead to this average height prediction, creating smoothness between landscapes units
- Additionally, the 10 m x 10 m S1 and S2 pixels on forest borders contain also average information from both forest and non-forest areas and are also "smoothed" which can explain the smoothing effect in our predictions

##  Bare soil
- Due to RH 95 properties, bare soil is retrieved with a height of ~2.25 m
- The height profile (Fig. 10.e) used to compare the 3D reconstruction with the FCN model highlights this phenomenon where we can see that low non-forest heights are overestimated
- The overestimation of lower heights visible in Fig. 9a for the GLORIE dataset is mainly related to this RH 95 effect and explains the higher SDSD values in Fig. 11b

##  Underestimation at high forest heights
- The FCN model underestimates heights above 20 m (ME = -2.5 m for trees between 20 and 25 m, Fig. 8a).
- Better performance over coniferous forests Thanks to the French NFI data, we were able to evaluate separately the performance of the FCN model over broadleaved and coniferous forests.
- The more S1 & S2 layers are available as inputs, the better the prediction is.
- For most evaluation metrics, the FCN model shows improved performance compared to available canopy height maps for the Landes forest.
- Better delimitation between landscape units, lower bias, better correlation, and better RMSE are obtained on all validation datasets except for the broadleaved part of the NFI data set where L22 is better.
- These results underline the importance of the scale at which the training is performed.

##  On the use of GEDI
- The GEDI mission provides an unprecedented database of LiDAR waveforms with high precision
- The ability of GEDI to retrieve canopy height properly in more complex forest structures is still uncertain
- In denser forests, some GEDI laser beams could not penetrate deep enough in the trees to reach the ground thus leading to a height underestimation
- Moreover, the uncertainty associated with the GEDI footprint location could potentially lead to large errors
- Here, we rasterized the GEDI footprint in a 10 m x 10 m pixel that corresponds to the center of this footprint. However, the height information contained in this GEDI footprint encompasses a 25 m diameter circle. Additionally, the 10 m uncertainty on the footprint location extends the area where the height information is actually captured by GEDI to a 45 m diameter circle around the supposed center of the footprint. Hence the height information could potentially come from a point that is the third neighbor of the actual pixel that was rasterized. These errors are randomly distributed and, thanks to the large number of GEDI samples, it only creates noise in the reference height data used for training. So, it seems that these errors can be well handled by the FCN model.
- But in other more complex regions, this noise can be higher and the FCN model could have difficulties to carry out correct height predictions.
- To evaluate the impact of this uncertainty, we retrained our model with the previous GEDI release (GEDI v001). In this previous version, the standard deviation on the GEDI footprint location was 20 m (GEDI v001) and it was improved to 10 m in the GEDI v002 version. The MAE on the Test dataset improved from 2.43 m to 2.02 m when using the more recent version of GEDI.
- FCN model outputs show clearer patterns and transitions between forested and nonforested areas for v002 vs v001 (See Appendix 4).
- The FCN model based on GEDIv001 produces blurred transitions between landscape units, thus trying to avoid high losses related to location errors.

##  Influence of the number of training samples
- The GEDI footprints are unevenly distributed globally because of the ISS trajectory.
- In order to assess how this can affect the reproducibility of the proposed method, we trained three additional models like the one from scenario 1 (all S1 and S2 bands) by randomly keeping only 10%, 1% and 0.1% of the footprints from the training dataset.
- As shown in Table 1, a model trained with only 10% of the original train dataset still leads to good results (MAE = 2.43 m on the Test dataset) and a canopy height map that looked very similar to the original one by visual inspection.
- However, when the number of training samples drops to 1% of the original sample size, the output map looks a little noisier with a lower MAE (3.02 m).
- These results stress the importance of having large training datasets, especially for deep learning algorithms like our FCN model.

## Concluding remarks
- The study highlights the potential of deep learning models to map forest height continuously at high resolution with sparse references, e.g. GEDI LiDAR data, and continuous images from Sentinel-1 SAR and Sentinel-2 multispectral imager.
- The study confirms the potential of GEDI data to produce a good estimation of forest height, especially when integrated into a deep learning prediction model that reduces the uncertainty related to the measurement of one LiDAR footprint.
- Our FCN model is able to retrieve forest height at 10 m resolution in a French coniferous plantation with a relatively good accuracy (MAE = 2.02 m) for the GEDI Test dataset and a high correlation with independent height measurement sources.
- These results remain relatively good when using only one satellite source for model training which is particularly interesting in order to extend this study to other regions of the globe with a higher cloud cover or to use other satellite sources like Planet that have only four spectral bands but a higher spatial resolution.
- The map we produced showed improved results in comparison to other existing canopy height models over this region.
- The Landes forest is mainly composed of even-aged forest parcels of maritime pines. This very specific situation has probably been "learned" by the deep learning model which tends to smooth the height within one forest stand and its performance on other types of forest structures is probably different.
- However, the method we developed still appears to be promising to retrieve canopy height on other forest structures such as broadleaved forests.
- For instance, we applied this methodology to another French "sylvoecoregion" called Sologne, mostly composed of broadleaved forest and obtained a similar accuracy with external validation from NFI plots (MAE = 2.62 m, see Appendix 6), Additionally, the area of interest is mostly flat.
- Sentinel-1 images are very sensitive to steep terrain and GEDI waveforms are also affected by higher slopes that tend to overestimate tree heights (Kutchartt et al., 2022).
- Further studies in more mountainous regions, by including a digital surface model in the deep learning process, could be potentially interesting to address these issues.
- Considering the availability of the Sentinel-1 and -2 observations, the canopy height map we retrieved could be used to monitor tree height with a yearly time frequency. Moreover, considering the strong relationship between canopy height and canopy biomass (Saatchi et al., 2011), the canopy height map could be used in a subsequent step to monitor forest biomass at the forest stand level and with a good temporal repetition (at least yearly), thus following the guidance of the Global Forest Observation Initiative (GFOI) to integrate earth observation data into national forest monitoring systems.
