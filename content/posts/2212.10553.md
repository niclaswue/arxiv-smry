---
title: "RangeAugment: Efficient Online Augmentation with Range Learning"
date: 2022-12-20T18:55:54.000Z
author: "Sachin Mehta, Saeid Naderiparizi, Fartash Faghri, Maxwell Horton, Lailin Chen, Ali Farhadi, Oncel Tuzel, Mohammad Rastegari"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2212-10553v1.webp" # image path/url
    alt: "RangeAugment: Efficient Online Augmentation with Range Learning" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2212.10553)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2212.10553).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/rangeaugment-efficient-online-augmentation).

# Abstract
- State-of-the-art automatic augmentation methods (e.g., AutoAugment and RandAugment) diversify training data using a large set of augmentation operations.
- The range of magnitudes of many augmentation operations (e.g., brightness and contrast) is continuous. Therefore, to make search computationally tractable, these methods use fixed and manually-defined magnitude ranges for each operation, which may lead to sub-optimal policies.
- To answer the open question on the importance of magnitude ranges for each augmentation operation, we introduce RangeAugment. RangeAugment uses an auxiliary loss based on image similarity as a measure to control the range of magnitudes of augmentation operations. As a result, RangeAugment has a single scalar parameter for search, image similarity, which we simply optimize via linear search.
- RangeAugment integrates seamlessly with any model and learns model- and task-specific augmentation policies. With extensive experiments on the ImageNet dataset across different networks, we show that RangeAugment achieves competitive performance to state-of-the-art automatic augmentation methods with 4-5 times fewer augmentation operations.

# Paper Content

## ABSTRACT
- State-of-the-art automatic augmentation methods (e.g., AutoAugment and Ran-dAugment) diversify training data using a large set of augmentation operations.
- The range of magnitudes of many augmentation operations (e.g., brightness and contrast) is continuous. Therefore, to make search computationally tractable, these methods use fixed and manually-defined magnitude ranges for each operation, which may lead to sub-optimal policies.
- To answer the open question on the importance of magnitude ranges for each augmentation operation, we introduce RangeAugment that allows us to efficiently learn the range of magnitudes for individual as well as composite augmentation operations.
- RangeAugment uses an auxiliary loss based on image similarity as a measure to control the range of magnitudes of augmentation operations.
- As a result, RangeAugment has a single scalar parameter for search, image similarity, which we simply optimize via linear search.
- RangeAugment integrates seamlessly with any model and learns model-and task-specific augmentation policies.
- With extensive experiments on the ImageNet dataset across different networks, we show that RangeAugment achieves competitive performance to state-of-the-art automatic augmentation methods with 4-5 times fewer augmentation operations.
- Experimental results on semantic segmentation, object detection, foundation models and knowledge distillation further shows RangeAugment's effectiveness.

## INTRODUCTION
- Data augmentation is a regularization method that uses carefully designed image transformation operations to increase the quantity and diversity of training data.
- These methods rely heavily on expert knowledge and extensive trial-and-error experiments.
- Recently, automatic augmentation methods have gained attention because of their ability to search for augmentation policy (i.e., combinations of different augmentation operations) that maximizes validation performance.
- In general, most augmentation operations (e.g., brightness and contrast) are parameterized by two variables: (1) the probability of applying them and (2) their range of magnitudes.
- RangeAugment is a simple and efficient method to learn the range of magnitudes for each augmentation operation.
- Inspired by image similarity metrics (Hore & Ziou, 2010), RangeAugment introduces an auxiliary augmentation loss that allows us to learn the range of magnitudes for each augmentation operation.
- We realize this by controlling the similarity between the input and the augmented image for a given model and task.
- Rather than directly specifying the parameters for each augmentation operation, RangeAugment takes a target image similarity value as an input.
- The loss function is then formulated as a combination of the empirical loss and an augmentation loss.
- The objective of the augmentation loss is to match the target image similarity value.
- As a result, the augmentation policy learning in RangeAugment reduces to searching for a single scalar parameter, target image similarity, that maximizes the downstream model's validation performance.
- We search for this target image similarity value via linear search.
- Empirically, we observe that this trade-off between the augmentation and empirical loss leads to better generalization ability of downstream model.
- Compared to existing automatic augmentation methods that require a large set of augmentation operations (usually 14-16 operations), RangeAugment is able to achieve competitive performance with only three simple operations (brightness, contrast, and additive Gaussian noise).
- Because RangeAugment's search space is independent of augmentation parameters and is fully differentiable (Fig. 1), it can be trained end-to-end with any downstream model to learn model-and task-specific policies.

## RELATED WORK
- Data augmentation combines different augmentation operations (e.g., random brightness, random contrast, random Gaussian noise, and data mixing) to synthesize additional training data.
- Traditional augmentation methods rely heavily on expert knowledge and extensive trial-and-error experiments.
- In practice, these manual augmentation methods have been used to train different models on a variety of datasets and tasks (e.g., Szegedy et al., 2015;He et al., 2016;Zhao et al., 2017;Howard et al., 2019).
- However, these policies may not be optimal for all models.
- Motivated by neural architecture search (Zoph & Le, 2017), recent methods focus on finding optimal augmentation policies automatically from data.
- AutoAugment formulates automatic augmentation as a reinforcement learning problem, and uses model's validation performance as a reward to find an augmentation policy leading to optimal validation performance.
- Because AutoAugment searches for several augmentation policy parameters, the search space is enormous and computationally intractable on large datasets and models.
- Therefore, in practice, policies found for smaller datasets are transferred to larger datasets.
- Since then, many follow-up works have focused on reducing the search space while delivering a similar performance to AutoAugment (Ratner et al., 2017;Lemley et al., 2017;LingChen et al., 2020;Li et al., 2020;Zheng et al., 2021;Liu et al., 2021a).
- The first line of research reduces the search time by introducing different hyper-parameter optimization methods, including population-based training (Ho et al., 2019), density matching (Lim et al., 2019;Hataya et al., 2020), and gradient matching (Zheng et al., 2021).
- The second line of research reduces the search space by making practical assumptions (Cubuk et al., 2020;Müller & Hutter, 2021).
- For instance, RandAugment (Cubuk et al., 2020) applies two transforms randomly with uniform probability.
- With these assumptions, RandAugment reduces AutoAugment's search space from 10 32 to 10 2 while maintaining downstream networks performance.
- One common characteristic among these different automatic augmentation methods is that they use fixed and manually-defined range of magnitudes for different augmentation operations, and focus on diversifying training data by using a large set of augmentation operations (e.g., 14 transforms).
- This is because the range of magnitudes for most augmentation operations is continuous and large, and searching over this large range is practically infeasible.
- Unlike these works, RangeAugment focuses on learning the magnitude range of each augmentation operation (Figs. 1 and 2).
- We show in Section 4 that RangeAugment is able to learn model-and task-specific policies while delivering competitive performance to previous automatic augmentation methods across different models.

## RA N G EAU G M E N T
- RangeAugment uses image similarity between the input and augmented image to learn the range of magnitudes for each augmentation operation.
- In the rest of this section, we first formulate the problem, then elaborate on RangeAugment's policy learning method, then we give implementation details.

## PROBLEM FORMULATION
- Let T = {T 1 , • • • , T N } be a set of N differentiable augmentation operations.
- Each augmentation operation T ∈ T is parameterized by a scalar magnitude parameter m ∈ R such that T (•; m) : X → X is defined on the image space X .
- Let π φ be an augmentation policy that defines a distribution over sub-policies S ∼ π φ in RangeAugment such that S = {T i (•; m i )} N i=1 .
- A sub-policy S applies augmentation operations to an input image x with uniform probability as S = {T i (•; m i )} N i=1 .
- For any given model and task, the goal of automatic augmentation is to find the augmentation policy π φ that diversifies training data, and helps improve model's generalization ability the most.
- RangeAugment learns the range of magnitudes for each augmentation operation in T .
- Formally, the policy parameters in RangeAugment are φ = {(a i , b i )} N i=1 and the magnitude parameter i=1 is uniformly sampled, where a i ∈ R and b i ∈ R are learned parameters.

## POLICY LEARNING
- Diverse training data can be produced by using wider range of magnitudes, (a i , b i ), for each augmentation operation.
- To address this, RangeAugment introduces an auxiliary loss which, in conjunction with the task-specific empirical loss, enables learning model-specific range of magnitudes for each augmentation operation in an end-to-end fashion.
- Let d : X ×X → R be a differentiable image similarity function that measures the similarity between the input and the augmented image.
- To control the range of magnitudes for each augmentation operation, RangeAugment minimizes the distance between the expected value of d(x, S(x)) and a target image similarity value ∆ ∈ R using an augmentation loss function L ra (e.g., smooth L1 loss or L2 loss).
- An example of d and ∆ are peak signal to noise ratio (PSNR) and target PSNR value respectively.
- When target PSNR value is small, the difference between the input and augmented image obtained after applying an augmentation operation (say brightness) will be large. In other words, for a smaller target PSNR value, the range of magnitudes for brightness operation will be wider and vice-versa.
- For a given value of ∆ and parameterized model f θ with parameters θ, the overall loss function to learn model-and task-specific augmentation policy is a weighted sum of the augmentation loss L ra and the task-specific empirical loss L task : where λ and D train represent weight term and training set respectively.
- Note that, in Eq. ( 2), re-parameterization trick on uniform distributions (Kingma & Welling, 2013) is applied to backpropagate through the expectation over S ∼ π φ .

## IMPLEMENTATION DETAILS
- We use PSNR as the image similarity function
- Across different downstream networks, we observe a 0.5%-3% training overhead over the empirical risk minimization baseline.
- To prevent this, we clip the range of magnitudes if they are beyond extreme bounds of augmentation operations.
- We choose these extreme bounds such that objects in an image are hardly identifiable at or beyond the extreme points of the bounds (see Fig. 4).
- Also, because the focus of RangeAugment is to learn the range of magnitudes for each augmentation operation, we apply all augmentation operations in T with uniform probability.
- We use smooth L1 loss as augmentation loss function

## EVALUATING RA N G EAU G M E N T ON IMAGE CLASSIFICATION
- RangeAugment can learn model-specific augmentation policies.
- To evaluate this, we first study the importance of single and composite augmentation operations using ResNet-50 on the ImageNet dataset.
- We then study model-level generalization of RangeAugment.

## EXPERIMENTAL SET-UP
- Single augmentation operation improves baseline accuracy.
- Composite augmentation operations improve model's generalization.
- Curriculum matters.

## MODEL-LEVEL GENERALIZATION OF RA N G EAU G M E N T
- RangeAugment is effective for ResNet-50
- RangeAugment's seamless integration ability with little training overhead (0.5% to 3%) over the baseline model allows us to study the generalization capability of different vision models easily
- Fig. 7 shows the performance of different models with RangeAugment
- When data regularization is increased for mobile models by decreasing the target PSNR value from 40 to 5, the training as well as validation accuracy of different mobile models is decreased significantly as compared to the baseline
- This is likely because of the limited capacity of these models
- Non-mobile models trained with RangeAugment are able to achieve competitive performance to state-of-the-art automatic augmentation methods, such as AutoAugment (N = 16), but with fewer augmentations (N = 3)

## Does RangeAugment increase variance on model performance?
- RangeAugment can cause variability in model performance
- The variability is in accordance with previous works

## COMPARISON WITH EXISTING METHODS
- RangeAugment achieves similar performance as previous methods, but with 4-5x fewer augmentation operations.
- The search space of RangeAugment is independent of the augmentation operations and is constant.

## Comparison with other models
- RangeAugment is effective across different models
- RangeAugment requires fewer augmentation operations than existing methods

## TASK-LEVEL GENERALIZATION OF RA N G EAU G M E N T
- RangeAugment is effective on different downstream models on the Im-ageNet dataset.
- RangeAugment can be used for tasks other than image classification.

## SEMANTIC SEGMENTATION WITH DEEPLABV3 ON ADE20K

## OBJECT DETECTION WITH MASK R-CNN ON MS-COCO
- The MS COCO dataset (Lin et al., 2014)
- It has about 118k training and 5k validation images across 81 catogries (including background)
- The instance detection and segmentation performance in terms of standar COCO mean average precision (mAP) on the validation set is reported
- Integrating mobile and non-mobile backbones with the Mask R-CNN (He et al., 2017) is also reported
- Following Detectron2 (Wu et al., 2019) which finetunes Mask R-CNN for about 270k iterations, the model is finetuned for similar number of iterations (230k iterations) with multi-scale sampler of (Mehta & Rastegari, 2021)

## Baseline augmentation methods
- We study Mask R-CNN with two augmentation methods: (1) Baseline -standard image resizing as in (He et al., 2017), and (2) RangeAugment -standard image resizing with learnable range of magnitudes for brightness, contrast, and noise.
- Searching for the curriculum We train Mask R-CNN with ResNet-50 for different target image similarity value, ∆.
- Fig. 8a shows that Mask R-CNN achieves the best performance when we anneal ∆ from 40 to 10.
- Transferring curriculum to other backbones We integrate different backbones with Mask R-CNN and finetune it by annealing ∆ from 40 to 10.
- Fig. 8b shows that RangeAugment improves the detection performance across backbones significantly.

## LEARNING AUGMENTATION FOR FOUNDATION MODELS AT SCALE
- RangeAugment improves the accuracy and data efficiency of large scale foundation models.
- CLIP (Radford et al., 2021) can be improved with RangeAugment.
- RangeAugment is less data-dependent than OpenCLIP.

## LEARNING AUGMENTATION FOR STUDENT MODEL DURING DISTILLATION
- RangeAugment can be used to learn the magnitude range for student model.

## Dataset and teacher details
- We distill knowledge from ResNet-101 to MobileNetv1 on the ImageNet dataset at different target image similarity values, ∆.
- Fig. 9a shows that MobileNetv1 achieves the best performance when we anneal ∆ from 40 to 20.
- This curriculum is different from our observations in Table 3, where we found that MobileNetv1 trained with ERM achieve best performance when we anneal ∆ from 40 to 30.
- Moreover, Fig. 9c shows that MobileNetv1 prefers wider magnitude ranges during KD as compared to ERM.
- RangeAugment's curriculum is transferable for other mobile models.
