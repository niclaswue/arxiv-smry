---
title: "Auxiliary Functions as Koopman Observables: Data-Driven Polynomial Optimization for Dynamical Systems"
date: 2023-03-02T18:44:18.000Z
author: "Jason J. Bramburger, Giovanni Fantuzzi"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2303-01483v1.webp" # image path/url
    alt: "Auxiliary Functions as Koopman Observables: Data-Driven Polynomial Optimization for Dynamical Systems" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2303.01483)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2303.01483).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/auxiliary-functions-as-koopman-observables).

# Abstract
- Presents a data-driven method for dynamical system analysis that does not require explicit model discovery.
- Method is implemented as a semidefinite program that can be solved numerically.
- Method is agnostic of whether data is generated through a deterministic or stochastic process.
- Rigorous convergence results justify the applicability of the method.

# Paper Content

## Introduction
- Koopman operator is a linear description of nonlinear systems
- Koopman operator can be approximated through EDMD
- EDMD has convergence guarantees
- EDMD can be used to provide system-level information from dynamic data
- Auxiliary functions can be used to prove statements about dynamical systems
- EDMD can be used to approximate auxiliary functions from data
- Method can be applied to a broad class of deterministic or stochastic dynamical processes

## A class of dynamical systems
- Introduces a general class of dynamical systems
- Includes deterministic and stochastic differential equations or maps
- Considers stochastic processes
- Deterministic systems can be viewed as stochastic ones

### The general case
- Let Xt denote the state of a stochastic process at time t.
- Expectation of a function ϕ at time s given Xt = x is denoted as E[ϕ(s, Xs)|Xt = x].
- Generator of the process is a linear operator L defined on Cb(T x X).
- Lie derivative of ϕ is Lϕ.
- Stochastic process is Markov and solves the martingale problem for its generator L.
- Koopman operator Kτ maps a function ϕ to Kτϕ.
- Family of Koopman operators is a contraction semigroup on Cb(T x X).

### Classical examples
- Processes X t are governed by deterministic maps, stochastic maps, ODEs, and stochastic differential equations.
- Condition (2.1a) holds with Lϕ(t, x) for deterministic maps and Brownian process for stochastic maps.
- Condition (2.1b) holds with Dynkin's formula and A, B = i,j A ij B ij .

## System analysis via auxiliary functions and lie derivatives
- Constructing auxiliary functions ϕ can help study properties of stochastic processes.
- This section reviews how these constraints encode the system's dynamics through the Lie derivative Lϕ.
- Examples of this are stability analysis and ergodic optimization.
- This framework can be used to bound stationary stochastic expectations.

### Global and local stability
- X is a d-dimensional space
- Process X is governed by a deterministic map or an ODE
- Time-independent functions are considered
- Lyapunov showed that the equilibrium point is globally stable if a continuous function V satisfies certain conditions
- This function must be non-negative and have a minimum at the equilibrium point
- Global asymptotic stability is obtained if the function is 0 at the equilibrium point and the inequalities are strict
- Local (asymptotic) stability can be proven by imposing the conditions in a neighbourhood of the equilibrium point

### Ergodic optimization
- Auxiliary functions can be used to estimate long-time averages.
- A continuous function D and a real number U can be used to determine the largest possible long-time average.
- A lower bound on the average can be derived by reversing the inequality sign in (3.4).
- Near-optimal auxiliary functions can be constructed computationally.

## Data-driven approximation of auxiliary functions
- Approximation of Lie derivatives and auxiliary functions using data-driven methods
- Results for discrete-time dynamics obtained by replacing quantities depending on a time increment τ with their values for τ = 1

### Approximation of the lie derivative
- Two finite dictionaries of observables in C b (T × X) are given: φ and ψ
- Span φ is assumed to be a subset of D(L) and span φ is assumed to be a subset of span ψ
- Data snapshots (t i , x i , y i ) are given
- EDMD framework approximates the action of the Koopman operator on span φ using an approximate Koopman operator K τ mn
- gEDMD framework assumes data snapshots are such that y i = Lφ(t i, x i )
- EDMD-based approximation L τ mn ϕ constructed in section 4.1.1 recovers G mn ϕ as τ → 0
- Approximate Lie derivatives can be combined with semidefinite programming to construct approximate auxiliary functions

### Integration with semidefinite programming
- Auxiliary functions can be constructed with semidefinite programming when X is finite dimensional.
- Assumptions A1, A2, and A3 are satisfied when a, b, c, φ, ψ and s are polynomials.
- A sufficient condition for (4.6a) is given.
- Construction of approximate auxiliary functions reduces to a semidefinite program.
- Relevant SDPs can be formulated automatically using open-source polynomial optimization toolboxes.

## Examples
- Constructs approximate auxiliary functions through semidefinite programming
- Uses yalmip, mosek and ChebFun to construct polynomial auxiliary functions
- Code to reproduce results available at given link

### Lyapunov functions
- Two-dimensional map has globally asymptotically stable equilibrium at origin
- Prove by finding Lyapunov function V (x, y) satisfying for some hyperparameter ε > 0
- Implemented two inequalities in (5.2) with ε = 1 and LV replaced by data-driven approximation
- Searched for polynomial V of degree 4
- Constructed V through semidefinite programming
- Maximizing ε subject to (5.2b) returns ε ≈ 0.9999

### Ergodic optimization for the van der pol oscillator
- Van der Pol oscillator is a second order ODE
- State-space is R2
- Seeking upper bounds on long-time average of energy
- Stable limit cycle attracts all initial conditions except unstable fixed point
- Synthetic data generated through numerical integration
- EDMD dictionary used to list monomials up to degree β
- Long-time average of energy is approximately 4.001
- Data-driven method can extract important system statistics before they can be observed in data
- Lie derivative approximated from data on limit cycle

### Ergodic optimization for a stochastic logistic map
- Stochastic logistic map is given by λt
- State-space is X = R and S = [0, 1] is positively invariant
- Seeking to place upper and lower bounds on long-time expected value of g(x) = x
- Auxiliary function framework for ergodic optimization applies to stochastic dynamics
- Construct approximate polynomial auxiliary functions of increasing degree α
- Represent polynomials using Chebyshev basis
- Assumptions (A1)-(A3) are met with u, v, and w
- Dataset consists of one trajectory of the map with initial condition x0 and n = 10^7 iterates
- EDMD matrix Kτmn converges at a O(1/√n) rate to its infinite-data limit Kτm∞
- Approximate upper and lower bounds on Xt converge to exact ones with increasing n
- Zero lower bound is sharp for (5.6)
- Upper bound decreases as α is raised and approaches 1/4 of stationary expectation of Xt

## Theoretical analysis
- Replacing exact Lie derivatives with data-driven approximations works well in practice.
- Approximate Lie derivatives converge to exact ones in the limits of infinite data, sampling rate, and EDMD dictionary.
- Results are similar to those already available in the literature.
- Proven for a broader class of stochastic processes and under weaker assumptions.

### Preliminaries
- Focus on continuous-time processes
- Lie derivative operator L is the generator of the process
- View C b (T × X), span φ and span ψ as subspaces of L 2 µ (T × X)
- Norm on this space is
- Projection of a function f ∈ L 2 µ (T × X) onto span ψ is
- Minimizer in this problem is unique in L 2 µ

### Exact and empirical data sampling measures
- Data snapshots (t, x, y) satisfy x = Xt and y = Xt + τ.
- Data points y are random variables with distribution νt,x.
- Each pair (t, x) is sampled from a probability measure µ on T × X.
- Joint distribution ρ of data snapshots is a probability measure on T × X × X.
- Empirical approximations of µ, νt,x and ρ can be built using data snapshots.
- Data snapshots can be sampled from a trajectory of the dynamical system or independently from ρ.

### A convenient problem reformulation
- Need to analyze convergence of approximate Lie derivatives
- Need to study n, m → ∞ and τ → 0 limits of matrices from (4.2) to (4.4)
- Lemma 6.1 provides identities for the matrices
- Lemma 6.2 resolves complication of pseudo-inversion
- Study limit of infinite data (n → ∞)
- Lemmas 6.1 and 6.2 show that EDMD approximations converge to L2μ-orthogonal projections of the latter onto span ψ
- Theorem 6.1 states that Kτmϕ, Lτmϕ and Gmϕ satisfy certain conditions
- BB†-I is a projection onto the kernel of B

### The infinite-sampling-rate limit
- Studied the limit of infinite sampling rate
- Linear operator P satisfies certain conditions
- Convergence in L2 implies pointwise convergence of Lτmϕ and Gmϕ
- More precise result: Lτmϕ → Gmϕ pointwise if certain condition is met
- Finite-data case: Lτmnϕ → Gmnϕ at least on data points

### The infinite edmd dictionary limit
- EDMD-based approximate Lie derivatives become increasingly accurate as the size of the approximation space span ψ increases.
- Assumption 6.2 requires that for every u in L2µ, there exists a u m in span ψ m that converges to u in L2µ.
- The approximate Lie derivatives converge to the exact Lie derivative pointwise on the full space if the dictionaries ψ m satisfy assumption 6.1.
- Assumption 1 requires that for all large enough m, Lϕ is in span ψ m for every ϕ in span φ ∩ D(L).
- Theorem 6.4 states that if assumption 1 holds, then G m ϕ = Lϕ on T × X.
- Convergence rates for EDMD-based identification of deterministic continuous-time systems can be found in [64].

## A further example illustrating the theory
- Assumption 6.1 must be met for Lie derivative approximations to work as expected.
- Results obtained with approximate auxiliary functions must be interpreted carefully.

### The problem
- System has an unstable equilibrium point at (0, 0) and an attracting circular limit cycle.
- Auxiliary function framework used to find lower bound on quantity g(x1, x2).
- Quadratic auxiliary function of the form used.
- γ chosen such that inequality holds for all x1, x2 and largest possible L.
- Lower bound L = 0 is sharp.

### Data-driven lower bound via edmd
- Approximate Lie derivative L τ mn V can be calculated analytically
- Data snapshots (t i , x i , y i ) sampled at a rate τ from the limit cycle
- Lower bound L = 1 applies only to the limit cycle and is sharp

### Data-driven lower bound via gedmd
- Used gEDMD-based approximate Lie derivative G mn V instead of L τ mn V
- Auxiliary function 2 has G mn V ≡ 0 independently of n
- Best lower bound provable with the inequality is L = 0

### Discussion
- EDMD- and gEDMD-based Lie derivatives behave differently when constructing auxiliary functions.
- In the infinite-data limit, the two functions do not recover the exact Lie derivative.
- As τ approaches 0, L τ m V converges to G m V only at certain points.
- Results for the van der Pol oscillator are different because its limit cycle is not an algebraic curve.

## Conclusion
- Provided a data-driven method for deducing information about dynamical systems without first discovering an explicit model
- Combines two areas: system analysis via auxiliary functions and data-driven approximation of the Koopman operator via EDMD
- Extended some known convergence results for EDMD to a broad class of stochastic systems
- Method can be applied to data generated by deterministic and stochastic dynamics
- Accurately obtain Lyapunov functions from data, provide sharp upper bounds on long-time averages
- Bounds expectations of stochastic processes
- Can be used as a pre-conditioner to discovering accurate and parsimonious dynamical models
- Computational bottlenecks when state-space dimension is not small
- Kernel-based EDMD formulation offers computational speed-up
- Establish convergence rates for certain classes of systems and dictionaries
- Quantify gaps between predictions made using data-driven auxiliary functions and their rigorous model-based counterparts
