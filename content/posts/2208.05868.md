---
title: "TotalSegmentator: robust segmentation of 104 anatomical structures in CT images"
date: 2022-08-11T15:16:40.000Z
author: "Jakob Wasserthal, Manfred Meyer, Hanns-Christian Breit, Joshy Cyriac, Shan Yang, Martin Segeroth"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2208-05868v1.webp" # image path/url
    alt: "TotalSegmentator: robust segmentation of 104 anatomical structures in CT images" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2208.05868)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2208.05868).


# Abstract
- The code and data for most segmentation algorithms is not publicly available or difficult to use
- Many segmentation algorithms suffer from 3 problems: 1. They are difficult to use, 2. They do not generalize, 3. They can only segment one anatomical structure

# Paper Content

## Introduction
- The number of radiological images is increasing
- There is a need for computer-based evaluation methods
- One important building block for the automatic analysis of radiological images is the segmentation of major anatomical structures
- There has been a lot of work on segmenting specific anatomical structures, e.g. pancreas (Simpson et al., 2019), spleen (Simpson et al., 2019), colon (Gayathri Devi & Radhakrishnan, 2015), lung (Hofmanninger et al., 2020) and many more
- However, all of those models only cover a small subset of relevant anatomical structures and train on a dataset which is not representative of a typical clinical population
- To the best of our knowledge, this is the first work trying to segment over 100 classes
- The closest work is from Chen et al. (Chen et al., 2021) which segments 50 classes
- However, they are still missing many classes, the dataset as well as the model is not publically available (the model can only be accessed via uploading data to a web interface) and the dataset is less diverse (the majority of the training data comes from the same scanner and uses the same CT sequence)

## Methods

### Data selection
- The dataset was collected from 10 years of CT scans of patients with general research consent
- Only images from patients with a general research consent were used
- CT images of legs and hands were excluded
- The dataset contains CT images with different sequences (native, arterial, portal venous, late phase, dual energy), with and without contrast agent, with different bulb voltages, with different slice thicknesses and resolution and with different kernels (soft tissue kernel, bone kernel)
- If the human expert annotator was unsure how to segment certain structures because of high ambiguity (e.g. structures highly distorted by pathologies), the examination was excluded

### Data annotation
- Based on clinical experience, 104 anatomical structures were identified for segmentation
- The classes of our model were identified by using existing models or by manual segmentation
- Refinement of segmentations and manual segmentation was supervised by a board-certified radiologist
- To be able to segment the different heart subparts (left/right atrium, left/right ventricle, myocardium, pulmonary artery) on all different CT series (also without contrast agent), the following approach was taken:
- An inhouse dataset was available with ground truth segmentations of the heart subparts on CT images with contrast agent.
- For each image with contrast agent also a native CT image without contrast agent was available.
- Since this image was from the same examination it was well aligned with the contrast agent image. So, we transferred the segmentation to the CT images without contrast agent and trained a U-Net (Ronneberger et al., 2015) on images with and without contrast agent.
- This model was then used to predict the heart subparts in our dataset, resulting in very accurate segmentations of the heart subparts in all kinds of CT sequences.
- To speedup manual segmentation we used the Nora imaging platform (Anastasopoulos et al., 2017).
- Compared to traditional tools like MITK (Wolf et al., 2005), Nora provides the following advantages:
- First, subjects do not have to be loaded individually, instead Nora provides a list of all subjects.
- Second, segmentation masks do not have to be created and saved individually for each image, but whenever you change the subject in Nora, the correct masks are created, named and saved automatically.
- Third, the autoloading as well as the view (e.g. the intensity window) can be configured for each project individually.
- Thus, it took us only 17 s in Nora to load the case, create a segmentation mask and save the segmentation mask, whereas with MITK this procedure took us 45 s.
- Forth, an even higher speedup is achieved by doing rough segmentations instead of pixel perfect segmentations. Those rough segmentations were preliminary and not sufficient for the final result. However, the U-Net is good at learning good segmentations from rough segmentations. The errors in the rough segmentations are rather random across subjects (no systematic error) and therefore the U-Net learns to ignore the random part of the segmentation and keeps the consistent part which aligns pretty well with the anatomical structure.
- Figure 3 shows how the U-Net produces a smooth segmentation from the rough input.
- Fifth, since rough segmentations are sufficient we used a pencil for segmentation which draws through 3 slices at the same time, providing another speedup.
- Exemplary, detailed segmentation of the urinary bladder takes 10 min whereas rough segmentation only takes 1 min 25 s and the U-Net produces accurate results also from these rough segmentations.
- Overall, using a traditional segmentation approach takes 45 s for loading/saving and 10 min for segmentation whereas using our approach it only takes 17 s for loading/saving and 1 min 25 s for segmentation.

### Model
- The nnU-Net is a U-Net implementation which automatically configures all hyperparameters
- This approach has been shown to deliver state of the art results
- When performing larger studies on many thousand subjects the "-fast" option can be helpful to make processing of so many subjects feasible

### Evaluation
- The dataset of 1204 subjects was randomly split into 1082 training subjects (89.9%), 57 validation subjects (4.7%) and 65 subjects for final testing (5.4%).
- All results are reported on the test set.
- As metric, we used the Dice score as well as the normalized surface distance (NSD) (using the function "compute surface dice at tolerance" from https://github.com/deepmind/surface-distance).
- For many applications (e.g. localisation of a certain organ) it is not necessary to precisely segment the organ boundary as long as the overall segmentation is correct.
- For this, the surface distance is a good measure.
- We set the threshold to 3 mm.
- This means that all areas of the segmentation surface are counted as correct if they are within 3 mm of the ground truth segmentation surface.
- Just as the Dice score, the NSD scores ranges between 0 and 1 with 1 being the best score.
- Moreover, the Dice score is biased towards big classes: the inner voxels are normally easier to predict than the border voxels, but in the Dice score they are equally weighted.
- In big classes, the ratio of inner voxels to border voxels is typically high and therefore the Dice score tends to be better.
- In contrast, the normalized surface distance with a high threshold of 3 mm is biased towards small classes: For thin structures like the iliac arteries almost the entire structure is within the 3 mm threshold. So the segmentation could miss parts of the class and still be counted as correct because it is within the 3 mm threshold.
- Therefore, looking at both metrics is important for proper evaluation.
- For each class in each subject the respective metric is calculated and then the mean is taken across all classes and subjects (micro-average).
- As additional evaluation we compared our model to a nnU-Net trained on the dataset from the "Multi-Atlas Labeling Beyond the Cranial Vault Challenge" https://doi.org/10.7303/syn3193805 (nnU-Net Task 17).
- With this model we predicted our test set and compared the results to our model.

## Results

### Overall results
- The two models have good accuracy
- The model trained on CTs with a slice thickness of 1.5 mm shows high accuracy
- For the 3 mm model the Dice score is reduced to 0.85, while the NSD is over 0.96

### Results per class
- Figure 5 shows the results for all classes independently.
- We grouped similar classes (e.g. left and right, all ribs, all vertebrae) for better readability.
- Results vary between 0.87 and 1.0.

### Comparison to other model
- Figure 7 shows the comparison of a high resolution model to a model trained on data from the "Multi-Atlas Labeling Beyond the Cranial Vault Challenge".
- The high resolution model achieves a higher dice and a higher NSD score.

### Runtime
- Table 8 shows an overview of the runtime, RAM requirements as well as GPU memory requirements of the high resolution (1.5 mm) and the low resolution model (3 mm) on three different CT images with different dimensions.
- The runtime was measured on a local workstation with a NVidia GeForce RTX 3090 GPU.
- Figure 8 shows an overview of runtime, RAM requirements as well as GPU memory requirements of the high resolution (1.5 mm) and the low resolution model (3 mm) on three different CT images: A small image of only abdomen with shape 512x512x280 voxels, a medium image of the thorax and abdomen with shape 512x512x458 voxels and a large image from head to knee with shape 512x512x824 voxels.

### Typical failure cases
- The model produces highly accurate results
- The model is robust
- There are a few typical failure cases which occur in roughly 15% of the subjects
- Being aware of those can be helpful when using the segmentations of the affected classes

### Application example
- The model can be used to study how different anatomical structures change over the lifespan
- The model can be used to study how density and volume change over the lifespan
- The model can be used to study how bone density changes over the lifespan

## Conclusion
- The model was able to produce accurate segmentations across a very diverse dataset which is directly sampled from clinical routine.
- We hope that many researchers find our model helpful for their use cases.
- We made it openly available on github (https://github.com/wasserth/TotalSegmentator) and it can be easily installed via pip.
- It can be easily used to segment anatomical structures, for example, by using it to create a high resolution model of a polytrauma cohort.
- The model is able to produce accurate predictions for a wide range of different characteristics, for example, age or gender. However, it is possible for it to fail in roughly 15% of the subjects.
