---
title: "SADM: Sequence-Aware Diffusion Model for Longitudinal Medical Image Generation"
date: 2022-12-16T01:35:27.000Z
author: "Jee Seok Yoon, Chenghao Zhang, Heung-Il Suk, Jia Guo, Xiaoxiao Li"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2212-08228v1.webp" # image path/url
    alt: "SADM: Sequence-Aware Diffusion Model for Longitudinal Medical Image Generation" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2212.08228)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2212.08228).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/sadm-sequence-aware-diffusion-model-for).

# Abstract
- Human organs constantly undergo anatomical changes due to a complex mix of short-term (e.g., heartbeat) and long-term (e.g., aging) factors.
- Evidently, prior knowledge of these factors will be beneficial when modeling their future state, i.e., via image generation.
- However, most of the medical image generation tasks only rely on the input from a single image, thus ignoring the sequential dependency even when longitudinal data is available.
- Sequence-aware deep generative models, where model input is a sequence of ordered and timestamped images, are still underexplored in the medical imaging domain that is featured by several unique challenges: 1) Sequences with various lengths; 2) Missing data or frame, and 3) High dimensionality.
- To this end, we propose a sequence-aware diffusion model (SADM) for the generation of longitudinal medical images.
- Recently, diffusion models have shown promising results on high-fidelity image generation.
- Our method extends this new technique by introducing a sequence-aware transformer as the conditional module in a diffusion model.
- The novel design enables learning longitudinal dependency even with missing data during training and allows autoregressive generation of a sequence of images during inference.
- Our extensive experiments on 3D longitudinal medical images demonstrate the effectiveness of SADM compared with baselines and alternative methods.

# Paper Content

## Introduction
- State-of-the-art computational hardware and availability of medical datasets are important factors in the success of iconic advancements in generative models in the medical domain
- Recent efforts to generate longitudinal medical image are mainly proposed for the following two tasks: 1) generation of longitudinal brain image, which take a source brain image and generate a new image with respect to chronological age (i.e., normal) progression or disease (i.e., abnormal) progression
- To this end, we explore ways to address these issues and propose a novel generative model for longitudinal medical image generation that can learn the temporal dependency given a sequence of medical images
- Our proposed method is named sequence-aware diffusion model (SADM) and can work in various real-world settings, such as single image input, longitudinal data with missing frames, and high-dimensional images

## Preliminary

### Diffusion Models
- Diffusion models consist of a forward process, which starts with the data x ∼ p(x) and gradually adds noise to obtain a noisy version of the data z = {z t |t ∈ [0, 1]}, and a reverse process, which reverts the forward process by predicting and subtracting the noise in the reverse direction (i.e., from t = 1 to t = 0).
- The forward process can be reformulated in the reverse direction as q(z s |z t , x) = N ( μs|t (z t , x), (σ 2 s|t )I), where μs|t (z t , x) = e λt−λs (α s /α t ) z t + 1 − e λt−λs α s x and σ2 s|t = 1 − e λt−λs σ 2 s .
- The reverse process is parameterized by a generative model xθ in the form: where the variance Σs|t = (σ 2 s|t ) 1−v (σ 2 t|s ) v is an interpolation between σ2 s|t and σ 2 t|s [12], and v is the hyperparameter that controls the stochasticity of the sampler [13].

### Classifier-free Guidance
- Classifier-guided conditioning is used for diffusion models, but it is often difficult to define the problem setting for a classifier
- We propose a classifier-free diffusion model that uses a conditioning signal as an additional input
- The classifier-free guided diffusion model takes the conditioning signal c as an additional input and is defined as the weighted sum of the model with condition c and model with zero tensor ∅
- The guidance strength w controls the tradeoff between sample quality and diversity, and can be set to a high value to reduce the diversity of the generated images
- The temporal encoder and spatial decoder are factorized into a temporal encoder and a spatial decoder that can benefit from long-range spatio-temporal attention with high computational efficiency

### Conditional Diffusion Model
- The proposed SADM follows the formulation of classifier-free diffusion model [8]
- Extends this diffusion model by using a sequence-aware conditioning signal explained in the previous section
- Uses an autoregressive sampling scheme that can effectively capture the long-distance temporal dependency during inference

## Experiments
- Our proposed SADM is effective in medical image generation
- Our proposed SADM is better than GAN-based and diffusion-based baselines
- An ablation study of our model components is presented.

### Dataset and Implementation
- We use the multi-frame cardiac MRI curated by ACDC organizers [3]
- A common task for cardiac image generation is to synthesize the final frame of a cardiac cycle (i.e., end-systolic or ES) given a starting frame of the cycle (i.e., end-diastolic or ED)
- The ACDC dataset consists of cardiac MRI from 100 train subjects and 50 test subjects
- We take intermediate frames from ED to ES and resize them to X ∈ R 12×128×128×32 , where each dimension is the length of the frame, the width, the height, and the depth, respectively
- Then we Min-Max normalize the dataset subject-wise
- Although MRI resizing results in uneven resolution, we opt for this approach, as it is the most reproducible preprocessing method
- For training, we randomly select conditioning, missing, and future indices
- During inference, we experiment with three settings: 1) Single image, where only the ED is used as input, 2) Single image and a pre-trained model, where the model is used to predict missing values, and 3) Multi-image and a pre-trained model, where the model is used to predict missing values and future indices

### Comparison with Baseline Methods
- SADM uses a UNet-based GAN model to synthesize an ES frame given an ED frame
- SADM shows a better depiction of the blood pool (red box) compared to the baseline methods
- Other areas surrounding the blood pool, such as the  myocardium and ventricles, are also synthesized with higher fidelity
- For brain image generation, the ventricular regions (blue box) synthesized by SADM are more crisp compared to baselines, and the cortical surface is synthesized more accurately
- Then, we perform a quantitative comparison by calculating the SSIM, PSNR, and normalized RMSE between the target and the synthesized ES frame. Our model outperforms the GAN-based method [4] by 3 ∼ 13% in each metric while slightly outperforming the diffusion-based model [11]

### Ablation Study
- Experiment with different settings for the input sequence defined in the first paragraph of Section 4.1
- Observe that the SADM is learning which frames of the input sequence are important in generating future frames
- Remove either the attention module or the diffusion model and see that the diffusion-only model performs on par with GAN-based baseline

## Conclusion
- Limitations diffusion models are computationally hungry models
- Our proposed SADM uses an autoregressive sampling scheme, which needs to synthesize images in the previous indexes to generate the target image
- Alternative self-conditioning sampling methods for the video diffusion model have been explored in [6]
- Sampling efficiency of diffusion models is a very active research topic, so we hope to find a solution for this in the near future
- To this end, we propose a sequence-aware diffusion model for the generation of longitudinal medical images
- Specifically, our model consists of a transformerbased attention module that can learn the sequential or temporal dependence of longitudinal data input and a diffusion model that can synthesize high-fidelity medical images
- We tested our proposed SADM on longitudinal cardiac and brain MRI generation and presented state-of-the-art performance quantitatively and qualitatively
- To the best of our knowledge, we are one of the first to explore the temporal dependency of sequential data and use it as a prior in diffusion models for medical image generation
- We hope to inspire researchers to actively engage in this newly found research topic
