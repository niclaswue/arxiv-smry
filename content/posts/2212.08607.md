---
title: "MURMUR: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text Generation"
date: 2022-12-16T17:36:23.000Z
author: "Swarnadeep Saha, Xinyan Velocity Yu, Mohit Bansal, Ramakanth Pasunuru, Asli Celikyilmaz"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2212-08607v1.webp" # image path/url
    alt: "MURMUR: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text Generation" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2212.08607)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2212.08607).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/murmur-modular-multi-step-reasoning-for-semi).

# Abstract
- Large language models have enabled significant recent progress in multi-step reasoning over text
- However, when applied to text generation from semi-structured data (e.g., graphs or tables), these methods typically suffer from low semantic coverage, hallucination, and logical inconsistency
- We propose MURMUR, a neuro-symbolic modular approach to text generation from semi-structured data with multi-step reasoning
- MURMUR is a best-first search method that generates reasoning paths using: (1) neural and symbolic modules with specific linguistic and logical skills, (2) a grammar whose production rules define valid compositions of modules, and (3) value functions that assess the quality of each reasoning step
- We conduct experiments on two diverse data-to-text generation tasks like WebNLG and LogicNLG
- MURMUR obtains significant improvements over recent few-shot baselines like direct prompting and chain-of-thought prompting, while also achieving comparable performance to fine-tuned GPT-2 on out-of-domain data
- Moreover, human evaluation shows that MURMUR generates highly faithful and correct reasoning paths that lead to 26% more logically consistent summaries on LogicNLG, compared to direct prompting.

# Paper Content

## Introduction
- Data-to-text generation is the task of generating fluent, faithful, and consistent summaries of semi-structured data.
- Recent works have introduced different data-to-text generation tasks wherein the data is represented in diverse structures, like meaning representations (Novikova et al., 2017), graphs (Gardent et al., 2017), or tables (Lebret et al., 2016;Parikh et al., 2020;Chen et al., 2020a).
- Text generation from such data is challenging because it extends surface realization of the input content and requires various reasoning and compositionality skills, such as filtering a table based on a certain criterion, retrieving the maximum value from a table column, etc.
- Recent works fine-tune pre-trained language models (Radford et al., 2019;Raffel et al., 2020) as the de-facto standard for building supervised data-to-text generation systems (Kale and Rastogi, 2020;Agarwal et al., 2021). However, this requires a large amount of domain-specific parallel data, which is expensive to obtain, and training models on such data also affects out-of-domain generalization (Laha et al., 2020;Dušek et al., 2020).
- Motivated by the recent success of few-shot prompting in multi-step reasoning over text (Wei et al., 2022;Nye et al., 2021;Wang et al., 2022a;Dohan et al., 2022), we pose data-to-text generation as multi-step reasoning over data.
- Reasoning over data brings its own set of challenges, especially in the context of text generation:
- Firstly, directly prompting large language models (LLMs) can cause models to suffer from low semantic coverage, hallucinations, and logically inconsistent generations when reasoning over complex forms of data, like tables (see red marked phrases for the Direct Prompting summaries in Fig. 1).
- Other prompting methods like Chain-of-Thought (CoT) encourage LLMs to also generate intermediate reasoning steps (Wei et al., 2022). However, it compromises the transparency, faithfulness,2 and correctness of the reasoning process due to the lack of explicit conditioning between the reasoning steps (Creswell and Shanahan, 2022).
- Unlike text, which is a sequence of tokens, data is typically represented as a set of elements (e.g., a graph is a set of edges while a table is a set of rows, as shown in Fig. 1). Hence, a model that reasons over data must be transformation-invariant (Wang et al., 2022a).
- For instance, the summary generated from a table should be invariant to randomly shuffling the rows of the table. Thus, prompting methods that linearize the data in an arbitrary order, can be prone to some variance (see Table 3 and 6).
- We propose MURMUR, a modular multi-step reasoning approach to text generation from data ( §3).
- It is a best-first search algorithm ( §3.4) that generates reasoning paths (see examples in Fig 1) with three features:
- (1) Modularity ( §3.1): MUR-MUR defines a set of neural and symbolic modules with diverse input/output data types that constitute multiple steps in a reasoning path. Neural modules perform linguistic skills that LLMs are good at (e.g., the Surface Realization module in Fig. 1 converts a reasoning path to a natural language summary) and symbolic modules perform logical skills that they mostly struggle with (Wang et al., 2022b;Gao et al., 2022) (e.g., the argmin module in Fig. 1 finds the row with...

## Definitions: Reasoning Step and Path
- Surface Realization: M sr : t → s
- Text Fusion: M tf : (s 1 , s 2 ) → s
- Inference: M inf : (x, y) → p
- Conditional Logic: M cl : (x, y) → q
- Disjunctive Logic: M dl : (x, y) → r
- Quantified Logic: M ql : (x, y) → s
- First-Order Logic: M fl : (x, y) → t
- Second-Order Logic: M s2 : (x, y) → u
- Higher-Order Logic: M hl : (x, y) → v
- A module is a neural or symbolic function that takes an input and produces an output.
- A reasoning step is a triple (M, X, y) where a module M performs a certain skill by conditioning on an input X to generate an output y.
- A reasoning path is a sequence of such reasoning steps {(M i , X i , y i )} r i=1 .
- A Surface Realization module M sr : t → s converts a triple t (with data type Triple) into a short sentence s (with data type String).
- A Text Fusion module M tf : (s 1 , s 2 ) → s combines two pieces of text s 1 and s 2 (with data types String) into a coherent text s.
- A Higher-Order Logic module M hl : (x, y) → v converts an arbitrary logical expression x → y into a sentence.

### Grammar over Modules
- The grammar determines a set of plausible modules in a reasoning step and how they should be composed.
- Each production rule defines multiple permissible modules. For example, the production rule 'Table → Number' (meaning that a number can be generated from a table) is valid for both max and min modules.
- When MURMUR searches for reasoning paths, the grammar reduces the search space (over all possible modules) by only selecting the ones that can be composed at each reasoning step.

### Value Functions
- The grammar helps reduce the search space by defining permissible compositions of modules
- Each reasoning step can still have multiple plausible modules and each module can also have multiple plausible inputs to choose from
- Thus, MURMUR introduces value functions that assess the quality of each plausible reasoning step (module and input to it) by scoring, ranking, and selecting the best reasoning step(s)
- Value Function for Graph-to-Text Generation: In a Graph-to-Text generation task, each intermediate reasoning step r generates a summary y r for a subset of edges (triples) G r from the input graph (see Fig. 7 for an illustration)
- MURMUR introduces value functions that assess the following two aspects of the generated summary y r : Fluency is measured by log-likelihood of the generated text similar to BARTScore (Yuan et al., 2021), and Semantic Consistency measures the average logical entailment probability P e (•) between the generated text y r and input triples G r5 and vice-versa
- We use an NLI model to infer entailment probabilities
- The both-way entailment scores capture equivalence between the triples and the generation, ensuring that the latter not only covers all the triples but also does not hallucinate any new information
- Overall score S(•) is an ensemble of the two scores:
- Value Function for Table-to-Text Generation: For these tasks, our value function can be used to choose the best module(s) at each reasoning step, as well as the best input(s) for the corresponding module(s)
- 6 For instance, if a reasoning step generates a number from a table (according to the grammar), the value function should determine the best module(s) between max, min, etc, as well as which column should the max or min module be operating on.

### Graph-to-Text Generation
- Contains RDF triples from DBPedia (Auer et al., 2007)
- The test split consists of two parts - the first half contains DB categories seen in training data, and the second half contains 5 unseen categories, which are used to evaluate model generalization
- We implement both modules, Surface Realization and Text Fusion as few-shot neural models by prompting a large language model, OPT-175B (Zhang et al., 2022) with skill-specific prompts
- We perform greedy decoding to generate text from each module
- Value Function
- As part of the value function described in §3.3, we compute fluency score using the log probabilities estimated by the OPT-175B model
- The entailment probability for the semantic scorer is based on a state-of-the-art DeBERTa-base model (He et al., 2020) trained on a collection of eight NLI datasets
- We choose the mixing ratio α between the two scorers to be 0.05

### Table-to-Text Generation
- We implement all logical modules, as described in §3.1, with PYTHON functions.
- We prompt OPT-175B for the Surface Realization module that converts a reasoning path into a natural language summary (see Appendix D for the prompt).
- Our saliency metric is a binary classifier. Specifically, we train a BERT-base model that takes a table (linearized into a sequence of rows) and a partial reasoning path as input and classifies it as correct or incorrect.
- During inference, we consider the correct class probability as the saliency score.
- We obtain training data for our model from the Logic2Text dataset (Chen et al., 2020c) that annotates open-domain tables with gold reasoning paths.
- Given a gold reasoning path, we create correct partial paths by breaking it at each intermediate step/module and incorrect paths by performing two types of perturbations on every correct partial path: (1) replacing the module at the current step with another module of same data type (e.g., replacing module max with module min); (2) replacing the inputs to the module with other plausible inputs (e.g., replacing max over column c 1 with max over column c 2 ).
- See Fig. 5 and appendix C.4 for an illustration of the training data creation process.
- We choose 221 (table, reasoning path) pairs from the Logic2Text dataset and convert them into 1500 correct and incorrect training samples consisting of (table, partial reasoning path) pairs.
- While choosing the samples, we ensure that the corresponding tables have no intersection with those in the test and validation sets of Logic-NLG.
- We choose the beam size of the search to be 20 (see further analysis of varying beam sizes in appendix C.3).

## Experiments on Graph-to-Text Generation
- We discuss our experimental findings on the WebNLG dataset.
- Baselines. We compare MURMUR to several state-of-the-art supervised methods from prior work which are trained on 37k (The surface realization (SR) step of converting the path to summary is left unchanged).
- In the second ablation, we remove the saliency metric from MURMUR by selecting the module (and its inputs) at each step randomly (but according to the grammar).
- All few-shot methods use 1 randomly chosen demonstration from the training data.
- Metrics. Following prior work (Chen et al., 2020a), we compare all methods with BLEU scores. Chen et al. (2020a) also propose some logical fidelity metrics like using an NLI model to evaluate logical consistency between the summary and the table. However, we found such learned metrics do not correlate well with humans and instead, we conduct more reliable human evaluations for evaluating logical correctness of MURMUR ( §6.2).
- Table 6 shows the results on the test set of LogicNLG. We draw the following conclusions.
- Even without this metric, all reasoning paths generated by MURMUR are still valid because of its grammar component.
- In appendix C.4, we analyze the effect of varying the amount of supervision for the saliency metric on downstream LogicNLG performance.

### Human Evaluation of Final Generations and Intermediate Reasoning Steps
- DP and MURMUR produce similar summaries
- MURMUR is more accurate and faithful to the data
- MURMUR can be used to generate summaries for data that DP cannot

### Effect of Number of Demonstrations
- DP outperforms MURMUR in terms of METEOR score
- The improvements for DP are marginal, while for MURMUR these are significant
- DP implicitly learns the underlying step-wise reasoning process, while such phenomenon is explicitly captured through one demonstration in MURMUR

## Experiments on Table-to-Text Generation
- LogicNLG is a machine learning algorithm that can identify logical statements
- The algorithm is able to identify logical statements from text
- The algorithm is able to identify logical statements from images
- The algorithm is able to identify logical statements from videos
- The algorithm is able to identify logical statements from a variety of sources
- The algorithm is able to identify logical statements from a variety of languages
- The algorithm is able to identify logical statements from a variety of formats
- The algorithm is able to identify logical statements from a variety of data sets

### Human Evaluation of Logical Correctness
- Next, they conduct human evaluation to assess the logical correctness of the generations from Direct Prompting and MURMUR.
- Two NLP experts annotate the generated generations for correctness.
- MURMUR generates 26% more correct outputs and 95% of the generated generations involve some underlying logical operations.

### Multi-step Reasoning over Text
- Recent large language model developments have enabled significant progress in few-shot methods for logical reasoning tasks
- Chainof-thought prompting encourages language models to output intermediate reasoning steps before generating the final answer, but the reasoning steps are all generated in one go from a single model, potentially leading to unfaithful reasoning
- MURMUR overcomes this issue by developing granular modules that are capable of performing specialized skills by explicitly condition-ing on the outputs from previous reasoning steps.

### Modular Reasoning over Text
- MURMUR follows a body of work on Neural Module Networks
- MURMUR's modules are a generalization of text-in text-out modules
- The transition from data to text is also clearly represented through the compositions of our modules

### Data-to-Text Generation
- Existing methods for data-to-text generation can be broadly grouped into three categories - supervised methods, pipeline approaches, and few-shot methods.
- MURMUR is a new few-shot method that does not require access to any unlabeled corpus.
- MURMUR is well-suited for use with as few as one demonstration.

## Discussion and Conclusion
- We presented MURMUR, a neuro-symbolic modular reasoning approach for data-to-text generation.
- Through extensive experiments on two tasks, WebNLG and LogicNLG, we demonstrated that MURMUR significantly outperforms few-shot baselines such as Direct Prompting and Chain-of-Thought Prompting, achieves comparable performance to fine-tuned LMs like GPT-2, and generates significantly more logical summaries.
- MURMUR shows the benefits of building interpretable modular text generation systems by breaking a task down into sub-problems and then solving them through separate modules, without requiring module-specific supervision.
- It utilizes the power of large language models in solving linguistic subtasks through in-context learning, while delegating the logical sub-tasks to symbolic modules.
- This, in turn, facilitates the introduction of a grammar for explaining module compositions (analogous to function compositions).
- Future work could explore extending MURMUR for text generation tasks that involve reasoning over multiple modalities, such as text, semi-structured data, and images.
- Training Data Construction.
- In Fig. 5, we show an illustrative example of the training data creation process for our saliency metric.
- In 'Incorrect Partial Path-1', when we perturb the avg module with the sum module, we aim to teach the model that although both are valid reasoning steps, averaging over the column 'points' is a more salient and informative reasoning step than summing over the column 'year'. Similarly, in 'Incorrect Partial Path-2', when we perturb the input to the module avg by performing average over the column 'wins', we want the model to learn the salient columns to reason over for a given module.
- Effect of Varying Supervision on Metric Accuracy and Downstream Performance.
- We conduct an in-depth analysis of the saliency metric used to score the reasoning steps in MURMUR. As shown in Table 12, we vary the amount of supervi- sion over the modules and observe that the metric accuracy improves with more supervision. However, the downstream performance is not affected much by the amount of supervision.
- We also vary the number of prompts and observe that the model generates more logical summaries with more prompts.
