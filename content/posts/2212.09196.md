---
title: "Emergent Analogical Reasoning in Large Language Models"
date: 2022-12-19T00:04:56.000Z
author: "Taylor Webb, Keith J. Holyoak, Hongjing Lu"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2212-09196v1.webp" # image path/url
    alt: "Emergent Analogical Reasoning in Large Language Models" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2212.09196)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2212.09196).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/emergent-analogical-reasoning-in-large).

# Abstract
- Recent advent of large language models - large neural networks trained on a simple predictive objective over a massive corpus of natural language
- Human cognitive capacities might emerge in such generic models given sufficient training data
- In human cognition, this capacity is closely tied to an ability to reason by analogy
- We performed a direct comparison between human reasoners and a large language model (GPT-3) on a range of analogical tasks, including a novel text-based matrix reasoning task closely modeled on Raven's Progressive Matrices
- We found that GPT-3 displayed a surprisingly strong capacity for abstract pattern induction, matching or even surpassing human capabilities in most settings. Our results indicate that large language models such as GPT-3 have acquired an emergent ability to find zero-shot solutions to a broad range of analogy problems.

# Paper Content

## Introduction

## Results
- GPT-3 is a transformer-based language model containing 175 billion parameters, trained on a web-based corpus of natural language consisting of over 400 billion tokens
- The first training objective was the standard predictive objective used to train language models, in which, given a string of natural language, the model is trained to predict the token that will most likely appear next.
- The key feature distinguishing this more recent instance of GPT-3 from its predecessors was the use of an additional alignment objective, intended to improve its ability to accurately respond to humangenerated prompts.
- Our primary evaluation focuses on a novel text-based matrix reasoning task that we designed to emulate the structure and complexity of Raven's Standard Progressive Matrices (SPM).
- The task is illustrated in Figure 1.
- We also evaluated GPT-3 on letter string analogies and four-term verbal analogies.

### Matrix reasoning problems
- The Digit Matrices dataset is a text-based problem set that is comparable to SPM, but guaranteed to be novel for both humans and LLMs.
- Transformation problems consisted of either digit transformations or logic problems.
- Logic problems were defined based on a single rule involving a set relation: OR, AND, or XOR.
- Transformation problems were solved zero-shot, and multiple-choice performance was assessed by presenting the problem along with each potential answer choice, and selecting the choice with the highest average log probability.
- GP-3 outperformed human participants on all problem types, both in terms of generative accuracy (Figure 3a; logistic regression, main effect of GPT-3 vs. human participants: p < 0.0001), and multiple-choice accuracy (Figure 3b; main effect of GPT-3 vs. human participants: p < 0.0001).
- Despite this difference in overall performance levels, GPT-3 and human participants showed a similar pattern of performance across problem subtypes (correlation analysis: r = 0.39, p = 0.029).

### Letter string analogies
- We presented letter string analogies to GPT-3 in the same format used for the Digit Matrices, preceded by the prompt 'Let's try to complete the pattern:'.
- We also evaluated GPT-3 without this prompt, and on an alternative format in which problems were presented in the form of a sentence (e.g., 'If a b c changes to a b d, what should i j k change to?').
- For each problem type, we generated multiple instances by varying the letters used in the target.
- This resulted in 18 basic successor relation problems, 16 problems involving the removal of a redundant character, 6 letter-to-number problems, 18 grouping problems, 16 problems with a longer target, 17 successor-to-predecessor problems, and 17 problems used as context to test for relational priming.

### Four-term verbal analogies
- GPT-3 was evaluated on the UCLA-VAT dataset
- The log probability associated with the final term (D or D') was used to select an answer choice.

### Analogy in natural language problem-solving
- Analogical reasoning is often assessed via well-controlled tasks such as matrix reasoning problems or fourterm verbal analogies
- Human reasoners can exploit analogies between complex real-world inputs such as stories or images, using them to derive solutions to novel problems
- Given GPT-3's ability to process a relatively large amount of text-based input, we examined whether it would be capable of solving more complex naturalistic analogy problems based on stories
- We evaluated GPT-3 using a paradigm developed by Gick and Holyoak [17]. In that paradigm, participants are presented with a target problem in the form of a story.
- In the original study, Duncker's radiation problem was used [31]. In that problem, a doctor wants to use radiation to destroy a malignant tumor, but destroying the tumor with a single high-intensity ray will also damage the surrounding healthy tissue.
- The solution -to use several low-intensity rays that converge at the site of the tumor -is rarely identified spontaneously, but participants are more likely to discover this solution when they are first presented with an analogous source story.
- In the original study, the source story involved a general who wants to capture a fortress ruled by an evil dictator, but cannot do so by sending his entire army along a single road, which would trigger landmines.
- We first presented GPT-3 with the target problem in isolation. GPT-3 proposed a solution that involved injecting a radiation source directly into the tumor, rather than identifying the intended solution based on the convergence of multiple low-intensity radiation sources (Supplementary Section S2.1).
- But when first presented with the general story, followed by the target problem, GPT-3 correctly identified the convergence solution (Supplementary Section S2.2).
- GPT-3 was further able to correctly explain the analogy, and to identify the specific correspondences between the source story and target problem when prompted (e.g., general ↔ doctor, dictator ↔ tumor, army ↔ rays).
- In a more challenging version of this paradigm, participants were first presented with both the general story, and two other non-analogous stories intended to serve as distractors.
- In this context, human participants were much less likely to identify the convergence solution.
- But when given a prompt to explicitly consider the previously presented stories when trying to solve the radiation problem, participants were often able to correctly identify the analogous general story, and use this analogy to devise the convergence solution.
- Remarkably, we found that GPT-3 displayed these same effects.
- When presented with these same distracting, non-analogous stories, GPT-3 no longer identified the convergence solution, instead proposing the same solution that it proposed in response to the radiation problem alone (Supplementary Section S2.3).
- But when prompted to consider the previous stories, GPT-3 both correctly identified the general story as most relevant, and proposed the convergence solution (Supplementary Section S2.4).
- We also evaluated GPT-3 using materials from a developmental study that employed a similar paradigm [18]. In that study, children were tasked with transferring gumballs from one bowl to another bowl that was out of reach, and provided with a number of materials for doing so (e.g., a posterboard, an aluminum walking cane, a cardboard tube), permitting multiple possible solutions.
- The key result was that when children were first presented with an analogous source story (about a magical genie trying to transfer jewels between two bottles), they were more likely to identify a solution to the target problem that was analogous to the events described in the source story.
- When presented with this target problem, GPT-3 mostly proposed elaborate, but mechanically nonsensical solutions, with many extraneous steps, and no clear mechanism by which the gumballs would be transferred between the two bowls (Supplementary Sections S2.5-S2.7).
- But when asked to explicitly identify an analogy between the source story and target problem, GPT-3 was able to identify all of the major correspondences, even though it could not use this analogy to discover an appropriate solution. This finding suggests that GPT-3's difficulty with this problem likely stems from its lack of physical reasoning skills, rather than being due to a difficulty with analogical reasoning per se.

## Discussion
- GPT-3 displays an emergent ability to reason by analogy, matching or surpassing human performance across a wide range of problem types.
- These included a novel text-based problem set (Digit Matrices) modeled closely on Raven's Progressive Matrices, where GPT-3 both outperformed human participants, and captured a number of specific signatures of human behavior across problem types.
- Because we developed the Digit Matrix task specifically for this evaluation, we can be sure GPT-3 had never been exposed to problems of this type, and therefore was performing zero-shot reasoning.
- GPT-3 also displayed an ability to solve analogies based on more meaningful relations, including four-term verbal analogies and analogies between stories about naturalistic problems.
- It is certainly not the case that GPT-3 mimics human analogical reasoning in all respects. Its performance is limited to the processing of information provided in its local context.
- Unlike humans, GPT-3 does not have long-term memory for specific episodes. It is therefore unable to search for previously-encountered situations that might create useful analogies with a current problem.
- For example, GPT-3 can use the general story to guide its solution to the radiation problem, but as soon as its context buffer is emptied, it reverts to giving its non-analogical solution to the problem -the system has learned nothing from processing the analogy.
- GPT-3's reasoning ability is also limited by its lack of physical understanding of the world, as evidenced by its failure (in comparison with human children) to use an analogy to solve a transfer problem involving construction and use of simple tools.
- But despite these major caveats, our evaluation reveals that GPT-3 exhibits a very general capacity to identify and generalize -in zero-shot fashion -relational patterns to be found within both formal problems and meaningful texts.
- These results are extremely surprising.

## Methods

### Code availability
- Code for all simulations can be downloaded from GitHub
- Code for all simulations was written in Python
- Code for all simulations was written in a specific programming language
- Code for all simulations was written by a specific person
- Code for all simulations was written for a specific purpose
- Code for all simulations was designed to be used in a specific way
- Code for all simulations can be downloaded from GitHub
- Code for all simulations was written in Python
- Code for all simulations was written in a specific programming language
- Code for all simulations was written by a specific person
- Code for all simulations was written for a specific purpose
- Code for all simulations was designed to be used in a specific way

### GPT-3
- We queried GPT-3 in an automated fashion through the OpenAI API
- All of our primary simulations employed the text-davinci-003 model instance
- We also performed some additional experiments using the davinci and text-davinci-002 instances, as specified in the main text
- The temperature was set to 0
- For each prompt, GPT-3 generates a proposed completion (a string of tokens), and assigns log probabilities to each token in the prompt and the completion
- We used these log probabilities to evaluate GPT-3 on multiple-choice problems
- For each choice in a given problem, we concatenated the problem with the choice, and treated the average log probability assigned to the choice tokens as a score, selecting the answer choice with the highest score

### Digit Matrices
- digit matrix problems consisted of two major problem categories: transformation and logic problems.
- transformation problems contained anywhere from one to five rules, while logic problems each contained only a single rule.
- transformation problems were defined using a combination of three rule types: constant, distribution-of-3, and progression.
- the constant rule was defined by the same digit appearing across either rows or columns.
- the distribution-of-3 rule was defined by the same set of three digits appearing in each row or column, but with the order permuted.
- the progression rule was defined by a progressive increase or decrease in value, in units of either 1 or 2, across either rows or columns.
- logic problems were defined by one of three rules: OR, XOR, and AND.
- in the OR rule, a particular row or column (e.g., the middle column) contained all entities that appeared in either of the other rows or columns (e.g., the left and right columns).
- in the XOR rule, entities appearing in both of the other rows or columns were excluded (e.g., only items that appear in either the left or right column, but not both, will appear in the middle column).
- in the AND rule, a particular row or column contained only entities that appeared in both of the other rows or columns.
- for some logic problems, the within-cell spatial position of corresponding elements was aligned, while in other problems it was permuted.
- for distribution-of-3 and logic problems, rules applied across both rows and columns, as is the case in the original SPM.
- within each problem type (one-through five-rule and logic problems), there were a number of specific problem subtypes.
- there were 6 one-rule subtypes, 6 two-rule subtypes, and 10 subtypes for three-rule, four-rule, five-rule, and logic problems.
- we generated 100 instances of each subtype (except in the case of progression problems, for which there were fewer possible problem instances).
- the one-rule problem subtypes consisted of a row-wise constant problem, a column-wise constant problem, two distribution-of-3 problems, and two progression problems (one with an increment of 1 and one with an increment of 2).
- the two-and three-rule problem subtypes consisted of all possible combinations of two or three rules (allowing for the same rule to be used multiple times within each problem).
- the four-and five-rule problem subtypes were sampled from the set of all possible combinations of four or five rules.
- there were five spatially aligned logic problem subtypes, and five spatially permuted logic problem subtypes.
- three out of each of these five subtypes were OR problems (defined by the row or column in which the set union appeared), and the other two were AND and XOR problems.
- for each problem, we also procedurally generated a set of 7 distractor choices, making for a set of 8 total answer choices.
- distractors were generated using different methods for the transformation and logic problems. These methods were chosen based on the approach of Matzen et al. [22], who performed an analysis of the answer choices in the original SPM.
- for transformation problems, the following methods were used to generate distractors:
- 1. Sample a random cell from the problem.
- 2. Sample a random cell from the problem, sample a random digit within that cell, and apply an increment or decrement of either 1 or 2.
- 3. Start with the correct answer, apply an increment or decrement of either 1 or 2 to a randomly sampled digit.
- 4. Randomly sample a previously generated distractor for this problem, apply an increment or decrement of either 1 or 2 to a randomly sampled digit.
- ...

### Story analogies
- Story analogy problems were entered directly into the OpenAI playground.
- Materials were taken from [17] and [18].
- All prompts and responses are shown in Supplementary Section S2.
- Each subsection shows the results for a single continuous session, with GPT-3's responses presented in bold text.
- Responses were not truncated or curated in any way.
- Figure S1: Transfer from few-rule to many-rule Digit Matrix problems in text-davinci-002.
- An earlier instance of GPT-3, text-davinci-002, did not show the same contextual effects as text-davinci-003.
- When presented with problems in order of increasing complexity, text-davinci-002 was not able to use this presentation format to generalize from few-rule to many-rule problems, with a significant decrease in performance on four-rule, and especially five-rule, problems.

## S1 Solutions to example matrix reasoning problems
- The solution to the example visual matrix reasoning problem in Figure 1a is option 5.
- The solution to the example Digit Matrix problem in Figure 1b is option 7.
- The solutions to the problems in Figure 2 are presented in Table S1.

## S2 Story analogy results
- GPT-3 is able to evaluate analogical reasoning in natural language problemsolving
- GPT-3's responses are presented in bold text
- GPT-3 is able to identify analogies between two concepts
- GPT-3's responses are presented in italics
- GPT-3 is able to identify analogies between two sets of data
- GPT-3's responses are presented in bold text
- GPT-3 is able to identify analogies between two problems
- GPT-3's responses are presented in italics

### S2.1 Solution to radiation problem in isolation
- GPT-3 proposes a solution to the radiation problem when presented in isolation
- The radiation problem is that high intensity rays will also destroy the healthy tissue they pass through
- The solution is to use a technique called brachytherapy, which involves placing a radioactive source directly into or near the tumor

### S2.2 Solution to radiation problem following general story

### S2.3 Solution to radiation problem with distracting stories
- The Wine Merchants: One day a rich man found that his wine cellar was empty. So he sent out messengers to announce a generous offer.
- The General: An evil dictator controlled a fortress situated in the center of a small country.
- The Identical Twins: Once there were identical twins who were continually playing pranks on their family, friends, and teachers.
- The Doctor: Suppose you were a doctor faced with a patient suffering from a malignant stomach tumor.
- The Solution: The doctor can use a technique called brachytherapy. This involves placing a radioactive source directly into the tumor. The radiation from the source will be of a high enough intensity to destroy the tumor, but the radiation will not travel far enough to damage the healthy tissue. The doctor can also use a technique called stereotactic radiotherapy. This involves using a machine to deliver a high-intensity beam of radiation to the tumor from outside the body. The beam is focused on the tumor, so that the healthy tissue is spared.

### S2.4 Solution to radiation problem with distracting stories and prompt
- When presented with a prompt to generate a solution to the radiation problem, GPT-3 correctly identified the convergence solution, and specifically identified the general story as the relevant source.
- The prompt used to elicit GPT-3's solution was changed, and when presented with this prompt, GPT-3 correctly identified the convergence solution.

### S2.5 Solution to gumball problem in isolation
- GPT-3 proposes a solution to the gumball problem (from [18]) when presented in isolation
- The gumball problem is to transfer a number of small gumballs from a filled bowl to an empty bowl without leaving your seat
- The solution proposed by GPT-3 is to cut a long strip of posterboard and tape it to the end of a cardboard tube, tie one end of the string to the end of the tube, place the tube in the bowl of gumballs and use the cane to pull the tube and gumballs towards you, use the paper clips to secure the tube to the edge of the table, and use the rubber bands to secure the tube to the cane.

### S2.6 Solution to gumball problem following magic staff story
- GPT-3 proposed a solution to the gumball problem when first presented with the 'magic staff story'.
- This story involves a magical genie who has moved from his old home (a bottle) to a new home (a different bottle), and wants to transport his collection of jewels between the bottles.
- To do so, he uses a magic staff to pull the new bottle over next to the old bottle and transfers the jewels by hand.
- When first presented with this story, children most often identify a solution to the gumball problem that involves using the aluminum walking cane to pull the empty bowl over next to the bowl with the gumballs and then transferring the gumballs by hand.
- GPT-3 was not able to discover this solution, but was able to identify the high-level analogy between the source story and the target problem (though not the specific analogy between the magic staff and the walking cane).
