---
title: "Protein Structure Prediction until CASP15"
date: 2022-12-15T10:25:44.000Z
author: "Arne Elofsson"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2212-07702v1.webp" # image path/url
    alt: "Protein Structure Prediction until CASP15" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2212.07702)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2212.07702).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/protein-structure-prediction-until-casp15).

# Abstract
- In Dec 2020, the results of AlphaFold2 were presented at CASP14, sparking a
- For the first time, a purely computational method could challenge experimental accuracy for structure
- The code of AlphaFold2 was released in the summer of 2021, and since then, it has been shown that it can be used to
- It has also sparked an explosion of development in the field, improving AI-based methods to predict protein complexes,

# Paper Content

## Background
- Protein structure prediction is often divided into template-based and de-novo protein structure prediction.
- In the 1980s, methods were developed to predict the structure of a protein by copying the coordinates from an experimentally determined protein structure.
- Since the first methods, there have been methodological advances, but more importantly, the increase in sequence and structure data has enabled many more proteins to be modelled accurately.
- Traditionally de novo modelling meant modelling a protein without using a template. However, this strict definition has blurred over the last two decades by using fragments.
- Methods such as Rosetta [3], I-Tasser [4], and FragFold [5] use fragments of various sizes to predict the structure of a protein.
- These fragments might come from homologous protein structures or not.
- Most successful in this area is the Rosetta program developed by the Baker group.
- However, only a small subset of proteins without templates could be modelled with any accuracy using this methodology, i.e. it is not very useful for general protein structure predictions.
- In the 1990s, it was proposed that it could predict the structure of a protein by using co-evolutionary signals in a multiple sequence alignment.
- However, the performance of these methods was minimal, and predictions were only slightly better than random.
- In 1999 a solution to increasing the accuracy of contact predictions was proposed by separating direct and indirect contacts using a trainable model.
- A similar idea had been proposed earlier [8].
- Unfortunately, these papers were largely ignored by the community.
- The methods could have been more helpful if only more protein families had sufficient members.
- About ten years ago, the idea of indirect correlation was rediscovered [9], and other methods were also proposed [10].
- These methods provided the ability to predict the structure of many proteins accurately.
- However, the method was still limited to large protein families, and the models' accuracy was limited.
- It was soon realised that combining DCA and machine (deep) learning was a way to improve the prediction of contacts.
- The most successful method uses a very deep network to predict contacts with significantly better accuracy than DCA-based methods.
- The requirements for very large multiple-sequence alignments also decreased.
- At CASP13, DeepMind introduced AlphaFold (version 1) [14], building on the earlier methods.
- The main differences were that the architecture was deeper and that the network predicted distance probabilities, and not only contacts were predicted.
- This resulted in such accuracy that it was possible to use a simple steepest descent methodology to predict the structure of proteins.
- However, only a tiny fraction of proteins without templates could be predicted at experimental accuracies.

## AlphaFold v2.0
- The average GDTts was close to 90 for individual domains, i.e. it was, in principle, as good as experimental structures.
- In the summer of 2021, the AlphaFold2 papers were published.
- The first paper [16] described the method and accompanied by a paper describing an extensive database with predicted structures [17].
- This database has recently been extended to cover virtually all known proteins.
- Notable, DeepMind released the source code of AlphaFold with an open-source license. This allowed the community to test and extend the method, spurring a real jump in development speed.
- In short, AlphaFold2 consists of two main modules the EvoFormer block and the structure block. Both of these blocks contain important innovations inspired by previous work.
- Most importantly, AlphaFold2 can be seen as an awe-inspiring engineering feat.
- In contrast to AlphaFold1, the input to AlphaFold2 is a "raw" multiple sequence alignment, i.e. the deep learning network extracts co-evolutionary (and other) types of information directly from the MSA as proposed earlier [18].
- A representation of the rawMSA (and a pair representation) is then used to input the 48 evoformer blocks.
- The Evoformer block is a two-track network, where first, a row and column-wise attention mechanism is used to analyse the MSA. This is then transformed into a pairwise description by an outer product, which is then updated using self-attention.
- One key innovation here is the triangle updates that can learn not to break triangle equalities.
- The output of one EvoFormer module is fed into the next.
- The final pair representation is used as an input to the structural module jointly with the representative sequence.
- Notably, the structure module in AlphaFold2 is locally translated and rotational equivariant [19].
- It starts treating the protein as a residue gas, i.e. ignoring all the chemistry from a protein being a polymer.
- Each residue is modelled as a triangle, and their internal relationships are described using affine matrices.
- One key invention here is the Invariant Point Attention (IPA), making the structure module invariant to translation and rotations (which is required as rotations and translations are arbitrary for a single protein).
- IPA is based on the L2-norm of a vector to be invariant concerning translations and rotations.
- The structure module (in contrast to other methods) also contains information about sidechains, represented by standard dihedral angles.
- Also, using Frame Aligned Point Error (instead of RMSD) as a loss function is novel and ingenious.
- Earlier attempts to develop an end-to-end method were unsuccessful because the structural representation was not optimal [20].
- Even methods implemented after AlphaFold use less efficient methods [21,22] and often only predict backbone coordinates and, therefore, require external programs to generate all-atom models

## The field after the release of AlphaFold2
- The algorithm was presented at the CASP conference and released as open source in June 2021
- Many labs use the AlphaFold2 paper and the code
- MMseqs2 is an essential tool for building models
- The success in predicting the structure of complexes led DeepMind to develop a version of AlphaFold aimed explicitly at this task
- The first version (released in Nov 2021) could have been better, but the second version (released in April 2022) performs slightly better

## AlphaFold2 clones/copies
- AlphaFold stimulated significant work to reproduce it
- RoseTTAFold was published at the same time as AlphaFold, but it is clear that the public description of AlphaFold strongly inspired their work
- OmegaFold omegafold and ESMfold were cloned from AlphaFold, but it is unclear if their predictions use a single sequence
- The performance is significantly worse for (orphan) proteins that do not have many homologs in the sequence databases
- Esmfold was computationally efficient and has been used to predict the structure of all proteins from an extensive meta-genomics database
- Alternative scoring functions were used to identify the best models

## Conclusions
- Since the release of AlphaFold in 2021, the field has shown steady progress
- In CASP15, it is shown that running default AlphaFold on difficult targets, and the average TM-score is about 0.7
- By using primarily increased sampling, it can be increased to about 0.8, i.e. for the vast majority of all proteins and protein complexes
