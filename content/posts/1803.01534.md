---
title: "Path Aggregation Network for Instance Segmentation"
date: 2018-03-05T07:46:36.000Z
author: "Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, Jiaya Jia"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/1803-01534v4.webp" # image path/url
    alt: "Path Aggregation Network for Instance Segmentation" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/1803.01534)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/1803.01534).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/path-aggregation-network-for-instance).

# Abstract
- Path aggregation network (PANet) boosts information flow in proposal-based instance segmentation framework
- Enhance the entire feature hierarchy with accurate localization signals in lower layers by bottom-up path augmentation
- Adaptive feature pooling links feature grid and all feature levels to make useful information in each feature level propagate directly to following proposal subnetworks
- Create complementary branch capturing different views for each proposal to further improve mask prediction

# Paper Content

## Introduction
- Instance segmentation is the process of predicting the class label and pixelwise instance mask of varying numbers of instances presented in images.
- Deep convolutional neural networks are a popular framework for instance segmentation.
- One of the most effective methods for instance segmentation is mask prediction using a fully convolutional network.
- Feature pyramid networks are a useful tool for augmenting feature hierarchies and improving localization accuracy.
- PANet is a bottom-up path augmentation and feature pooling framework that achieves state-of-the-art performance on several datasets.

## Related Work
- Instance segmentation is the process of dividing an image into individual objects or regions
- There are 2 streams of methods for instance segmentation- one is based on object detection and the other is based on segmentation
- Mask R-CNN is a method in the stream based on object detection that uses masks to predict the transformation that an object would need to be in order to be in a certain region
- Our work is a method that is based on segmentation that uses a foveal structure to exploit context information from regions with different resolutions
- Global pooling was used in PSPNet and ParseNet to greatly improve quality of semantic segmentation
- Similar trend was observed by Peng et al. where global convolutionals were utilized

## Framework
- Our framework is illustrated in Figure 1
- Path augmentation and aggregation is conducted for improving performance
- A bottom-up path is augmented to make low-layer information easier to propagate
- We design adaptive feature pooling to allow each proposal to access information from all levels for prediction
- A complementary path is added to the mask-prediction branch
- This new structure leads to decent performance

### Bottom-up Path Augmentation
- Neurons in high layers strongly respond to entire objects while other neurons are more likely to be activated by local texture and patterns
- Our framework further enhances the localization capability of the entire feature hierarchy by propagating strong responses of low-level patterns based on the fact that high response to edges or instance parts is a strong indicator to accurately localize instances
- To this end, we build a path with clean lateral connections from the low level to top ones. Therefore, there is a "shortcut" (dashed green line in Figure 1), which consists of less than 10 layers, across these levels.
- In comparison, the CNN trunk in FPN gives a long path (dashed red line in Figure 1) passing through even 100+ layers from low layers to the topmost one

### Adaptive Feature Pooling
- Motivation: In FPN, proposals are assigned to different feature levels according to the size of proposals.
- It makes small proposals assigned to low feature levels and large proposals to higher ones.
- Albeit simple and effective, it still could generate non-optimal results.
- For example, two proposals with 10-pixel difference can be assigned to different levels.
- In fact, these two proposals are rather similar.
- Further, importance of features may not be strongly correlated to the levels they belong to.
- High-level features are generated with large receptive fields and capture richer context information.
- Allowing small proposals to access these features better exploits useful context information for prediction.
- Similarly, low-level features are with many fine details and high localization accuracy.
- Making large proposals access them is obviously beneficial.
- With these thoughts, we propose pooling features from all levels for each proposal and fusing them for following prediction.
- We call this process adaptive feature pooling.
- We now analyze the ratio of features pooled from different levels with adaptive feature pooling.
- We use max operation to fuse features from different levels, which lets network select element-wise useful information.
- We cluster proposals into four classes based on the levels they were assigned to originally in FPN.
- For each set of proposals, we calculate the ratio of features selected from different levels.
- In notation, levels 1 − 4 represent low-to-high levels.
- As shown in Figure 3, the blue line represents small proposals that were assigned to level 1 originally in FPN.
- Surprisingly, nearly 70% of features are from other higher levels.
- We also use the yellow line to represent large proposals that were assigned to level 4 in FPN. Again, 50%+ of the features are pooled from other lower levels. This observation clearly indicates that features in multiple levels together are helpful for accurate prediction.
- It is also a strong support of designing bottom-up path augmentation.

### Fully-connected Fusion
- Fully connected layers, or MLP, were widely used in mask prediction in instance segmentation and mask proposal generation
- Results of [8,33] show that FCN is also competent in predicting pixelwise masks for instances
- Mask R-CNN [21] applied a tiny FCN on the pooled feature grid to predict corresponding masks avoiding competition between classes
- We note fc layers yield different properties compared with FCN where the latter gives prediction at each pixel based on a local receptive field and parameters are shared at different spatial locations
- Contrarily, fc layers are location sensitive since predictions at different spatial locations are achieved by varying sets of parameters. So they have the ability to adapt to different spatial locations
- Also prediction at each spatial location is made with global information of the entire proposal. It is helpful to differentiate instances and recognize separate parts belonging to the same object
- Given properties of fc and convolutional layers different from each other, we fuse predictions from these two types of layers for better mask prediction
- Mask Prediction Structure Our component of mask prediction is light-weighted and easy to implement
- The mask branch operates on pooled feature grid for each proposal. As shown in Figure 4, the main path is a small FCN, which consists of 4 consecutive convolutional layers and 1 deconvolutional layer.
- Each convolutional layer consists of 256 3 × 3 filters and the deconvolutional layer up-samples feature with factor 2. It predicts a binary pixel-wise mask for each class independently to decouple segmentation and classification, similar to that of Mask R-CNN.
- We further create a short path from layer conv3 to a fc layer. There are two 3 × 3 convolutional layers where the second shrinks channels to half to reduce computational overhead.
- A fc layer is used to predict a class-agnostic foreground/background mask. It not only is efficient, but also allows parameters in the fc layer trained with more samples, leading to better generality.
- The mask size we use is 28 × 28 so that the fc layer produces a 784 × 1 × 1 vector. This vector is reshaped to the same spatial size as the mask predicted by FCN.
- To obtain the final mask prediction, mask of each class from FCN and foreground/background prediction from fc are added. Using only one fc layer, instead of multiple of them, for final prediction prevents the issue of collapsing the hidden spatial feature map into a short feature vector, which loses spatial information.

## Experiments
- Our method is top ranked on all three datasets
- Comprehensive ablation study is conducted on the COCO dataset
- Results are presented on the COCO 2017 Instance Segmentation and Object Detection Challenges

### Implementation Details
- We re-implement Mask R-CNN and FPN based on Caffe
- All pre-trained models we use in experiments are publicly available
- We adopt image centric training
- For each image, we sample 512 region-of-interests (ROIs) with positive-to-negative ratio 1 : 3. Weight decay is 0.0001 and momentum is set to 0.9. Other hyper-parameters slightly vary according to datasets and we detail them in respective experiments.
- Following Mask R-CNN, proposals are from an independently trained RPN

### Experiments on COCO

### Experiments on Cityscapes

### Experiments on MVD
- MVD provides 25,000 images with fine instance-level annotations for 37 semantic classes
- PANet with one ResNet-50 performs comparably with the ensemble result with pre-training on COCO
- With multi-scale and horizontal flip testing, which are also adopted by UCenter, our method performs even better

## Conclusion
- We have presented our PANet for instance segmentation.
- We designed several simple and yet effective components to enhance information propagation in representative pipelines.
- We pool features from all feature levels and shorten the distance among lower and topmost feature levels for reliable information passing.
- Complementary path is augmented to enrich feature for each proposal.
- Impressive results are produced.
- Our future work will be to extend our method to video and RGBD data.
