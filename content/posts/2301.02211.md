---
title: "Teaching Computer Vision for Ecology"
date: 2023-01-05T18:30:17.000Z
author: "Elijah Cole, Suzanne Stathatos, Björn Lütjens, Tarun Sharma, Justin Kay, Jason Parham, Benjamin Kellenberger, Sara Beery"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "https://ik.imagekit.io/smryai/2301-02211v1_6u0zd7Wur.jpg" # image path/url
    alt: "Teaching Computer Vision for Ecology" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2301.02211)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2301.02211).


# Abstract
- Computer vision can help ecologists speed up their research by automating the analysis of raw imagery from sensors like camera traps, drones, and satellites
- The workshop discussed in the paper is designed to help ecologists learn how to use computer vision and improve their research
- Computer vision is an emerging field and is not commonly taught to ecologists, so this workshop is designed to help ecologists learn how to use it

# Paper Content

## Introduction
- Computer vision algorithms can automate the process of extracting important information from images and videos
- This is especially important when manually reviewing the data is not feasible
- Ecology presents a particularly compelling use case for computer vision
- To build on this progress, we must equip ecologists with the skills they need to understand and apply computer vision methods
- While ecologists often have training in statistics and programming, they are rarely exposed to the interconnected web of software engineering and machine learning topics necessary for computer vision

## Related Work
- Machine learning is an emerging literature devoted to teaching students how to use computers to learn from data
- Most of these works concern efforts to teach students from computer science or related disciplines
- However, there is prior work discussing the specific challenge of teaching machine learning to cross-disciplinary audiences
- Our work is complementary, focusing on the process of teaching computer vision to ecologists (mostly Ph.D. students and postdocs) who have background knowledge in statistics and programming but little prior experience in machine learning
- In addition, we consider an immersive workshop in which researchers build prototypes using their own research data, not a traditional classroom environment

## The CV4E Workshop
- The inaugural CV4E Workshop was held at Caltech from August 1 -19, 2022
- The program was designed to train ecologists to use computer vision in their own research
- Application had five components: (i) a one-page project proposal, (ii) a one-page personal statement, (iii) a programming example, (iv) one letter of reference, and (v) a CV
- The selection process was based on the following criteria: (i) goal clarity, (ii) project feasibility, (iii) potential impact, and (iv) candidate preparation
- All 18 of the workshop's participants had trained models by the end of the program

## Lessons Learned
- The primary obstacle for most participants was insufficient Python preparation.
- To facilitate this process, the staff provided resources for learning Python and hosted office hours in the months leading up to the CV4E Workshop.
- However, many participants (even capable R programmers) still struggled with Python issues throughout the workshop.
- In hindsight, we overestimated the extent to which R experience is helpful for quickly learning Python.
- In the future we will enforce more structured Python preparation before the workshop.
- Start simple. It is challenging to build a working computer vision system from scratch in 3 weeks.
- To maximize the probability of success, it is important to start simple.
- When appropriate, we encouraged participants to use standard well-understood pipelines e.g. fine-tuning an ImageNet-pretrained ResNet-50.
- Collect similar projects in working groups.
- Mix experience levels in working groups.
- Make unambiguous infrastructure recommendations.
- Avoid deep learning library wrappers.
- Avoid Jupyter Notebooks.
- Make sure GPUs are available.

## Educational Techniques
- Guided troubleshooting was important to provide opportunities to hone these abilities
- To balance these objectives, instructors tried to walk participants through the troubleshooting process by asking leading questions about the problems they were encountering
- For unusual problems of limited educational value (i.e. complex configuration or installation issues), instructors intervened to resolve the issue as quickly as possible
- Pair pseudocoding was used to prevent participants from getting stuck on code design issues
- Contextualized lectures were used to ensure that the lectures remained grounded in applications and examples

## Conclusion
- The workshop was successful
- All participants trained models by the end of the workshop
- There were some challenges that were discussed and opportunities for improvement were identified
- This information will be useful for others who teach computer vision across disciplines

### A.1 Participant Backgrounds
- The inaugural 2022 CV4E Workshop had 18 participants
- The cohort was made up of researchers from different academic backgrounds
- The workshop was held in the U.S. and consisted of participants from different countries

### A.2 Participant Projects

## B Key Topics
- Using annotation tools to label image or audio data
- Labeled data is essential for training and evaluating computer vision algorithms
- Since CV4E Workshop participants were using their own data, many of them needed to learn to use some sort of annotation tool
- Many of these tools can export labels in the standard formats expected by open-source computer vision libraries
- Content: Common Unix commands like ls, pwd, rm, mkdir, rmdir, mv, cat, head, tail etc.
- Facility with Unix commands is crucial for installing packages, working with virtual machines, and using revision control
- Understanding Unix commands also helps to build intuition for core concepts like absolute vs. relative paths
- Content: Tools like nano for editing text that is stored on a server from the command line
- When configuring SSH authentication it is often necessary to edit text files on the VM (e.g. ∼/.ssh/config)
- Content: Tools like tmux or screen for managing terminal sessions
- Long-running code (e.g. model training in PyTorch) should be executed in a terminal session that is decoupled from the SSH connection to avoid being terminated when a laptop is closed or internet connection is lost
- Content: The ssh command and SSH keys. Occasionally, SSH tunneling.
- Namespaces are the answer to many common questions e.g. why variables defined inside a function are not accessible outside the function
- Content: Tools like scp or rsync for transferring files
- Command line tools are the most reliable way to move large amounts of data from one place to another
- Content: Using GitHub for tracking changes made to code
- Code for computer vision projects tends to quickly grow in complexity, and it is easy to forget what has changed since the last working version
- Tools like GitHub allow earlier versions of the code to be revisited easily if a bug was introduced by some change
- In addition, GitHub can be used to move code from a local machine (git push) to a virtual machine (git pull) along with allowing users to download (git clone) open-sourced computer vision repositories
- Content: Interacting with the web interfaces of cloud computing providers
- Creating a virtual machine with appropriate resources e.g. GPUs, storage. Estimating and managing cost.
- One of the most common ways to access GPU resources for computer vision work is to use a VM from a cloud computing provider like Amazon Web Services (AWS) [1] or Microsoft Azure [9]
- It is important to understand the benefits (scalability, reliability) and drawbacks (cost) of cloud computing
- Content: Creating and managing virtual environments
- Virtual environments are also useful if a "clean reinstall" becomes necessary, because they are easy to create and delete

### B.2 Computer Science Concepts
- Classes and objects
- Inheritance
- Encapsulation
- Polymorphism
- Data structures
- In-place operations
- Mutable vs. immutable

### B.3 Machine Learning Concepts
- Participants learned different practical and conceptual aspects of computer vision and machine learning depending on their project.
- However, all participants had to engage with a few core concepts.
- The concept of generalization, different types of generalization, identifying a type of generalization that reflects the goals of a project.
- Computer vision projects depend on numerous complex but (generally) well-documented libraries. It is important to be able to understand the documentation. Sometimes it also becomes necessary to locate and inspect the piece of code being documented (e.g. a function from some library) to understand how it works in detail.
- Errors vs. warnings, searching for more information about error messages.
- For a given line of code, any number of errors could arise. Understanding the different types of Python errors is helpful for pinpointing the root cause.
- Print statement debugging is also extremely useful for troubleshooting code running on a remote machine.
