---
title: "Causal Inference in Recommender Systems: A Survey of Strategies for Bias Mitigation, Explanation, and Generalization"
date: 2023-01-03T00:56:50.000Z
author: "Yaochen Zhu, Jing Ma, Jundong Li"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2301-00910v1.webp" # image path/url
    alt: "Causal Inference in Recommender Systems: A Survey of Strategies for Bias Mitigation, Explanation, and Generalization" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2301.00910)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2301.00910).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/causal-inference-in-recommender-systems-a-1).

# Abstract
- Traditional RSs estimate user interests and predict their future behaviors by utilizing correlations in the observational historical activities, their profiles, and the content of interacted items.
- However, since the inherent causal reasons that lead to the observed users' behaviors are not considered, multiple types of biases could exist in the generated recommendations.
- In addition, the causal motives that drive user activities are usually entangled in these RSs, where the explainability and generalization abilities of recommendations cannot be guaranteed.
- To address these drawbacks, recent years have witnessed an upsurge of interest in enhancing traditional RSs with causal inference techniques.
- In this survey, we provide a systematic overview of causal RSs and help readers gain a comprehensive understanding of this promising area.
- We start with the basic concepts of traditional RSs and their limitations due to the lack of causal reasoning ability.
- We then discuss how different causal inference techniques can be introduced to address these challenges, with an emphasis on debiasing, explainability promotion, and generalization improvement.
- Furthermore, we thoroughly analyze various evaluation strategies for causal RSs, focusing especially on how to reliably estimate their performance with biased data if the causal effects of interests are unavailable.
- Finally, we provide insights into potential directions for future causal RS research.

# Paper Content

## Introduction
- Traditional RSs can only estimate user interests and predict future recommendations based on correlations in the observational user historical behaviors and user/item features, which guarantee no causal implications
- There are three classes of RSs- collaborative filtering-based, content-based, and hybrid
- Collaborative filtering-based RSs estimate user interests and predict their future behaviors by exploiting their past activities, such as browsing, clicking, purchases, etc.
- Content-based methods, on the other hand, predict new recommendations by matching user interests with item content
- Hybrid methods combine the advantages of both worlds, where collaborative information and user/item feature information are comprehensively considered to generate more accurate recommendations
- However, recent years have witnessed substantial achievements for all three classes of RSs introduced above, but a great limitation of these methods is that they can only estimate user interests and predict future recommendations based on correlations in the observational user historical behaviors and user/item features
- For example, a collaborative filtering-based RS may discover that several drama shows from a certain genre tend to have high ratings from a group of users, and conclude that we should keep recommending drama shows from the same genre to these users
- But there is an important question: Are the high ratings caused by the fact that the users indeed like drama shows from this genre, or they were limitedly exposed to drama shows from the same genre (i.e., exposure bias), and if given a chance, they would prefer something new to watch?
- In addition, a content-based RS may observe that micro-videos with certain features are associated with more clicks and conclude that these features may reflect the current trend of user interests
- But are the clicks because these micro-videos tend to have sensational titles as clickbait where users could be easily deceived?
- Moreover, if the titles of these micro-videos are changed to the ones that reflect their true content, would users still click them?
- The above questions are causal in nature because they either ask about the effects of an intervention (e.g., what the rating would be if a new drama show is made exposed to the user) or a counterfactual outcome (e.g., would the user still click a micro-video if its title had been changed to faithfully reflect the content), rather than mere associations in the observational data.
- According to Pearl [15], these questions lie on Rungs 2 and 3 of the Ladder of Causality, i.e., interventional and counterfactual reasoning, and they cannot be answered by traditional RSs that reason only with associations, which lie on Rung 1 of the ladder
- For example, a collaborative filtering-based RS may discover that several drama shows from a certain genre tend to have high ratings from a group of users, and conclude that we should keep recommending drama shows from the same genre to these users
- But there is an important question: Are the high ratings caused by the fact that the users indeed like drama shows from this genre, or they were limitedly exposed to drama shows from the same genre (i.e., exposure bias), and if given a chance, they would prefer something new to watch?
- In addition, a content-based RS may observe that micro-videos with certain features are associated with more clicks and conclude that these features may reflect the current trend of user interests
- But are the clicks because these micro-videos tend to have sensational titles as clickbait where users could be easily deceived?
- Moreover, if the titles of these micro-videos are changed to the ones that reflect their true content, would users still click them?
- The above questions are causal in nature because they either ask about the effects of an intervention (e.g., what the rating would be if a new drama show is made exposed to the user) or a counterfactual outcome (e.g., would the user still click a micro-video if its title had been changed to faithfully reflect the content), rather than...

## Recommender System Basics
- RSs are data-driven models that use ratings to predict user ratings for items that have not been interacted with before.
- The RS is trained on observed ratings to simplify the discussion unless specified otherwise.
- The RS is designed to predict user ratings for items that have not been interacted with before, based on the observed ratings and available user and item side information.

### Collaborative Filtering
- Collaborative filtering-based RSs recommend new items by leveraging user ratings in the past.
- They generally consider the ratings as being generated from a user latent variable u that represents user interests and an item latent variable v that encodes the item attributes (i.e., item latent semantic information), where  is the dimension of the latent space.
- Here we list three widely-used collaborative filtering-based RSs, which will be frequently used as examples in this survey: Matrix Factorization (MF), Deep Matrix Factorization (DMF), and Auto-encoder (AE)-based RSs.
- In the training phase, the models learn the latent variables u, v, and the associated function  by fitting on the observed ratings    (e.g., via maximum likelihood estimation, which essentially estimates the conditional distribution (  |u, v) from the observational data [24]).
- Afterward, we can use them to predict new ratings for previously uninteracted items, e.g., rMF for DMF, and rAE =    (u)  for AE-based RSs, where the top ones that best match users' interests can be selected as recommendations.
- Ideally, we would expect u, v, and  to capture the causal influence of user interests and item attributes on ratings, i.e., what the rating would be if item is made exposed to user  [24]. However, since the collected rating data are observational rather than experimental, what actually learned by u, v, and are the co-occurrence patterns in users' past behaviors, which guarantee no causal implications. Consequently, spurious correlations and biases can be captured by the model, which will be amplified in future recommendations [25].

### Content-Based Recommender Systems
- Personalized content-based RSs (CBRSs) estimate user interests based on the features of the items they have interacted with.
- CBRSs typically encode user interests into user latent variables u  ∈ R  and assume that the ratings are generated by matching user interests with item content, i.e.,    ∼ N (  (u  , f  ),   ), where  is a matching function.
- The training of personalized CBRSs follow similar steps as collaborative filtering, where u  and  are learned by fitting on the observed ratings (which essentially estimates the conditional distribution (   |u  , f  ) from the observational data), and new ratings can be predicted by r =  (u  , f  ).
- The key step of building a CBRS is to create item features f  that can best reflect user interests, which crucially depends on the item being recommended.

### Hybrid Recommendation
- Hybrid RSs combine user/item side information with collaborative filtering to improve the recommendations.
- A commonly-used hybrid strategy is to augment user and item latent variables with user/item side information.
- The dimensions of the user/item side information that encode the collaborative information are adjusted accordingly.
- Another important class of hybrid RS is the factorization machine (FM) and its extensions like [31,32], which can be viewed as learning a bi-linear function where the ratings are generated by Simple hybrid strategies cannot break the correlational reasoning limitation of collaborative filtering and content-based RSs.

## Causal Recommender Systems: Preliminaries
- The traditional RSs (RS1, RS2, RS3) have limitations due to correlational reasoning on observational user behaviors.
- Two causal inference frameworks, i.e., Rubin's potential outcome framework (also known as the Rubin causal model, RCM) [33] and Pearl's structural causal model (SCM) [34], are introduced in the context of RSs, aiming to provide a theoretically rigorous basis for reasoning with correlation and causation in recommendations.
- Both RCM and SCM are powerful frameworks to build RSs with causal reasoning ability, but they are best suited for different tasks and questions.

### Rubin's Potential Outcome Framework
- Traditional RSs (e.g. collaborative filtering-based RSs) are susceptible to the confounding bias, where the observed ratings are biased due to the confounding effect of   on the exposure probability of item  .
- To address this issue, RCM-based RSs draw inspiration from clinical trials, where exposing a user to an item is compared to subjecting a patient to a treatment, and the user ratings are analogous to the outcomes of the patients after the treatment.
- Accordingly, RCM-based RSs aim to estimate the causal effects of the treatments (exposing a user to an item) on the outcomes (user ratings), despite the possible correlations between the treatment assignment and the outcome observations.

### Pearl's Structural Causal Model
- Different from RCM that uses rating potential outcomes to reason with causality and attributes the biases in observed user behaviors to non-randomized item exposures, Pearl's structural causal model (SCM) delves deep into the causal mechanism that generates the observed outcomes (and biases) and represents it with a causal graph  = (N , E).
- The nodes N specify the variables of interests, which in the context of RS could be user interests , item attributes , observed ratings , and other important covariates , such as item popularity, user features, etc .
- The directed edges E between nodes represent their causal relations determined by researchers' domain knowledge.
- Each node  ∈ N is associated with a structural equation   ( |()) , which describes how the parent nodes () causally influence  (i.e., the response of  when setting nodes in () to specific values)
- Although RCM and SCM are generally believed to be fundamentally equivalent [34], both have their unique advantages. Compared to RCM, the key advantage of SCM is that causal graph offers an intuitive and straightforward way to encode and communicate domain knowledge and substantive assumptions of researchers, which is beneficial even for the RCM-based RSs [42]. Furthermore, SCM is more flexible as it can represent and reason with the causal effects between any subset of nodes in the causal graph (e.g., between two causes ,  and one outcome ), as well as the causal effects along specific paths (e.g.,  →  and   → ).
- In causal graphs, the subscripts ,  for each node are omitted for simplicity. We also omit the mutually independent exogenous variables for each node and summarize their randomness into the structural equations with probability distributions [14].
- Subscript  is used to distinguish structural equations from other conditional relationships that can be inferred from .
- The structure of causal graphs represents researchers' domain knowledge regarding the causal generation process of the observational data, which is the key to distinguishing stable, causal relations from other undesirable correlations between variables of interest.
- Confounders can lead to non-causal dependencies among variables in the observational dataset. This could introduce bias in traditional RSs, where the confounding effects are mistaken as causal relations. Confounding bias is a generic problem in RSs [24], which will be further analyzed in the following subsections.

## Causal Recommender Systems: The State-of-the-Art
- Traditional RSs suffer from limitations due to correlational reasoning, which can be addressed by using state-of-the-art causal RSs.
- Bias mitigation, explainability promotion, and generalization improvement are important topics that are covered by state-of-the-art causal RSs.

### Causal Debiasing for Recommendations
- Exposure bias in RSs broadly refers to the bias in observed ratings due to nonrandomized item exposures.
- From the RCM's perspective, exposure bias can be defined as the bias where users are favorably exposed to items depending on their expected ratings for them (i.e., rating potential outcomes) [43].
- Exposure bias occurs due to various reasons, such as users' self-search or the recommendation of the previous RSs [36], which leads to the down-weighting of items less likely to be exposed to users.
- Since item exposures can be naturally compared with treatments in clinical trials, we discuss the debiasing strategies with the RCM framework.
- RSs aim to reweight the biased observed ratings    for user-item pairs in the treatment group, i.e., T = {(, ) :    = 1}, to create pseudo randomized samples [57] for unbiased training of RS models that aim to predict the rating potential outcomes    (  = 1) for the population PO = {(, ), 1 ≤ ,  ≤ , }.
- Intuitively, we can set the weight of    for units in T to be the inverse of item 's exposure probability to user , such that under-exposed items can be up-weighted and vice versa.
- If for each user-item pair, the covariates c that satisfy the conditional unconfoundedness assumption in Eq. ( 3) are available, the exposure probability    can be unbiasedly estimated from c via which is formally known as propensity score in causal inference literature [58].

### Causal Explanation in Recommendations
- Causality is used to explain the user decision process.
- In order to disentangle user interests from conformity to the current trend, DICE uses the colliding effect of causal graphs.
- The key to achieving disentanglement is to split the triplets (, , ) in R  into two disjoint subsets based on the popularity of the positive and negative items.
- Finally, a rating predictor is formed based on the disjointed embeddings and the match functions.

### Causal Generalization of Recommendations
- RSs can be improved with causal intervention and disentanglement
- Causal intervention can improve the generalization of RSs within a dynamic environment
- Causal disentanglement can promote the generalization of RSs by identifying and basing recommendations on causes that are more robust to potential changes in the environments

## Evaluation Strategies for Causal RSs
- Various causal inference techniques are promising to address multiple types of biases
- Evaluation of causal RS models is difficult, because the groundtruths, i.e., the causal effects of interest, are usually infeasible
- There are several strategies that can reliably evaluate causal RSs with biased real-world data

### Evaluation Strategies for Traditional RSs
- Traditional RSs generally follow three steps: First, the observed ratings in the rating matrix R are split into the non-overlapping training set R and test set R, usually by randomly holding out a certain percentage of the observed ratings from each user.
- Then, the proposed RS is trained on ratings in R to learn the latent variables and the associated functional models.
- Finally, the trained RS predicts the missing ratings in R for each user, where the results are compared with the held-out ratings in R to evaluate the model performance.

### Challenges for the Evaluation of Causal RSs
- The evaluation strategy for causal RSs is not directly applicable to causal RSs because ratings in R may have the same spurious correlation and bias as ratings in R, which makes the evaluation on R biased.
- It is ideal that we have a biased/entangled training set R  to learn the model, and an unbiased/disentangled test set R  for model evaluation, such that the effectiveness of the causal debiasing/disentangling algorithm can be directly verified from experiments. However, such unbiased/disentangled test set R  can be difficult to acquire and expansive to establish.
- Therefore, we first introduce common data simulation strategies for causal RS evaluation. We then discuss how real-world datasets can be directly utilized to further promote the credibility of causal RS research.

### Evaluation Based on Simulated Datasets
- The generation mechanisms of the bias and entanglement to be studied are clearly identified, credibly designed, and can be adjusted in a flexible manner
- The available real-world information is utilized as much as possible
- Deep generative models are a promising dataset simulation strategy that satisfies the above criteria

### Evaluation Based on Real-world Datasets
- For the study of exposure bias, it is feasible to establish-bias free real-world datasets, where ratings for either every item or randomly selected items are collected from a subset of users.
- This can be extremely expansive and user-unfriendly, but recent years have witnessed a growing interest in causal RS research from the industry, where more such randomized datasets are established and released to facilitate causal RS research.
- The available real-world datasets are compiled as follows:
- • The Coat dataset [39] (2016). The Coat dataset is a small-scale dataset crowdsourced from the Amazon Mechanical Turkers platform with 300 users and 290 items. Specifically, each Turker is first asked to self-select 24 coats to rate, where the ratings form the biased training set R   . Then each Turker is asked to rate 16 random coats, and these ratings form the unbiased test set R   .
- • Yahoo! R3 dataset [99,100] (2009). The Yahoo! R3 dataset is collected from the Yahoo! Music platform. The biased training set R   is composed of 300,000 self-supplied ratings from 15,400 users to 1,000 items. In addition, a subset of 5,400 users is presented with ten randomly selected items to rate, and the ratings are used to create the unbiased test set R   .
- • KuaiRec dataset [101] (2022). The KuaiRec dataset is established based on a popular micro-video sharing platform, KuaiShou, in China (known as Kwai internationally). The dataset records self-supplied ratings from 7,176 users to 10,728 items as the biased training set R   . The unbiased test set R   is composed of a subset of 1,411 users and 3,327 items, where the ratings between these users and items are almost fully observed (with 99.6% density).
- The statistics of the datasets are summarized in Table 1 for reference.
- There are also randomized datasets for some related topics such as click-through rate prediction [102], i.e., Criteo Ads datasets [103], and bandit-based RS [104], i.e., Open Bandit dataset [105], where the sources are also provided in case the readers are interested.
- From Table 1 we can find that, the Coat dataset is small in scale. While for the Yahoo! R3 dataset, the training set is comparatively large (15,400 users and 1,000 items), the randomized experiment conducted to establish the unbiased test set is small-scale in comparison (16 and 10 randomly exposed items per user, respectively).
- Therefore, although these ratings are unbiased due to randomization, they may not capture well-rounded user interests and therefore induce a high evaluation variance.

## Future Directions
- There are strong assumptions required by existing causal RSs
- There is a lack of a universal causal model for RSs
- Simulated datasets are often used to evaluate the effectiveness of causal RSs
- More collaborations with the industry are needed to more convincingly demonstrate the practical utility of causal RSs.

## Summary
- Traditional RSs rely on correlations in observed user behaviors and user/item features
- Two mainstream causal inference frameworks, i.e., Rubin's RCM and Pearl's SCM, are introduced
- State-of-the-art causal RS models lead to enhanced robustness to various biases and improved explainability
- Evaluation strategies for causal RSs are introduced
- Real-world datasets where expensive randomized experiments are conducted on users are introduced
- Causal RS is still a relatively new and under-explored research topic, more efforts are urgently demanded
- RSs rely on correlations in observed user behaviors and user/item features, which leads to exposure bias
- To remedy the bias, IPW-based causal RSs reweight the observed ratings
- Based on this, the following adjustment is made:
- RSs rely on correlations in observed user behaviors and user/item features, which leads to exposure bias
- To remedy the bias, IPW-based causal RSs reweight the observed ratings
- Based on this, the following adjustment is made:
- RSs reweight the observed ratings by the inverse of the propensity scores, i.e., 1
