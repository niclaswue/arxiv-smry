---
title: "Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation"
date: 2022-12-01T18:56:37.000Z
author: "Haochen Wang, Xiaodan Du, Jiahao Li, Raymond A. Yeh, Greg Shakhnarovich"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2212-00774v1.webp" # image path/url
    alt: "Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2212.00774)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2212.00774).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/score-jacobian-chaining-lifting-pretrained-2d).

# Abstract
- A diffusion model is used to predict a vector field of gradients.
- Chain rule is applied to the learned gradients.
- The score of the diffusion model is back-propagated through a differentiable renderer.
- 2D scores are aggregated into a 3D score.
- A pretrained 2D model is repurposed for 3D data generation.
- A novel estimation mechanism is proposed to address a distribution mismatch.
- The algorithm is tested on several off-the-shelf diffusion image generative models.

# Paper Content

## Introduction
- Introduce a method to convert a 2D diffusion generative model to 3D
- Diffusion models can be interpreted as learned predictors of a gradient field
- Apply the chain rule on the estimated score
- Generating a sample from a diffusion model involves repeated evaluations of the score function
- Pair a pretrained diffusion model with a differentiable renderer to create a 3D generative model
- Challenge of OOD when using a pretrained denoiser and propose Perturb-and-Average Scoring to resolve it
- Demonstrate effectiveness of SJC for 3D text-driven generation

## Related works
- Diffusion models have been used to generate images on large datasets
- Diffusion models can be interpreted as VAEs or denoising score-matchers
- Models trained under one regime can be used for inference and sampling by the other
- Neural radiance fields (NeRF) have been used for 3D reconstruction tasks
- NeRF parameterizes a volume with a neural network, but querying the network densely is costly
- Voxel NeRFs store the volume on voxels and observe no loss in end task performance
- 2D-supervised 3D GANs use unstructured 2D images to train 3D generative models
- CLIP-guided, optimization-based 3D generative models use 2D renderings to optimize 3D assets
- DreamFusion is similar to our approach at the pseudo-code level

## Preliminaries
- Denoising score matching is used to learn a denoiser D by minimizing the difference between a noised sample and the original sample
- Denoising diffusion models estimate the score function of the noised distribution at various noise levels
- Score behaves like mean-shift and there is a closed-form expression for the optimal denoiser
- Denoising score function is a non-parametric guide on how to update a sample to move it towards its weighted nearest neighbors

## Score jacobian chaining for 3d generation
- Our goal is to model and sample from a 3D scene distribution.
- We assume that the probability density of a 3D asset is proportional to the expected probability densities of its 2D renderings.
- We use Jensen's inequality to establish a lower bound on the 3D distribution.
- We use the chain rule to compute the 2D score using a pretrained diffusion model.

### Computing 2d score on non-noisy images
- Computing 3D score requires 2D score on x π
- Directly applying score from denoiser causes out-of-distribution problem
- Perturb-and-Average Scoring computes score on non-noisy images
- Perturb-and-Average Scoring approximates score on x π at inflated noise level
- Perturb-and-Average Scoring computes gradient w.r.t. lower bound of log p √ 2σ (x)

### Inverse rendering on voxel radiance field
- Represent 3D asset as voxel radiance field
- Render image independently along camera ray
- Sample (RGB, τ) tuple from color and density grids
- Vector-Jacobian product in Eq. (11) between PAAS and Jacobian
- Emptiness loss to encourage sparsity
- Center depth loss to keep object in center of image

### Sjc vs. dreamfusion
- SJC and DreamFusion have differences in terms of formulation
- SJC does not include U-Net Jacobian term
- SJC has analysis of OOD problem and PAAS method
- SJC and DreamFusion have comparable performance for 3D generation
- SJC adopted idea of randomized scheduling of σ and view-augmented language prompting from DreamFusion

## Experiments
- Experiments conducted on unconditioned and conditioned diffusion models
- Unconditioned models trained on FFHQ and LSUN Bedroom datasets
- Stable Diffusion model trained on LAION5B dataset
- Annealed σ schedule vs. Random σ schedule
- Annealed σ performs better on FFHQ and LSUN Bedroom
- Random σ performs better with stronger language guidance

### 3d generation
- Focused on 3D Generation with the language-conditioned Stable Diffusion model
- Used Random σ schedule with high language guidance scale
- Rendered with Latent 3D Features
- Compared SJC with Stable-DreamFusion
- Conducted ablations to demonstrate importance of proposed emptiness loss and scheduling of its weight

## Conclusion
- Propose an optimization-based approach to generate 3D assets from pretrained image (2D) diffusion models
- Derive Perturb-and-Average Scoring method to bridge gap between denoising-trained diffusion models and non-noisy images
- Propose new regularization loss for improving quality of generated 3D scene
- Demonstrate approach can generate compelling 3D models
- Investigate effect of noise scheduling regime in unconditional image diffusion models and a text-conditional model
- Noising step describes marginal distribution
- Stochastic differential equation describes infinitesimal time evolution
- Fokker-Planck equation states stochastic differential equation implies deterministic ODE
- Log derivative trick applied to ODE
- Schedule with s(t) = 1, σ(t) = t allows for taking large step sizes during inference
- Discretized sampling algorithm described
- Camera elevation and azimuth quadrant used to alleviate degeneracy of multiple frontal faces
- Future work to develop more general solution to induce optimization towards more plausible geometry
- Denoiser's OOD issue illustrated
- PAAS computed by averaging over multiple samples of n
- Perturb-and-Average Scoring compared between Annealed and Random σ schedule
- Text-prompted generation of 3D models with SJC
- Ablation experiments on proposed emptiness loss schedule
