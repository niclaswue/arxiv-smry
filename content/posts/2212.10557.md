---
title: "DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines"
date: 2022-12-20T18:57:18.000Z
author: "Prakhar Gupta, Yang Liu, Di Jin, Behnam Hedayatnia, Spandana Gella, Sijia Liu, Patrick Lange, Julia Hirschberg, Dilek Hakkani-Tur"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2212-10557v1.webp" # image path/url
    alt: "DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2212.10557)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2212.10557).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/dialguide-aligning-dialogue-model-behavior).

# Abstract
- Dialogue models are able to generate coherent and fluent responses
- However, unpredictability diminishes user trust and can hinder the use of the models in the real world
- To address this, we introduce DialGuide, a novel framework for controlling dialogue model behavior using natural language rules, or guidelines
- These guidelines provide information about the context they are applicable to and what should be included in the response, allowing the models to generate responses that are more closely aligned with the developer's expectations and intent
- We evaluate DialGuide on three tasks in open-domain dialogue response generation: guideline selection, response generation, and response entailment verification
- Our dataset contains 10,737 positive and 15,467 negative dialogue context-response-guideline triplets across two domains- chit-chat and safety
- We provide baseline models for the tasks and benchmark their performance
- We also demonstrate that DialGuide is effective in the dialogue safety domain, producing safe and engaging responses that follow developer guidelines

# Paper Content

## Introduction
- Rules are difficult to control and require large datasets to re-purpose them for a new task or domain
- On the other hand, most deployed conversational systems use handcrafted rules and templates (Juraska et al., 2021;Konr√°d et al., 2021;Chi et al., 2022), as they allow more control over responses, output interesting and high quality responses, and rules are easy to add and update
- However, such systems are rigid and have poor coverage
- Then the model either generates a response using one of the selected guidelines (Guideline A) in Task 2 or checks whether response candidates follow the guideline in Task 3.
- We propose a new framework, DIALGUIDE, to control dialogue response generation using natural language rules which we call guidelines
- A guideline consists of an "if x" condition part that specifies the contexts that it is relevant for and a "then y" action part that specifies what the response should contain
- We show the framework overview in Figure 1, which consists of three independent tasksguideline selection, guideline based response generation, and guideline based response entailment verification
- We adopt a retrieve-then-infer process where the model first retrieves a small set of guidelines relevant to the context and then uses one of the retrieved guidelines to either generate a response or verify if a response candidate follows the guidelines
- Using guidelines is beneficial since they can be added, removed, or edited at any point based on changes in the input distribution, the discovery of new failure modes, or evolving safety norms
- Developers can create guidelines as a control mechanism to drive system actions toward predefined agendas, create more engaging responses, and fix common problems in system outputs such as the generation of toxic responses
- Prior work on controlled response generation used task-dependent discrete labels such as emotions (Zhong et al., 2019), persona (Song et al., 2019) and dialogue acts (Hedayatnia et al., 2020). However, such approaches require labeled training data for each predetermined label, making it difficult to incorporate new control codes and mechanisms into the system
- On the other hand, guidelines are more natural for control, and incorporating a new guideline does not require retraining the model since we can simply update the guidelines while keeping the trained models intact
- This way developers or model users can easily assert their principles into the outputs of the model with minimal effort through just the guideline update.

## Related Work
- Neural dialogue models are prone to generating harmful content
- Approaches devised to mitigate such safety issues include filtering out unsafe text from training corpora, specialized decoding procedures for safer generation, and controlled language generation techniques
- Our work is closest to Kim et al. (2022a), who proposed ProSocial dialog, a multi-turn dialogue dataset where a speaker disagrees with unethical and toxic context, using safety labels and social norms

## Proposed Task and Data collection
- DIALGUIDE framework aims to enable control over a dialogue model through developer-defined guidelines.
- A guideline consists of two parts, the condition, and the action. The condition part, for example, "if a person asks if you had trouble learning a musical instrument" from Figure 1, specifies which contexts the guideline is relevant to. The action part, for example, "No, I had it easy. My tutor...", specifies what the response should contain.
- DIALGUIDE consists of the following tasks:
- Response generation: Generate a response to the conversation that follows the guideline.
- Response entailment verification: Infer whether a response is coherent to the context and follows or entails the guideline or not.
- At test time, a model first retrieves a guideline most relevant to the context. Then, a model either generates a response based on the guideline(s), or checks if a response follows the guideline(s).
- We create two versions of DIALGUIDE. For DI-ALGUIDE-BST, we augment conversations from the BlendedSkillTalk (Smith et al., 2020) (BST) dataset. We use the Amazon Mechanical Turk platform to collect annotations for the three tasks mentioned above.
- For each dialogue context, we use the Blenderbot model (Roller et al., 2021) to create a set of four responses, R b , which is used in tasks A) and C) below.
- From our manual examination, we find that most of the generated responses in R b are fluent and coherent. We describe the data collection details in the following section.
- To evaluate how well the framework generalizes to different domains, we collect data for the safety domain. For DIALGUIDE-SAFETY we augment conversations from the ProsocialDialog (Kim et al., 2022a) dataset.
- A) Guideline writing task. We collect annotations to form a triplet C, g, r cg , where C is the context, guideline g describes the context it is applicable to and the content of the responses, and response r cg is coherent with the context and follows the guideline. We collect such annotations through two mechanisms: In mechanism 1, we show the annotators the dialogue context and a response, and they write a guideline such that the provided response can be created based on the guideline. The guideline should cover at least some aspects of the response but does not need to cover all the details of the response.
- In mechanism 2, we show the annotators the dialogue context and ask them to write a guideline and then a response that follows the guideline. We add that response to R b .
- To aid the annotators, we provide hints in the form of a small set of guideline phrases, such as "ask a question about x", and "give a reason for doing x", that they use as part of the guideline.
- Workers are shown multiple good and bad examples for the task and are encouraged to use abstract concepts in the guidelines so that they can generalize over novel contexts.
- For example, in Figure 1 the condition "...learning a musical instrument" instead of "...learning piano" generalizes the guideline to any musical instrument. While mechanism 1 reduces the cognitive load of the workers since they do not need to write responses, guidelines can become very specific to the provided response.
- Using mechanism 2, we obtained more abstract guidelines through the guideline phrase hints (such as "change the topic to x").
- In Figure 2, we show the annotation interface for mechanism 1. We call the set of context-guidelines-responses instances collected from this task G ann .
- B) Guideline annotation task. For a context C, workers are shown a set of guidelines G c (g 1 , g 2 , ..g k ) (only the condition part), and asked to...

## Experiments and Results
- The experimental setup consisted of a web-based task where participants were asked to retrieve a set of guidelines from a website.
- The results showed that participants were able to retrieve the guidelines successfully, but they were not able to correctly select the guidelines that they wanted to use.
- The results also showed that participants were not able to correctly verify the entailment of the guidelines.

### Guideline Retrieval
- The Dialbart0 model trained on safety guideline data.
- The Dialbart0 model pre-trained on Instructdial (Gupta et al., 2022b) tested on zero-shot generation with guidelines.
- The Dialbart-rot baseline uses RoTs or rules of thumbs (such as "it is bad to be racist").
- ROTs do not contain the if condition (for example, "If someone wants to steal food"), and thus selecting the correct ROT at test time is harder than selecting a guideline since they do not contain the information about the contexts the ROTs are relevant for.
- Dialbart-rot has similar performance to DIAL-GUIDE-tuned, however RoTs are often very generic which leads to poor control as evident by the lower RS-entail score (61.7).
- We perform ablation experiments with a few baselines.
- The No-guidelines baseline that is not trained on safety data without guidelines or RoTs can generate safe responses, but lack control, whereas DIALGUIDE-tuned can generate safe responses based on the developers agenda.
- Although Safety-only baseline trained exclusively on DIAL-GUIDE-SAFETY performs better than BST-only, the peformance of BST-only trained on DIALGUIDE-BST is close, which implies that a model that uses guidelines can perform well on cross-domain settings.

### Response Generation
- We train all models using batch size 8 on 6 GPUs
- The models are provided with the dialogue context and the guideline as input and output the response as output.
- The Ret-generate model is trained in the same as the DIALGUIDE-tuned model, but at inference time we retrieve the guidelines in two steps -we first retrieve a large set of guidelines using BM25 + DPR (100 from each) for faster inference, and then rerank these using the Rerank-Deberta (silver+ann) model from Section 4.1.
- The final guideline is selected randomly from the set of guidelines with a score greater than 98% from the Deberta model.
- For evaluation we report Bleu-2,4 and RougeL scores based on reference responses.
- We measure the similarity between the guideline and the response using Bleu-2 and report it as Gd-Bleu-2.
- We use the response entailment model BSTGuide to measure whether the response follows the guideline and we name the metric RS-entail.

## Qualitative Analysis

## Conclusion
- DialGuide framework and dataset provide a solution for controlling dialogue model behavior using natural language rules, or guidelines.
- Through the three tasks of guideline selection, response generation, and response entailment verification, Dial-Guide aims to enable better control over the generation semantics of dialogue models and improve their trustworthiness and real-world use.
- We evaluate DialGuide on two domains, chit-chat and safety, and provide baseline models and benchmark performance for these tasks.
- We also show that models trained on the DialGuide data can generate coherent and diverse responses that generalize well to new guidelines and contexts, and demonstrate the usefulness of DialGuide in the dialogue safety domain by generating safe and engaging responses that follow developer guidelines.
- Our work explores aligning and controlling dialogue models towards developer defined natural lan- guages.
