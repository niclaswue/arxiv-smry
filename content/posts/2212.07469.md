---
title: "Learning threshold neurons via the "edge of stability""
date: 2022-12-14T19:27:03.000Z
author: "Kwangjun Ahn, Sébastien Bubeck, Sinho Chewi, Yin Tat Lee, Felipe Suarez, Yi Zhang"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2212-07469v1.webp" # image path/url
    alt: "Learning threshold neurons via the "edge of stability"" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2212.07469)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2212.07469).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/learning-threshold-neurons-via-the-edge-of).

# Abstract
- Existing analyses of neural network training often operate under the unrealistic assumption of an extremely small learning rate.
- This lies in stark contrast to practical wisdom and empirical studies, such as the work of J. Cohen et al. (ICLR 2021), which exhibit startling new phenomena (the "edge of stability" or "unstable convergence") and potential benefits for generalization in the large learning rate regime.
- Despite a flurry of recent works on this topic, however, the latter effect is still poorly understood. In this paper, we take a step towards understanding genuinely non-convex training dynamics with large learning rates by performing a detailed analysis of gradient descent for simplified models of two-layer neural networks.
- For these models, we provably establish the edge of stability phenomenon and discover a sharp phase transition for the step size below which the neural network fails to learn "threshold-like" neurons (i.e., neurons with a non-zero first-layer bias). This elucidates one possible mechanism by which the edge of stability can in fact lead to better generalization, as threshold neurons are basic building blocks with useful inductive bias for many tasks.

# Paper Content

## Introduction
- We begin with a simple and canonical learning task which indicates that the answer is still "far too little".
- Motivating example: Consider a binary classification task of labeled pairs (x (i) , y (i) ) ∈ R d ×{±1} where each covariate x (i) consists of a 1-sparse vector (in an unknown basis) corrupted by additive Gaussian noise, and the label y (i) is the sign of the non-zero coordinate of the 1-sparse vector.
- Due to rotational symmetry, we can take the unknown basis to be the standard one and write where y (i) ∈ {±1} is a random label, j(i) ∈ [d] is a random index, ξ (i) is Gaussian noise, and λ > 1 is the unknown signal strength.
- In fact, (1.1) is a special case of the well-studied sparse coding model [OF97; VG00; OF04; Yan+09; AL22; KR18].
- We ask the following fundamental question: How do neural networks learn to solve the sparse coding problem (1.1)?
- In spite of the simplicity of the setting, a full resolution to this question requires a thorough understanding of surprisingly rich dynamics which lies out of reach of existing theory.
- To illustrate this point, consider an extreme simplification in which the basis e 1 , . . . , e d is known in advance, for which it is natural to parametrize a two-layer ReLU network as The parametrization (1.2) respects the latent data structure (1.1) well: a good network has a negative bias b to threshold out the noise, and has a − < 0 and a + > 0 to output correct labels.
- We are particularly interested in understanding the mechanism by which the bias b becomes negative, thereby allowing the non-linear ReLU activation to act as a threshold function; we refer to this as the problem of learning "threshold neurons".
- More broadly, such threshold neurons are of interest as they constitute basic building blocks for producing neural networks with useful inductive bias.
- Figure 2: Large learning rates lead to unexpected phenomena: non-monotonic loss and wild oscillations of weights.
- We choose the same setting as Figure 1. With a small learning rate (η = 2.5 • 10 −5 ), the bias does not decrease noticeably, and the same is true even when we increase the learning rate by ten times (η = 2.5 • 10 −4 ). When we increase the learning rate by another ten times (η = 2.5 • 10 −3 ), we finally see a noticeable decrease in the bias, but with this we observe unexpected behavior: the loss decreases non-monotonically and the sum of second-layer weights d • (a − + a + ) oscillates wildly.
- We train the parameters a − , a + , b using gradient descent with step size η > 0 on the logistic loss n i=1 logi (y (i) f (x (i) ; a − , a + , b)), where logi (z) := log(1 + exp(−z)), and we report the results in Figures 1 and 2.
- The experiments reveal a compelling picture of the optimization dynamics. Large learning rates are necessary, both for generalization and for learning threshold neurons.

### Main scope of this work
- The dynamics of the simple ReLU network (1.2) is a microcosm of emergent phenomena beyond the convex optimization regime.
- In fact, there is a recent growing body of work [Coh+21; ALP22; AZS22; CB22; DNL22; LLA22a; LLA22b; Ma+22; Zhu+22] on training with large learning rates, which largely aims at explaining a striking empirical observation called the "edge of stability (EoS)" phenomenon.
- The main observation of [Coh+21] is that when training neural networks1 with constant step size η > 0, the largest eigenvalue of the Hessian at the current iterate (dubbed the "sharpness") initially increases during training ("progressive sharpening") and saturates near or above the value 2/η ("EoS").
- A surprising message of the present work is that the answer to our main question is intimately related to the EoS.
- Consequently, we first set out to thoroughly understand the workings of the EoS phenomena through a simple example. Specifically, we consider a single-neuron linear neural network in dimension 1, corresponding to the loss where is convex, even, and Lipschitz .
- Although toy models have appeared in works on the EoS (see Subsection 1.3), our example is simpler than all prior models, and we provably establish the EoS for (1.3) with transparent proofs.
- We then use the newfound insights gleaned from the analysis of (1. 3) to answer our main question.

### Our contributions
- Explaining the EoS with a single-neuron example
- The connection between the singleneuron example and the ReLU network (1.2) can already be anticipated
- In fact, this connection can be made formal by considering an approximation for the GD dynamics for the ReLU network (1.2)
- For any δ > 0, • if η ≤ (8 − δ)π/d 2 , then the mean model fails to learn threshold neurons: the limiting bias satisfies • if η ≥ (8+δ)π/d 2 , then the mean model enters the EoS and learns threshold neurons: the limiting bias satisfies b ∞ ≤ −Ω δ

### Related work
- Edge of stability: Our work is motivated by the extensive empirical study of Coh+21, which identified the EoS phenomenon.
- Properties of the loss landscape: The concurrent works AZS22; Ma+22 study the properties of the loss landscape that lead to the EoS. Namely, Ahn, Zhang, and Sra [AZS22] argue that the existence of forward-invariant subsets near the set of minimizers allows GD to convergence even in the unstable regime. They also explore various characteristics of EoS in terms of loss and iterates.
- Also, Ma et al. [Ma+22] empirically show that the loss landscape of neural networks exhibits subquadratic growth locally around the minimizers. They prove that for a one-dimensional loss, subquadratic growth implies that GD finds a 2-periodic trajectory.
- Limiting dynamics: Other works characterize the limiting dynamics of the EoS in various regimes. The works [ALP22;LLA22b] show that (normalized) GD tracks a "sharpness reduction flow" near the manifold of minimizers. The recent work of Damian, Nichani, and Lee [DNL22] obtains a different predicted dynamics based on self-stabilization of the GD trajectory. Also, Ma et al. [Ma+22] describes a quasi-static heuristic for understanding the overall trajectory of GD when one component of the iterate is oscillating.
- Simple models and beyond: Closely related to our own approach, there are prior works which carefully study simple models. Chen and Bruna [CB22] prove global convergence of GD for the two-dimensional function (x, y) → (xy − 1) 2 and a single-neuron student-teacher setting; note that unlike our results, they do not study the limiting sharpness.
- Lyu, Li, and Arora [LLA22a] study progressive sharpening for a neural network model. Also, the recent and concurrent work of Zhu et al. [Zhu+22] studies the two-dimensional loss (x, y) → (x 2 y 2 − 1) 2 ; to our knowledge, their work is the first to asymptotically and rigorously show that the limiting sharpness of GD is 2/η in a simple setting, at least when initialized locally.
- In comparison, in Section 2, we perform a global analysis of the limiting sharpness of GD for (x, y) → (xy) for a class of convex, even, and Lipschitz losses , and in doing so we clearly delineate the "gradient flow regime" from the "EoS regime".
- Effect of learning rate on learning: Recently, several works have sought to understand how the choice of learning rate affects the learning process, in terms of the properties of the resulting minima [Jas+18; WME18; MMS21; Nac+22] and the behavior of optimization dynamics [Xin+18; Jas+19; Jas+20; Lew+20]. In particular, the effect of learning rate on generalization is theoretically studied under various settings, as we summarize below. Li et al. [LWM19] demonstrate for a synthethic data distribution and a two-layer ReLU network model that choosing a larger step size for SGD helps with generalization. Subsequent works have shown similar phenomena for regression [Nak20; Wu+21; Ba+22], kernel ridge regression [BMR22], and linear diagonal networks [Nac+22]. However, the large step sizes considered in these work still fall under the scope of descent lemma, and most prior works do not theoretically investigate the effect of large step size in the EoS regime. A notable exception is the work of [Wan+22], which studies the impact of learning rates greater than 2/smoothness for a matrix factorization problem.
- Also, the recent work of [And+22] seeks to explain the generalization benefit of SGD in the large step size regime by relying on a heuristic SDE model for the case of linear diagonal networks. Despite this similarity, their main scope is quite different from ours, as we (i) focus on GD instead of SGD and (ii) establish a direct and detailed analysis of the GD dynamics for a model of the motivating sparse coding example.

## Single-neuron linear network
- The single-neuron linear network model is a model of the behavior of a single neuron.
- The model is used to study the behavior of a single neuron.
- The model is used to study the behavior of a single neuron.

### Basic properties and assumptions
- Basic properties
- Assumptions
- Properties of
- Lemma 2
- Example 3
- Higher-order

### Two different regimes for GD depending on the step size
- The GD dynamics are symmetric in x, y and that the lines y = ±x are invariant.
- The gradient flow admits a conserved quantity, thereby allowing us to predict the dynamics in this initial phase.
- Lemma 4 (conserved quantity): Along the gradient flow for f , the quantity y 2 − x 2 is conserved.
- Proof. Differentiating y 2 t − x 2 t with respect to t gives 2y t (− (x t y t ) x t ) − 2x t (− (x t y t ) y t ) = 0.
- Lemma 4 implies that the gradient flow converges to (0, y GF ∞ ) = (0, y 2 0 − x 2 0 ).
- For GD with step size η > 0, the quantity y 2 − x 2 is no longer conserved, but we show in Lemma 12 that it is approximately conserved until the GD iterate lies close to the y-axis.
- Hence, GD initialized at (x 0 , y 0 ) also reaches the y-axis approximately at the point (x t 0 , y t 0 ) ≈ (0, y 2 0 − x 2 0 ).
- At this point, GD either approximately converges to the gradient flow solution (0, y 2 0 − x 2 0 ) or diverges away from it, depending on whether or not y 2 t 0 > 2/η.
- To see this, for |x t 0 y t 0 | 1, we can Taylor expand near zero to obtain the approximate dynamics for x (recalling (0) = 1),
- 3), we deduce the following conclusions. < 1 for all t ≥ t 0 , and so |x t | converges to zero exponentially fast.
- (ii) On the other hand, if y 2 t 0 > 2/η, then |1 − ηy 2 t 0 | > 1, i.e., the magnitude of x t 0 increases in the next iteration, and hence GD cannot stabilize. In fact, in the approximate dynamics, x t 0 +1 has the opposite sign as x t 0 , i.e., x t 0 jumps across the y-axis.
- One can show that the "bouncing" of the x variable continues until y 2 t has decreased past 2/η, at which point we are in the previous case and GD approximately converges to (0, 2/η).
- This reasoning, combined with the expression for the Hessian of f , shows that Accordingly, we refer to the case y 2 0 − x 2 0 < 2/η as the gradient flow regime, and the case y 2 0 − x 2 0 > 2/η as the EoS regime. See Figure 5 for illustrations of these two regimes.

### Results

## Understanding the bias evolution of the ReLU network
- The role of a large step size during the "initial phase" of training in which (i) the bias b rapidly decreases and (ii) the sum of weights a − + a + oscillates.
- Approximating the initial phase of GD with the "mean model" leads to an approximation of the GD dynamics on the population loss E[ logi (yf (x; a − , a + , b))]: where sym (s) := 1 2 (log(1 + exp(−s)) + log(1 + exp(+s))) is the symmetrized logistic loss.
- The mean model is the GD dynamics on (a − , a + , b) → sym (d (a − + a + ) g(b)).

### Two different regimes for the mean model
- The mean model exhibits two different regimes depending on the step size.
- The EoS regime corresponds to when the step size is above the threshold 8π/d 2 .
- The bias decreases more with the large learning rate.
- The average of second layer weights oscillates.
