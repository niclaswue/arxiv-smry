---
title: "Unsupervised Representation Learning from Pre-trained Diffusion Probabilistic Models"
date: 2022-12-26T02:37:38.000Z
author: "Zijian Zhang, Zhou Zhao, Zhijie Lin"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "https://ik.imagekit.io/smryai/2212-12990v2_yy8CTBIuS.jpg" # image path/url
    alt: "Unsupervised Representation Learning from Pre-trained Diffusion Probabilistic Models" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2212.12990)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2212.12990).


# Abstract
- Diffusion probabilistic models (DPMs) have shown a powerful capacity of generating high-quality image samples
- Recently, diffusion autoencoders (Diff-AE) have been proposed to explore DPMs for representation learning via autoencoding
- Their key idea is to jointly train an encoder for discovering meaningful representations from images and a conditional DPM as the decoder for reconstructing images
- Considering that training DPMs from scratch will take a long time and there have existed numerous pre-trained DPMs, we propose pre-trained DPM autoencoding (PDAE), a general method to adapt existing pre-trained DPMs to the decoders for image reconstruction
- Extensive experiments demonstrate the effectiveness, efficiency and flexibility of PDAE.

# Paper Content

## Introduction
- Deep generative models such as variational autoencoders (VAEs), generative adversarial networks (GANs), autoregressive models, normalizing flows (NFs), and energybased models (EBMs) have shown remarkable capacity to synthesize striking image samples.
- Recently, another kind of generative models, Diffusion Probabilistic Models (DPMs) are further developed and becoming popular for their stable training process and state-of-the-art sample quality.
- Although a large number of degrees of freedom in implementation, the DPMs discussed in this paper will refer exclusively to those trained by the denoising method proposed in DDPMs.

### Denoising Diffusion Probabilistic Models
- DDPMs employ a forward process that starts from the data distribution q(x 0 ) and sequentially corrupts it to N (0, I) with Markov diffusion kernels q(x t |x t−1 ) defined by a fixed variance schedule {β t } T t=1 .
- The process can be expressed by: q(x t |x t−1 ) = N (x t ; 1 − β t x t−1 , β t I) q(x 1:T |x 0 ) = T t=1 q(x t |x t−1 ) , where {x t } T t=1 are latent variables of DDPMs.
- According to the rule of the sum of normally distributed random variables, we can directly sample x t from x 0 for arbitrary t with q(x t |x 0 ) = N (x t ; √ ᾱt x 0 , (1 − ᾱt )I), where α t = 1 − β t and ᾱt =
- The forward process of DDPMs can be expressed as a sum of normally distributed random variables.

### Denoising Diffusion Implicit Models
- DDIMs define a non-Markov forward process that leads to the same training objective as DDPMs, but the corresponding reverse process can be much more flexible and faster to sample from.
- Specifically, one can sample x t−1 from x t using the θ of some pre-trained DDPMs via: where t ∼ N (0, I) and σ t controls the stochasticity of forward process.
- The strides greater than 1 are allowed for accelerated sampling.

### Classifier-guided Sampling Method
- Classifier-guided sampling method
- Shows that one can train a classifier on noisy data and use its gradient to guide some pre-trained unconditional DDPM to sample towards specified class y
- The conditional reverse process can be approximated by a Gaussian similar to that of the unconditional one in Eq.(2), but with a shifted mean: p θ,φ (x t−1 |x t , y) ≈ N (x t−1 ; µ θ (x t , t) + Σ θ (x t , t) • ∇ xt log p φ (y|x t ) , Σ θ (x t , t))

### Forward Process Posterior Mean Gap
- Conditional DPMs can approximate the same forward process posterior q(x t−1 |x t , x 0 ) = N (x t−1 ; µ t (x t , x 0 ), 1− ᾱt−1 1− ᾱt β t I) as the unconditional DPMs, but there is a gap between the posterior mean predicted by the two.
- The more information of x 0 that y contains, the smaller the gap is.
- The Gaussian mean of classifier-guided conditional reverse process contains an extra shift item compared with that of the unconditional one.

### Unsupervised Representation Learning by Filling the Gap
- Employs an encoder z = E ϕ (x 0 ) to learn compact and meaningful representations from input images
- Uses a gradient estimator G ψ (x t , z, t) to simulate ∇ xt log p(z|x t ), where p(z|x t ) is some implicit classifier that we will not use explicitly
- Uses pre-trained DPMs so that θ are frozen during the optimization
- Usually sets 2 , which forces the predicted mean shift Σ θ (x t , t) • G ψ (x t , E ϕ (x 0 ), t) to fill the posterior mean gap µ t (x t , x 0 ) − µ θ (x t , t)

### Network Design
- Figure 2 shows the network and data flow of PDAE
- For encoder E ϕ , unlike Diff-AE that uses the encoder part of U-Net [40], we find that simply stacked convolution layers and a linear layer is enough to learn meaningful z from x 0 .
- For gradient estimator G ψ , we use U-Net similar to the function approximator θ of pre-trained DPM. Considering that θ also takes x t and t as input, we can further leverage the knowledges of pre-trained DPM by reusing its trained encoder part and time embedding layer, so that we only need to employ new middle blocks, decoder part and output blocks of U-Net for G ψ .
- To incorporate z into them, we follow [8] to extend Group Normalization [53] by applying scaling & shifting twice on normalized feature maps.

### Weighting Scheme Redesign

## Experiments
- To compare PDAE with Diff-AE, we follow their experiments with the same settings.
- Moreover, we also show that PDAE enables some added features.
- For fair comparison, we use the baseline DPMs provided by official Diff-AE implementation as our pre-trained models (also as our baselines), which have the same network architectures (hyperparameters) with their Diff-AE models.
- For brevity, we use the notation such as "FFHQ128-130M-z512-64M" to name our model, which means that we use a baseline DPM pre-trained with 130M images and leverage it for PDAE training with 64M images, on 128 × 128 FFHQ dataset [21], with the semantic latent code z of 512-d.

### Training Efficiency
- We think that the reason that PDAE needs less training time than Diff-AE is because Diff-AE needs to model the posterior mean gap, which is easier to do with pre-trained DPMs.
- The network reuse and weighting scheme redesign also help.

### Learned Mean Shift Fills Posterior Mean Gap
- We train a model of "FFHQ128-130M-z512-64M"
- We show that our learned mean shift can fill the posterior mean gap with qualitative and quantitative results
- Specifically, we select some images x 0 from FFHQ, sample x t = √ ᾱt x 0 + √ 1 − ᾱt for different t and predict x0 from x t by denoising them for only one step (i.e., ), using pre-trained DPM and PDAE respectively
- As we can see in the figure (left), even for large t, PDAE can predict accurate noise from x t and reconstruct plausible images, which shows that the predicted mean shift fills the posterior mean gap and the learned representation helps to recover the lost information of forward process

### Autoencoding Reconstruction
- FFHQ128-130M-z512-64M is used to run autoencoding reconstruction examples
- Both DDIM and DDPM generate samples with similar contents to the input
- Some stochastic variations occur in minor details of hair, eye and skin when introducing stochasticity
- Due to the similar performance, we will always use DDIM sampling method in later experiments
- PDAE is competitive with the state-of-the-art NVAE even with much less latent dimensionality and also outperforms Diff-AE in all metrics except the LPIPS for random x T

### Interpolation of Semantic Latent Codes and Trajectories
- Given two images x 1 0 and x 2 0 from FFHQ, we use "FFHQ128-130M-z512-64M" to encode them into (z 1 , x 1 T ) and (z 2 , x 2 T ) and run PDAE generative process of DDIM starting from Slerp(x 1 T , x 2 T ; λ) under the guidance of G ψ x t , Lerp(z 1 , z 2 ; λ), t with 100 steps, expecting smooth transitions along λ.
- From the view of the diffusion trajectories, PDAE generates desired samples by shifting the unconditional sampling trajectories towards the spatial direction predicted by G ψ (x t , z, t). This enables PDAE to directly interpolate between two different sampling trajectories.
- Intuitively, the spatial direction predicted by the linear interpolation of two semantic latent codes, G ψ x t , Lerp(z 1 , z 2 ; λ), t , should be equivalent to the linear interpolation of two spatial directions predicted by respective semantic latent code, Lerp G ψ (x t , z 1 , t), G ψ (x t , z 2 , t); λ .
- We present some examples of these two kinds of interpolation methods in Figure 7. As we can see, both methods generate similar samples that smoothly transition from one endpoint to the other, which means that G ψ x t , Lerp(z 1 , z 2 ; λ), t ≈ Lerp G ψ (x t , z 1 , t), G ψ (x t , z 2 , t); λ , so that G ψ (x t , z, t) can be seen as a function of z analogous to a linear map.

### Attribute Manipulation
- We can explore the learned semantic latent space in a supervised way.
- To illustrate this, we train a model of "CelebA-HQ128-52M-z512-25M" and conduct attribute manipulation experiments by utilizing the attribute annotations of CelebA-HQ dataset.
- Specifically, we first encode an image to its semantic latent code, then move it along the learned direction and finally decode it to the manipulated image.
- Similar to Diff-AE, we train a linear classifier to separate the semantic latent codes of the images with different attribute labels and use the normal vector of separating hyperplane (i.e. the weight of linear classifier) as the direction vector.
- We present some attribute manipulation examples in Figure 8.

### Truncation-like Effect
- According to [8,15], we can obtain a truncation-like effect in DPMs by scaling the strength of classifier guidance.
- We have assumed that G ψ (x t , z, t) trained by filling the posterior mean gap simulates the gradient of some implicit classifier, and it can actually work as desired.
- In theory, it can also be applied in truncation-like effect.
- To illustrate this, we directly incorporate the class label into G ψ (x t , y, t) and train it to fill the gap. Specifically, we train a model of "ImageNet64-77M-y-38M" and use DDIM sampling method with 100 steps to generate 50k samples, guided by the predicted mean shift with different scales for a truncation-like effect.
- Figure 9 shows the sample quality effects of sweeping over the scale. As we can see, it achieves the truncation-like effect similar to that of classifier-guided sampling method, which helps us to build connections between filling the posterior mean gap and classifier-guided sampling method.

### Few-shot Conditional Generation
- D2C is a method for training a model to generate images that look like those in a given dataset
- D2C uses a latent space model to learn how to generate images that look like those in a given dataset
- PDAE is a method that achieves better FID scores than Diff-AE and D2C

### Improved Unconditional Sampling
- z is used to improve the unconditional sampling of pre-trained DPMs
- PDAE uses an independent gradient estimator as a corrector of the pre-trained DPM for sampling
- PDAE can be applied for any pre-trained DPMs as an auxiliary booster to improve their sample quality

## Related Work
- Our work is based on an emerging latent variable generative model known as Diffusion Probabilistic Models (DPMs) [43,14], which are now popular for their stable training process and competitive sample quality.
- Numerous studies [34,24,8,15,44,19,46,30] and applications [5,26,18,32,57,6,29,41,3,16,17] have further significantly improved and expanded DPMs.
- Unsupervised representation learning via generative modeling is a popular topic in computer vision.
- Latent variable generative models, such as GANs [13], VAEs [25,39], and DPMs, are a natural candidate for this, since they inherently involve a latent representation of the data they generate.
- For GANs, due to its lack of inference functionality, one have to extract the representations for any given real samples by an extra technique called GAN Inversion [54], which invert samples back into the latent space of trained GANs.
- Existing inversion methods [58,35,4,1,2,51] either have limited reconstruction quality or need significantly higher computational cost.
- VAEs explicitly learn representations for samples, but still face representation-generation trade-off challenges [49,42].
- VQ-VAE [49,37] and D2C [42] overcome these problems by modeling latent variables post-hoc in different ways.
- DPMs also yield latent variables through the forward process. However, these latent variables lack high-level semantic information because they are just a sequence of spatially corrupted images.
- In light of this, diffusion autoencoders (Diff-AE) [36] explore DPMs for representation learning via autoencoding. Specifically, they jointly train an encoder for discovering meaningful representations from images and a conditional DPM as the decoder for image reconstruction by treating the representations as input conditions.
- Diff-AE is competitive with the state-of-the-art model on image reconstruction and capable of various downstream tasks.
- Compared with Diff-AE, PDAE leverages existing pre-trained DPMs for representation learning also via autoencoding, but with better training efficiency and performance.

## Conclusion
- PDAE is a general method for representing data that is more efficient and effective than Diff-AE
- The key idea is based on the concept of posterior mean gap and its connections with classifier-guided sampling method
- A concurrent work, textual inversion of pre-trained text-to-image DPMs, can also be explained from this perspective

### C.2 Autoencoding Reconstruction
- Figure 5 shows autoencoding reconstruction examples using different models
- Figure 6 shows autoencoding reconstruction examples using a deterministic method
- Figure 7 shows autoencoding reconstruction examples using a stochastic method
- Both the deterministic and stochastic methods can generate samples with similar contents to the input except for some minor details, such as sheet pattern and wrinkle for LSUN-Bedroom; horse eye, spot and mane for LSUN-Horse.

### C.3 Interpolation of Semantic Latent Codes and Trajectories
- Figure 8 shows two interpolation methods, one using a model and one using a manually selected set of similar images.
- Both methods generate similar samples that smoothly transition from one endpoint to the other.

### C.4 Attribute Manipulation
- PDAE can move semantic latent codes
- PDAE can change attribute-relevant features
- PDAE can keep other irrelevant details almost stationary

### C.5 Few-shot Conditional Generation
- PDAE can generate samples belonging to specified class for different few-shot scenarios
- Semantic latent codes are easy to classify even with a very small number of labeled samples

### C.6 Visualization of Mean Shift
- The gradient estimator learns a mean shift direction towards x 0 for each x t .
- The gradient estimator is a linear function of the input variables x t and the output variables E ϕ (x 0 ).
- The gradient estimator is unbiased and consistent.

## D Limitations and Potential Negative Societal Impacts
- PDAE has a slower inference speed than Diff-AE
- Although many studies have been able to achieve decent performance with few reverse steps, they still lag behind VAEs and GANs
- Almost perfect PDAE reconstruction needs hundreds of extra forward steps to infer the stochastic latent code
- We leave empirical and theoretical investigations of this aspect as future work
