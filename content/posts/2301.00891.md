---
title: "Understanding Political Polarisation using Language Models: A dataset and method"
date: 2023-01-02T22:15:04.000Z
author: "Samiran Gode, Supreeth Bare, Bhiksha Raj, Hyungon Yoo"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2301-00891v1.webp" # image path/url
    alt: "Understanding Political Polarisation using Language Models: A dataset and method" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2301.00891)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2301.00891).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/understanding-political-polarisation-using).

# Abstract
- Our paper aims to analyze political polarization in US political system
- The availability of this information will help voters understand their candidates' views on the economy, healthcare, education and other social issues
- Our main contributions are a dataset extracted from Wikipedia that spans the past 120 years and a Language model based method that helps analyze how polarized a candidate is
- Our data is divided into 2 parts, background information and political information about a candidate, since our hypothesis is that the political views of a candidate should be based on reason and be independent of factors such as birthplace, alma mater, etc.
- We further split this data into 4 phases chronologically, to help understand if and how the polarization amongst candidates changes

# Paper Content

## Introduction
- Poole and Rosenthal 1984
- Jiang, Robertson, and Wilson 2020
- Chen, Li, and Liu 2022
- Word2Vec (Mikolov et al. 2013)
- Doc2Vec (Le and Mikolov 2014)
- Transformers (Vaswani et al. 2017)
- Longformers (Beltagy, Peters, and Cohan 2020)

## Related Work
- Political polarization is visible online
- The authors use machine translation to interpret political polarization on the internet
- The authors discuss the impacts of hyper-partisan websites on influencing public opinion
- The authors then show how certain political biases are assumed for the purpose of their study, namely overt support for either a Democrat or Republican is taken to be an indicator of the site being either Liberal or Conservative
- This paper is fundamental to our research as it looks into the political division and lays the foundation for any following work in the domain of using specific features to classify an entity as being Liberal or Conservative
- The features they considered were transcripts of the content being published or shared on these sites
- In our case, the features will simply be the Wikipedia page content of the people
- (KhudaBukhsh et al. 2022) shows the polarization in TV media and fringe new networks and uses Language model-based techniques to understand them further
- However, this polarization visible in the electorate stems from the candidates
- (DeSilver 2022) claims that the candidates become polarized and moved away from the center over the years
- With this paper, we release a dataset and a few metrics that will help us understand if political polarization exists in political candidates and how we might be able to measure this political polarization
- The aim of this study is to aid voters to make informed decisions before elections
- And we use language-based techniques on a dataset that is classified into 4 eras and divided into 3 parts, mainly background, political and other
- (Belcastro et al. 2020) Demonstrates that Political Polarization can be mapped with the help of Neural Networks
- This is almost a baseline idea as we are using attention networks and Longformer models for the same
- The key difference lies in the data extraction and methodology
- (Khadilkar, KhudaBukhsh, and Mitchell 2022) goes in depth towards finding gender and racial bias in a large sample of Bollywood (and Hollywood) movies
- The author has amalgamated several known NLP models while he tries to create a reasonably robust model of his own
- The portions in which this particular study differs from those before is that the sample size is fairly large
- It then diverges further with its rather innovative use of diachronic-word embedding association tests (WEAT)
- Other techniques that are implemented include count-based statistics dependent on a highly popular lexicon cloze test using BERT as a base model (an idea we could consider after data attention) and bias recognition using WEAT
- The final model is a combination of the above three
- (Rajani et al. 2019) tried to improve speech-based models on their ability to verbalize the reasoning that they learned during training
- It uses the CAGE framework (Common-Sense Auto-Generated Explanations) on the common sense explanation dataset to increase the effectiveness by 10 percent
- It introduces improvements over the use of BiDAF++ (augmented with self-attention layer) in these newer models
- It further uses NLE as rationale generalization within the second phase primarily as means for sentiment analysis
- In this paper, Mturk (from Amazon) is used to generate explanations for the dataset
- CAGE primarily uses a questionanswer format with 3 options, a label and the best explanation for that label
- Furthermore, other evaluation parameters affecting performance are tested and may be used in our project either as verification models or otherwise
- BERT is certainly an interesting choice for verification given the higher accuracy it attains
- A factor to be considered however is that the types of datasets and models are very different
- Thus certain modifications will be made to the above framework

### Data Collection and Processing
- We scrape Wikipedia based on the list of politicians from the Wikipedia page for each congress.
- For each congress member in the list, we store the label, their party and the metadata.
- For each instance, this includes their personal details and all the information from their page as a dictionary, with the heading being the keys and the content being the value.
- This information helps with the downstream task of cleaning.
- We annotate this data based on the experiment, in our case we have manually annotated the data to classify these keys into three separate categories.
- 1) Background data, 2) Political data, 3) Other; in our release, we will be releasing both the annotated and raw versions to facilitate custom use.
- Wikipedia page sections don't have a fixed format, each politician has different key sections.
- For instance, Early Life and Background can be split into many sections such as Education, Career, Family, Personal History, etc. So all these sections are grouped into a single category Background.
- Similarly, anything related to their political affiliation, elections, campaigns and positions held during their tenure are categorized into a single annotation Political Career.
- All other categories such as Awards, Controversies, Business related activity, Post political career are clubbed under the Others category.
- This way, only relevant data is selected under each category by manually changing the annotation based on the content inside each category.
- To conclude, for just Phase 4, a total of 1656 categories were merged into 3 categories for 1631 instances in the first pass spread over roughly 26 years.

## Language Model
- Natural Language Processing based applications have been dominated by transformer-based language models where models like BERT (Devlin et al. 2018) and RoBERTa(Liu Our initial experiments were aimed at gaining insights about patterns or trends that might be present in our data, and also questioning if polarization exists.
- We do these preliminary experiments using the Doc2Vec (Le and Mikolov 2014) and Word2Vec (Mikolov et al. 2013) models.
- The Doc2Vec model was built from scratch with the raw data, where each Wikipedia page is considered to be a document.
- We first use the Doc2Vec model with K-means clustering and get a classification accuracy of 59.52% with political data and 61.846% with background data.
- We then used the same Doc2Vec model with binary SVM classifier and achieved an accuracy of 72.872% with political data and 63.564% with background data.
- These results are summarized in the table presented below.
- The Word2Vec tests were run on pretrained models as well as models we built from scratch and trained using the data we collected.
- We used the Word2Vec approach to find approximate nearest neighbors and exact nearest neighbors for certain words on both the Democratic and the Republican sides.
- This nearest-neighbor approach led to some interesting insights.
- We expected to see some disparity in the nearest neighbor searches for the Republican data and Democratic data basis the assumption that there is polarization. However using the simple Word2Vec models the 15 nearest neighbors we got were quite similar but as there were certain words for whom the order of the neighbors changed based on the party, for example, for the word 'GUN' , 'VIOLENCE' is the 2 nd nearest neigh-bor(approximate nearest neighbor using spotify's annoy algorithm) for democratic data however the same word is 9 th for the republican case, similarly the word 'CHECKS' is the 3 rd nearest neighbor for democrats while it is the 8 th for republicans.
- There are more such interesting examples which coupled with the results from the Doc2Vec classification results, prove that political polarization exists and can be learned using Natural Language Processing based techniques.

### Main analysis
- RoBERTa is used to determine the political leaning of a text
- The removal of words like "Democratic", "Republican" etc. causes a drop in classification
- Longformer is used to determine the political leaning of a text
- The background of a candidate can also help identify the political leaning of a person

## Results
- We tested different models with the annotated raw dataset to understand the polarization in the text.
- The three models were tested with both the political career dataset and the
- Apart from these accuracy tests, we also leverage the attention mechanism of the Longformer model.
- We find the words with the highest attention scores to correlate them with our theory of political polarization.
- We have also designed an interactive website that helps you to understand if polarization exists.
- The website finds the nearest neighbors of the selected politicians from the Longformer output.
- Then depending on the ratio of Republicans to Democrats in the nearest neighbors, we estimate the politician's polarization.
- One such example is shown below-In the graph, the x-axis is the rank of the 20 closest neighbors for the politician you choose given the dataset and the y-axis shows their respective closeness scores. The color blue is for Democrats and red for Republicans. The ratio is Blue vs Red points in this graph, so one of our hypotheses is that if a politician isn't polarized this ratio should be 0.5(democrat/total) if we just look at the background data.
- The above graph in Figure 10 shows the neighbors for Mitch McConnell (Republican) and it is very evident that majority of the neighbors are Republican (red in color) whereas the Democrat count is only 2 out of 20. So one can infer that the polarization ratio is 0.9 for Mitch McConnell. Similarly, in Figure 11, we can see that Ayenna Presley who is a Democrat has 16 neighbors belonging to the same party resulting in a ratio of 0.8 for background data.
- Scaled-up versions of such websites with more metrics that highlight the political views of a member as radical or moderate will be beneficial to the voters.
- Also, we show the worthiness of this data and hope that this will be useful to the research community in examining the idea of political polarization in candidates and how it is linked to other attributes of the candidate.
- Also, to under-stand the views of a candidate and measure how polarizing their views are.

## Future Work
- For future work, we aim to use other metrics for finding the political polarization of individuals and communities again using the Wikipedia dataset.
- Specifically, we want to use the attention tokens mentioned above to look at the ratio of tokens from the background to the political given text from a candidate that is equally distributed across the background and political.
- Figure 1: Webscraping based on each Tag
- Figure 2: Background
- Figure 3: Political
- Figure 4: Nearest neighboring words to the word immigrant in the democratic corpus across time from left to right, as we can see, words like americans were closely associated in the early 20th century.
- Figure 5: Nearest neighboring words to the word immigrant in the republican corpus, the words are similar in the 1st era, the early 20th century, but in the most recent era it is related to other politically sensitive words.
- Figure 6: Nearest neighbors for political data belonging to Mitch McConnell (Republican)
