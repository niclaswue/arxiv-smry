---
title: "Towards Autoformalization of Mathematics and Code Correctness: Experiments with Elementary Proofs"
date: 2023-01-05T17:56:00.000Z
author: "Garett Cunningham, Razvan C. Bunescu, David Juedes"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "https://ik.imagekit.io/smryai/2301-02195v1_7KLuvCalN.jpg" # image path/url
    alt: "Towards Autoformalization of Mathematics and Code Correctness: Experiments with Elementary Proofs" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2301.02195)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2301.02195).


# Abstract
- Mathematical proofs are becoming increasingly complex, making manual verification by mathematicians difficult.
- Autoformalization aims to address this issue by translating proofs written in natural language into a formal representation that is computer-verifiable.
- This paper introduces an approach based on the Universal Transformer architecture to translate elementary mathematical proofs into an equivalent formalization in the language of the Coq interactive theorem prover.
- The same architecture is also used to translate simple imperative code decorated with Hoare triples into formally verifiable proofs of correctness.
- Experiments on a limited domain show the models generalize well to intermediate lengths and variations in natural language.

# Paper Content

## Abstract
- Mathematical proofs are becoming increasingly complex, making manual verification by mathematicians difficult.
- Autoformalization aims to address this issue by translating proofs written in natural language into a formal representation that is computer-verifiable.
- This paper introduces an approach based on the Universal Transformer architecture to translate elementary mathematical proofs into an equivalent formalization in the language of the Coq interactive theorem prover.
- The same architecture is also used to translate simple imperative code decorated with Hoare triples into formally verifiable proofs of correctness.
- Experiments on a limited domain show the models generalize well to intermediate lengths and variations in natural language.

## Introduction
- Mathematical proofs must have formal underpinnings beyond the written argument
- Tymoczko (1979) proposed that proofs must be convincing, surveyable, and formalizable
- Great progress has been made formalizing mathematical results since 1970s
- LaTeX provides a tool for satisfying the first two criteria
- This paper looks at machine learning techniques for converting LaTeX into equivalent, formally verified mathematics
- Prior work has evaluated LSTM-based models, Universal Transformer, and copying mechanisms
- Models are evaluated on their ability to generalize to statement lengths not seen during training

## Dataset of Theorems and Proofs
- Two independent datasets of mathematical statements corresponding to four classes of theorems and proofs created
- Datasets contain: 3 classes of arithmetic statements (EVEN-ODD, COMPOSITES, and POWERS) and statements about code correctness via Hoare logic (POLY)
- Input theorem-proof pairs in LaTeX, formalized output represented in Coq
- Work focuses on proof assistant Coq for (a) rich set of mathematical libraries, (b) successfully used to reason about computation artifacts, (c) rich set of training material for software verification
- Each class of examples demonstrates features necessary for successful autoformalization of mathematical theorems and proofs
- Examples provide stress test of copying mechanism
- Manually created a few examples to guide construction of complex grammar
- Datasets generated using corresponding grammar
- Quasi-synchronously generate LaTeX and Coq versions of mathematical statements, allowing for simple re-orderings
- Grammar-based method theoretically produces over 283 million unique arithmetic examples and over 491,000 unique code examples

### Arithmetic Statements
- Evaluated Transformer model on data combining EVEN-ODD + COMPOSITES + POWERS
- Tuned model with specified parameters
- Trained model over minibatches of size 20, optimized with Adam
- Tested on values n âˆˆ {2, 3, . . . , 12}
- Model generalizes well to intermediate lengths of {4, 6, 8}
- Model fails to generalize to longer unseen lengths
- Switching to semantic-level evaluation leads to significant increase in accuracy for COMPOSITES, more modest increase for EVEN-ODD

### Handwritten Examples
- Evaluated semantic-level accuracy of trained models on 45 human-written theorem-proof pairs
- Fully trained model achieved 53.3%, 73.3% for EVEN-ODD, COMPOSITES and POWERS
- Mistakes mostly due to mishandling of out-of-vocabulary tokens
- Mistakes correlated with examples that deviate from artificial data
- Pre-trained language models or pre-training new models on mathematical corpora may help

### Code Correctness Statements
- We extend scope to include data representing proofs of program correctness using Hoare logic
- We train model with same embedding and state sizes, feed forward width, learning rates, and 8 encoder/decoder blocks, 8 recurrent passes, 8 attention heads, and a clipping value of 8
- Model is trained over minibatches of size 1 with Adam, with a patience of 3 epochs
- POLY results show model is able to generalize to program line counts of {4, 6, 8, 10} unseen during training, with diminishing returns as the program length grows
- Increasing model depth significantly improved generalization
- Non-fatal token swapping errors significantly reduced
- Semantic-level accuracy is identical to sequence-level

## Semantic Parsing Architecture
- Formalized LaTeX statements into Coq using encoder-decoder architecture
- Based on Universal Transformer
- Added recursive passes to encoder and decoder of base Transformer
- Model analogous to Universal Transformer without ACT
- Introduced copying mechanism
- Supported out-of-vocabulary mathematical terms

### Copying Mechanism
- Mathematical language contains features uncommon or non-existent in natural language
- Replacing tokens with generic forms to address general mathematical jargon
- Copying mechanism adapted from Gu et al.
- Different generic token introduced for each unique numerical constant or variable literal
- Encoding distinctions while maintaining coreference in LaTeX and Coq statements
- Using generic tokens for numbers, variables, and definitions
- Limited set of embeddings need to be trained
- Model has ability to generalize to unseen numbers or variable and definition names
- CopyNet uses encoder-decoder architecture with copying mechanism
- Calculating probability of producing a token using simplified formula
- Scoring functions given by onehot encoding and hidden encoder state

### Encoder-Decoder Architecture
- Probabilities are calculated via p(y t )
- Absolute positional encodings removed
- Self-attention uses relative positional representations
- Stacks of N encoder/decoder blocks have T recurrent passes
- Model unchanged from original Transformer
- Emphasis on relative positional information
- Evaluation on EVEN-ODD dataset
- Transformer models with absolute positional encodings had 0% accuracy
- Removing reliance on absolute position resolved accuracy
- Relative positional encodings essential for stronger generalization

## Experimental Evaluations
- Evaluated performance of trained models in two experiments
- Measured accuracy by comparing generated Coq sequences to ground truth
- Reported semantic-level accuracy as well
- Semantic-level accuracy required generated Coq theorem to attain perfect sequence-level accuracy and Coq engine to verify generated Coq proof
- All experiments performed on one NVIDIA RTX-A6000 GPU with 48GB of memory

## Concluding Remarks
- It is feasible to train machine learning models to perform autoformalization over restricted domains
- Models show capability to generalize to new expression lengths and program sizes
- Models were able to translate unseen natural language examples
- Hope approach can be applied to autoformalization of a larger segment of mathematics and code verification
- Autoformalization would represent a breakthrough for general AI
- Significant impact in education, where integration would enable detection of missing steps or misconceptions
