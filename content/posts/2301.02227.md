---
title: "Optimal lower bounds for Quantum Learning via Information Theory"
date: 2023-01-05T18:55:04.000Z
author: "Shima Bab Hadiashar, Ashwin Nayak, Pulkit Sinha"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "https://ik.imagekit.io/smryai/2301-02227v1_6fO8ugDjq.jpg" # image path/url
    alt: "Optimal lower bounds for Quantum Learning via Information Theory" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2301.02227)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2301.02227).


# Abstract
- A concept class may be learnt more efficiently using quantum samples as compared with classical samples in certain scenarios
- However, Arunachalam and de Wolf proved that quantum learners are asymptotically no more efficient than classical ones in the quantum PAC and Agnostic learning models
- They established lower bounds on sample complexity via quantum state identification and Fourier analysis
- In this paper, we derive optimal lower bounds for quantum sample complexity in both the PAC and agnostic models via an information-theoretic approach
- We then turn to a quantum analogue of the Coupon Collector problem, a classic problem from probability theory also of importance in the study of PAC learning
- Arunachalam, Belovs, Childs, Kothari, Rosmanis, and de Wolf characterized the quantum sample complexity of this problem up to constant factors
- First, we show that the information-theoretic approach mentioned above provably does not yield the optimal lower bound
- As a by-product, we get a natural ensemble of pure states in arbitrarily high dimensions which are not easily (simultaneously) distinguishable, while the ensemble has close to maximal Holevo information
- Second, we discover that the information-theoretic approach yields an asymptotically optimal bound for an approximation variant of the problem
- Finally, we derive a sharp lower bound for the Quantum Coupon Collector problem, with the exact leading order term, via the Holevo-Curlander bounds on the distinguishability of an ensemble

# Paper Content

## Introduction
- The number of labelled examples needed to learn a feature is
- The PAC model can be extended to the quantum setting
- The (ǫ, δ)-PAC quantum sample complexity is
- The (ǫ, δ)-agnostic classical sample complexity is
- The lower bound for quantum sample complexity is
- The upper bound for quantum sample complexity is
- The information-theoretic argument given in Ref. [3] results in lower bounds for quantum sample complexity that are smaller by a factor of log(d/ǫ).

## Preliminaries
- The Hamming weight of a string is the number of non-zero symbols in the string.
- The parity signature of a string is the function that assigns a parity to each bit in the string.
- The Fano inequality bounds the conditional entropy of a given quantum state.
- The Chernoff bound states that a given quantum state is concentrated around its expected value.
- A quantum state is pure if it has rank one.

## Quantum Coupon Collection.
- Let n be an integer ≥ 3
- For a positive integer k ∈ (1, n), let S be a k-element subset of [n], and let |ψ S denote the uniform superposition over the elements of S: This is a quantum analogue of a uniformly random sample from S, and we call this a quantum sample of S.
- For ease of notation, we define m := n − k.
- In the Quantum Coupon Collector problem, we are given n, k and quantum samples of an arbitrary but fixed, unknown k-element subset S, and we would like to learn the subset using few samples as possible.
- By "learning the subset", we mean that we would like to determine, with probability at least 1 − δ for some parameter δ ∈ [0, 1), all the k elements of the set S.
- We are interested in the quantum sample complexity of the problem, i.e., the least number of samples required by a quantum algorithm to learn the set with probability of error at most δ.
- We also study a variant of this problem, in which given a parameter ∆ ≥ 0 the goal of the learning algorithm is to approximate the set S to within ∆ in expectation, i.e., output a size-k subset S ′ such that the expected number of mismatches |S \ S ′ | is bounded: E |S \ S ′ | ≤ ∆.
- Note that when ∆ ≤ 1, with probability at least 1 − ∆, such an algorithm outputs the set S. So the condition that the expected number of mismatches is bounded by 1 is a stronger condition than the learnability of the set S.

## Learning Boolean functions
- The lower bound for the sample complexity of learning Boolean functions in the PAC is O(n log n).
- The lower bound for the sample complexity of learning Boolean functions in the agnostic learning model is O(n).

### Sample complexity of PAC learning

### Sample complexity of agnostic learning
- The lower bound for the sample complexity of agnostic quantum learning in Eq. (1.2) has two parts.
- The first part is due to Arunachalam and de Wolf [3] and is VC-independent.
- The second part is due to the agnostic learning criterion and is VC-dependent.
- For every δ ∈ (0, 1/2), ǫ ∈ (0, 1/4), an (ǫ, δ)-agnostic quantum learner for C has quantum sample complexity at least Ω( 1 ǫ 2 log 1 δ ).
- For t = νd/(1 − √ 1 − 16ǫ 2 ), with ν chosen to be a sufficiently small positive constant, I(A : B) ρ violates this inequality.
- Therefore, t ∈ Ω(d/ǫ 2 ).
- For u ∈ [d] t and l ∈ {0, 1} t , denote t j=1 D a (u j , l j ) by D a (u, l).
- We separate the indices and the corresponding bits in register B into subregisters I and L, respectively.
- We then have
- Define σ B to be the state obtained by applying the t-qubit Hadamard transformation to register L in ρ B .
- We have
- We simplify this expression as follows. Consider fixed a, u, v, x, y as in the expression. Define
- We have
- Hence, and
- We may verify that for each b ∈ {0, 1} d , the vector is an eigenvector of σ B with corresponding eigenvalue λ b , where
- The eigenvalue λ b only depends on the Hamming weight |b|. Thus its multiplicity is d h , and we write λ h instead of λ b for any string b with Hamming weight h.
- We may now bound the entropy of ρ B as
- Furthermore, the Hamming weight of the parity signature of a string of length r is at most r, i.e., n r,h = 0 for h > r. Hence, for every r ≤ d 2 , we have .
- Since the binomial distribution B(t, p) is concentrated around its mean pt, by the multiplicative Chernoff bound (Eq. (2.1)) we have
- We take ν < 1/2 so that 3pt/2 = 3νd/4 < d/2.
- To bound the second term in Eq. (3.12), we partition the sum over r into two intervals, r < 3pt/2 and r > 3pt/2.

## Quantum Coupon Collection
- The Quantum Coupon Collector problem has a sample complexity of O(n2).
- The standard version of the problem has a sample complexity of O(n).
- The approximation version of the problem has a sample complexity of O(n log n).

### Technical preparations

### Properties of the spectrum
- The eigenvalues λ s,t always occur in multiples of l s .
- We derive a recurrence for l s λ s,t to analyse the expressions we encounter.
- For convenience, define l −1 := 1 and l m+1 := n m+1 − n m .
- Lemma 4.6 states that l 0 λ 0,0 = 1, and l s λ s,0 = 0 for s ∈ [m].
- For t ≥ 1, for all s ∈ {0} ∪ [m], l s λ s,t = p s,0 l s λ s,t−1 + p s−1,+1 l s−1 λ s−1,t−1 + p s+1,−1 l s+1 λ s+1,t−1 .
- Proof: The values for t = 0 are straightforward to verify. Multiplying the recurrence relation in Lemma 4.5 by l s on both sides, we get
- We may verify by direct calculation that , and .
- As U t ≥ U ′ t , we have and
- We use this property in deriving the bounds in the next three lemmas.
- Proof: We construct a random walk (W ′ t ) on {0} ∪ [m], with W ′ t := 0 and
- We may verify that the right hand side is at most m−s n−5m .
- By Lemma 4.7 the random walk
- We may interpret the random walk W ′ t as follows. Suppose the first m numbers out of [n − 5m] are designated as coupons. In each step, we pick a sample from [n − 5m] uniformly at random, with replacement. Note that the probability of selection of each coupon is 1  n−5m at each step. Then W ′ t is the number of distinct coupons collected (i.e., sampled) in t steps.
- We use linearity of expectation to bound E[W ′ t ].
- Let X s,t be the indicator random variable for the event that coupon s is collected within t steps. Then
- We show below that
- Using these, we get
- We invoke the inequality e −z ≤ (1 + z) −1 for z > −1, with z be such that (1 + z) −1 = 1 − 1/(n − 5m). This gives us Eq. (4.2).
- Eq. (4.3) is equivalent to
- Using 1 ≤ m ≤ n/40, m ln m ≤ |c| n/10, we have
- Further, when c ≥ 0, cn/(n − 5m − 1) ≤ cn/(n − 6m) ≤ 4c/3, and when c < 0, cn/(n − 5m − 1) ≤ c.
- Combining these, we see that Eq. ( 4.3) also holds.

### Sample complexity of Quantum Coupon Collection
- The lower bound on the sample complexity of the Quantum Coupon Collector problem is at least k ln k − k ln ln k.
- For n such that k < n < n 0 , note that both m/n and (m ln m)/n decrease as n decreases. So for such n we have m ≤ δn/2 and m ln m ≤ n/20, and the lower bound given by Theorem 4.18 holds.
- Thus we get the bound claimed in Eq. (4.6) for all n > k.
