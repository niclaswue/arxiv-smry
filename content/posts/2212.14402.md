---
title: "GPT Takes the Bar Exam"
date: 2022-12-29T18:19:43.000Z
author: "Michael Bommarito II, Daniel Martin Katz"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2212-14402v1.webp" # image path/url
    alt: "GPT Takes the Bar Exam" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2212.14402)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2212.14402).


# Abstract
- Nearly all jurisdictions in the United States require a professional license
- To even sit for the exam, most jurisdictions require that an applicant completes at least seven years of post-secondary education, including
- three years at an accredited law school
- In addition, most test-takers also undergo weeks to months of further, exam-specific preparation
- Despite this significant investment of time and capital, approximately one in five test-takers still score under the rate required to pass the exam on their first try
- In the face of a complex task that requires such depth of knowledge, what, then, should we expect of the state of the art in "AI?"
- In this research, we document our experimental evaluation of the performance of OpenAI's `text-davinci-003` model, often-referred to as GPT-3.5, on the multistate multiple choice (MBE) section of the exam
- While we find no benefit in fine-tuning over GPT-3.5's zero-shot performance at the scale of our training data, we do find that hyperparameter optimization and prompt engineering positively impacted GPT-3.5's zero-shot performance
- For best prompt and parameters, GPT-3.5 achieves a headline correct rate of 50.3% on a complete NCBE MBE practice exam, significantly in excess of the 25% baseline guessing rate, and performs at a passing rate for both Evidence and Torts. GPT-3.5's ranking of responses is also highly-correlated with correctness; its top two and top three choices are correct 71% and 88% of the time, respectively, indicating very strong non-entailment performance. While our ability to interpret these results is limited by nascent scientific understanding of LLMs and the proprietary nature of GPT, we believe that these results strongly suggest that an LLM will pass the MBE component of the Bar Exam in the near future.

# Paper Content

## Introduction
- The legal system is becoming increasingly complex, leading to a need for technology to assist with the quantity, quality, and accessibility of legal services demanded by society.
- Artificial intelligence and process engineering have promised help for decades to both non-professional and professional users of legal systems.
- Significant research and development has gone into use cases like search and legal aid for laypeople, automated argumentation or brief construction, pre-and post-execution contract processes, due diligence and e-discovery, and judicial analysis.
- However, the complexity of legal language and vastness of legal knowledge has made it historically difficult to develop systems that understand the nuances of legal tasks, and many systems have failed to deliver desired results or reach adoption.
- As noted in [9], law is a field which is heavily reliant on the use of language, producing massive volumes of textual data.
- Documents such as briefs, memos, statutes, regulations, contracts, patents, and judicial decisions are continuously authored by lawyers, judges, and regulators.
- To make matters even more difficult, legal language is notoriously complex; lawyers and other legal professionals undertake nearly a decade of education and professional training to understand and generate it.
- The answer is likely two-fold. First, for both technical and cultural reasons, the grammar of legal language is significantly different than the grammar of normal language, featuring both highly-stylized customs and pedantically-precise phrasing.
- Second, by the very nature of common law and precedent, legal language is full of semantic nuance and history. Words like "security" that have common meaning in normal language often have different, context-specific meanings in legal language. Many words that do not occur at all in normal language, like "estoppel" or "indemnitor," occur regularly in legal corpora.
- This semantic depth and breadth traditionally required systems that interact with legal text to embed a large amount of domain-specific knowledge.
- Viewed from this perspective, legal education and training is required to teach humans to understand and produce this very particular kind of language, and it is no surprise that traditional models in NLP struggled in general legal task assessments.
- In recent years, however, developments in natural language processing and computing have led to significant advances in state of the art performance.
- Leveraging advances in neural network research [11] [12], sophisticated efforts have been made to build quasi-semantic models.
- The age of neural NLP can be traced to [13], which has been followed by successive waves of embedding [14] [15] and transformer-based large language models (LLMs) [16] [17] [18] [19] [20].
- In particular, transformer architectures, first introduced in [25], have revolutionized machine learning research, and have been most successfully applied to text and image modalities.
- The most famous and accessible of these LLMs is OpenAI's family of Generative Pre-trained Transformer models, commonly referred to as GPT.
- As a proprietary model in production for OpenAI's customers, there is no guarantee that previously-published academic literature is still accurate.
- However, as of July 2020, OpenAI reported that GPT-3 was "an autoregressive language model with 175 billion parameters" featuring 96 layers trained with a batch size of 3.2M.
- While these numbers may be difficult to contextualize, those who have trained their own models can easily appreciate the effort involved.
- Since then, OpenAI has also launched or published a number of derivative models, most notably InstructGPT-3 and Codex 12B.
- Colloquially, these recent models are referred to by many, including OpenAI, as GPT-3.5.
- More specifically, as described on OpenAI's website, "GPT-3.5 series is a series of models that was trained on a blend of text and code from before Q4 2021."

## Data

## Methods
- The text completion API was used to provide prompts to a machine learning model.
- Prompts were tested that varied in terms of what the model was asked to do (e.g. single choice, single choice and explanation, top two choices, top two choices and explanation, top two choices and re-prompt).
- Prompts that improved model performance the most were rank order all choices and rank order top three choices.

### (Hyper)parameters for GPT-3
- Machine learning and computational research are highly sensitive to model parameters or hyperparameters
- In this research, we evaluated how hyperparameters like model "temperature" impacted the performance of the model
- We tested values in {0.0, 0.25, 0.5, 0.75, 1.0} for temperature
- We tested values in {0.75, 1.0} for top p
- We tested values in {1, 2, 4} for best of
- We tested values in {16, 32} for max tokens

### Fine-tuning
- LLMs like GPT-3.5 have received so much interest in part because their zero-shot or few-shot performance is so good.
- OpenAI does make some retraining or "fine-tuning" capabilities available through its API, and these API endpoints do allow for some control of the training process like learning rates or batch sizes.
- We did attempt to fine tune text-davinci-003 by providing it with 200 unseen, simulated MBE bar exam questions with correct and incorrect explanations.
- We provided the training samples both with and without explanatory text from the answer guide.
- In total, we trained six fine-tuned models, altering training prompts, training responses, batch size, learning rate, and prompt weighting.
- However, in all cases, the fine-tuned model significantly underperformed text-davinci-003 itself.

## Results
- GPT outperforms human test-takers on multiple choice exams by a significant margin
- GPT's second and third best answers are highly correlated with correctness
- GPT's performance on trickier questions is also significantly better than human test-takers

## Conclusion and Future Work
- GPT-3.5 outperforms NCBE-Reported Students on Evidence questions
- GPT-3.5 outperforms NCBE-Reported Students on Constitutional Law, Real Property, Contracts, and Criminal Law
