---
title: "Myths and Legends in High-Performance Computing"
date: 2023-01-06T09:32:19.000Z
author: "Satoshi Matsuoka, Jens Domke, Mohamed Wahib, Aleksandr Drozd, Torsten Hoefler"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "/home/niclas/arxiv-smry/arxiv-smry/static/thumbnails/2301-02432v1.webp" # image path/url
    alt: "Myths and Legends in High-Performance Computing" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2301.02432)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2301.02432).


# Abstract
- The high-performance computing community has a collection of myths that reflect the current era of massive change.
- Some of the myths are based on evidence or argumentation, but others are based on folklore.
- The collection of myths is a discussion of possible new directions for research and industry investment.

# Paper Content

## Introduction
- Deep learning is a data-driven model that uses deep neural networks.
- Deep learning models can learn to approximate complex functions used in scientific simulations.
- Deep learning models have been successful in a wide range of applications.

## Conclusions
- Many myths shape the discussions in the HPC community today-in this work, we debate some of those and hope to stir up arguments.
- While we present them in an exaggerated and humorous way, many of those myths form the core of thinking in our community.
- Some may be more divisive than others but it seems that many are hard to answer definitively.
- Maybe some points will settle in the future while others will not. Yet, their sheer importance mandates a serious treatment in order to help guide future directions for academic research but also industry and government investment.
- Figure 1. Classification of Compute Kernels and Supercomputing Architecture
- Figure 2. Historical fp64 power efficiency [inGflop/s  Watt ] extrapolated until 2038 to put Intel's zettaflop/s claims into perspective.
- Figure 3. Examples of "Algorithmic Moore's Law" for different areas in HPC; Fusion energy and combustion simulations data byKeyes (2022) and climate simulation data bySchulthess (2016)
