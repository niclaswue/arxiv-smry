---
title: "Instant Neural Graphics Primitives with a Multiresolution Hash Encoding"
date: 2022-01-16T07:22:47.000Z
author: "Thomas Müller, Alex Evans, Christoph Schied, Alexander Keller"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2201-05989v2.webp" # image path/url
    alt: "Instant Neural Graphics Primitives with a Multiresolution Hash Encoding" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2201.05989)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2201.05989).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/instant-neural-graphics-primitives-with-a).

# Abstract
- Neural graphics primitives can be costly to train and evaluate
- We reduce this cost with a versatile new input encoding that permits the use of a smaller network without sacrificing quality
- This allows for a small neural network to be augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through stochastic gradient descent
- We leverage this parallelism by implementing the whole system using fully-fused CUDA kernels

# Paper Content

## INTRODUCTION
- Computer graphics primitives are fundamentally represented by mathematical functions that parameterize appearance
- Multi-layer perceptrons (MLPs), used as neural graphics primitives, have been shown to match these criteria (to varying degree), for example as representations of shape [Martel et al. 2021;Park et al. 2019] and radiance fields [Liu et al. 2020;Mildenhall et al. 2020;Müller et al. 2020Müller et al. , 2021]
- The important commonality of the these approaches is an encoding that maps neural network inputs to a higher-dimensional space, which is key for extracting high approximation quality from compact models
- Most successful among these encodings are trainable, task-specific data structures [Liu et al. 2020;Takikawa et al. 2021] that take on a large portion of the learning task
- However, such data structures rely on heuristics and structural modifications (such as pruning, splitting, or merging) that may complicate the training process, limit the method to a specific task, or limit performance on GPUs where control flow and pointer chasing is expensive
- We address these concerns with our multiresolution hash encoding, which is adaptive and efficient, independent of the task
- Key to both the task-independent adaptivity and efficiency is a multiresolution hierarchy of hash tables: • Adaptivity: we map a cascade of grids to corresponding fixedsize arrays of feature vectors. At coarse resolutions, there is a 1:1 mapping from grid points to array entries. At fine resolutions, the array is treated as a hash table and indexed using a spatial hash function, where multiple grid points alias each array entry. Such hash collisions cause the colliding training gradients to average, meaning that the largest gradients-those most relevant to the loss function-will dominate. The hash tables thus automatically prioritize the sparse areas with the most important fine scale detail. Unlike prior work, no structural updates to the data structure are needed at any point during training. • Efficiency: our hash table lookups are O (1) and do not require control flow. This maps well to modern GPUs, avoiding execution divergence and serial pointer-chasing inherent in tree traversals. The hash tables for all resolutions may be queried in parallel. We validate our multiresolution hash encoding in four representative tasks (see Figure 1): (1) Gigapixel image: the MLP learns the mapping from 2D coordinates to RGB colors of a high-resolution image. (2) Neural signed distance functions (SDF): the MLP learns the mapping from 3D coordinates to the distance to a surface. (3) Neural radiance caching (NRC): the MLP learns the 5D light field of a given scene from a Monte Carlo path tracer. (4) Neural radiance and density fields (NeRF): the MLP learns the 3D density and 5D light field of a given scene from image observations and corresponding perspective transforms.

## BACKGROUND AND RELATED WORK
- Early examples of encoding the inputs of a machine learning model into a higher-dimensional space include the one-hot encoding and the kernel trick
- Encodings have been used in the attention components of recurrent architectures and transformers
- The five dimensions of this light field are independently encoded using the above formula; this was later extended to randomly oriented parallel wavefronts
- We will refer to this family of encodings as frequency encodings.

## Parametric encodings.
- Parametric encodings blur the line between classical data structures and neural approaches.
- The idea is to arrange additional trainable parameters (beyond weights and biases) in an auxiliary data structure, such as a grid [Chabra et al. 2020;Jiang et al. 2020;Liu et al. 2020;Mehta et al. 2021;Peng et al. 2020a;Sun et al. 2021;Tang et al. 2018;Yu et al. 2021a] or a tree [Takikawa et al. 2021], and to look-up and (optionally) interpolate these parameters depending on the input vector x ∈ R  .
- This arrangement trades a larger memory footprint for a smaller computational cost: whereas for each gradient propagated backwards through the network, every weight in the fully connected MLP network must be updated, for the trainable input encoding parameters ("feature vectors"), only a very small number are affected.
- For example, with a trilinearly interpolated 3D grid of feature vectors, only 8 such grid points need to be updated for each sample back-propagated to the encoding.
- In this way, although the total number of parameters is much higher for a parametric encoding than a fixed input encoding, the number of FLOPs and memory accesses required for the update during training is not increased significantly.
- By reducing the size of the MLP, such parametric models can typically be trained to convergence much faster without sacrificing approximation quality.
- Another parametric approach uses a tree subdivision of the domain R  , wherein a large auxiliary coordinate encoder neural network (ACORN) [Martel et al. 2021] is trained to output dense feature grids in the leaf node around x.
- These dense feature grids, which have on the order of 10 000 entries, are then linearly interpolated, as in Liu et al. [2020].
- This approach tends to yield a larger degree of adaptivity compared with the previous parametric encodings, albeit at greater computational cost which can only be amortized when sufficiently many inputs x fall into each leaf node.
- Sparse parametric encodings. While existing parametric encodings tend to yield much greater accuracy than their non-parametric predecessors, they also come with downsides in efficiency and versatility.
- Dense grids of trainable features consume much more memory than the neural network weights.
- To illustrate the trade-offs and to motivate our method, Figure 2 shows the effect on reconstruction quality of a neural radiance field for several different encodings.
- Without any input encoding at all (a), the network is only able to learn a fairly smooth function of position, resulting in a poor approximation of the light field.
- The frequency encoding (b) allows the same moderately sized network (8 hidden layers, each 256 wide) to represent the scene much more accurately.
- The middle image (c) pairs a smaller network with a dense grid of 128 3 trilinearly interpolated, 16-dimensional feature vectors, for a total of 33.6 million trainable parameters.
- The large number of trainable parameters can be efficiently updated, as each sample only affects 8 grid points.
- However, the dense grid is wasteful in two ways. First, it allocates as many features to areas of empty space as it does to those areas near the surface.
- Second, natural scenes exhibit smoothness, motivating the use of a multi-resolution decomposition [Chibane et al. 2020;Hadadan et al. 2021].
- Figure 2 (d) shows the result of using an encoding in which interpolated features are stored in eight co-located grids with resolutions from 16 3 to 173 3 , each containing 2-dimensional feature vectors.
- These are concatenated to form a 16-dimensional (same as (c)) input...

## MULTIRESOLUTION HASH ENCODING
- neural network with trainable weight parameters and trainable encoding parameters
- each level stores feature vectors at the vertices of a grid, with resolution chosen to be a geometric progression between the coarsest and finest resolutions
- number of trainable encoding parameters is O( ) and bounded by  •  •
- spatial hash function of the form where ⊕ denotes the bit-wise XOR operation and   are unique, large prime numbers
- performance vs. quality trade-off
- memory footprint is linear in  , whereas quality and performance tend to scale sub-linearly
- we analyze the impact of  in Figure 4, where we report test error vs. training time for a wide range of  -values for three neural graphics primitives
- we recommend practitioners to use  to tweak the encoding to their desired performance characteristics
- when training samples collide in this way, their gradients average.

## IMPLEMENTATION
- The multiresolution hash encoding is a fast encoding for multiresolution data.
- The encoding is implemented in CUDA and integrated with the fast MLPs of the tiny-cuda-nn framework.
- The encoding is designed to be cache-friendly and fast to converge.
- The encoding is robust to initialization.
- The encoding is trained jointly using Adam [Kingma and Ba 2014].
- Non-spatial input dimensions can be encoded with established techniques whose cost does not scale superlinearly with dimensionality.

## EXPERIMENTS
- The encoding is versatile and high quality
- The encoding is good for four computer graphics primitives
- The encoding is good for highlighting objects
- The encoding is good for highlighting text
- The encoding is good for highlighting shapes

## Gigapixel Image Approximation
- Learning the 2D to RGB mapping of image coordinates to colors has become a popular benchmark for testing a model's ability to represent high-frequency detail
- Recent breakthroughs in adaptive coordinate networks (ACORN) have shown impressive results when fitting very large images-up to a billion pixels-with high fidelity at even the smallest scales
- We target our multiresolution hash encoding at the same task and converge to high-fidelity images in seconds to minutes
- For comparison, on the Tokyo panorama from Figure 1, ACORN achieves a PSNR of 38.59 dB after 36.9 h of training. With a similar number of parameters ( = 2 24 ), our method achieves the same PSNR after 2.5 minutes of training, peaking at 41.9 dB after 4 min.

## Signed Distance Functions
- Signed distance functions (SDFs) are used in many applications
- DeepSDF uses a large MLP to represent one or more SDFs at a time
- In contrast, when just a single SDF needs to be fit, a spatially learned encoding, such as ours can be employed and the MLP shrunk significantly
- This is the application we investigate in this section
- As baseline, we compare with NGLOD, which achieves state-of-the-art results in both quality and speed by prefixing its small MLP with a lookup from an octree of trainable feature vectors
- Lookups along the hierarchy of this octree act similarly to our multiresolution cascade of grids: they are a collision-free analog to our technique, with a fixed growth factor  = 2
- To allow meaningful comparisons in terms of both performance and quality, we implemented an optimized version of NGLOD in our framework, details of which we describe in Appendix B
- Details pertaining to real-time training of SDFs are described in Appendix C
- In Figure 7, we compare NGLOD with our multiresolution hash encoding at roughly equal parameter count
- We also show a straightforward application of the frequency encoding [Mildenhall et al. 2020] to provide a baseline, details of which are found in Appendix D
- By using a data structure tailored to the reference shape, NGLOD achieves the highest visual reconstruction quality. However, even without such a dedicated data structure, our encoding approaches a similar fidelity to NGLOD in terms of the intersectionover-union metric (IoU2 ) with similar performance and memory cost. Furthermore, the SDF is defined everywhere within the training volume, as opposed to NGLOD, which is only defined within the octree (i.e. close to the surface). This permits the use of certain SDF rendering techniques such as approximate soft shadows from a small number of off-surface distance samples [Evans 2006], as shown in the adjacent figure.
- To emphasize differences between the compared methods, we visualize the SDF using a shading model. The resulting colors are sensitive to even slight changes in the surface normal, which emphasizes small fluctuations in the prediction more strongly than in other graphics primitives where color is predicted directly. This sensitivity reveals undesired microstructure in our hash encoding on the scale of the content that the camera is momentarily observing.

## Neural Radiance Caching
- Neural radiance caching predicts photorealistic pixel colors from feature buffers
- The MLP is run independently for each pixel, so the feature buffers can be treated as per-pixel feature vectors that contain the 3D coordinate x as well as additional features
- We can therefore directly apply our multiresolution hash encoding to x while treating all additional features as auxiliary encoded dimensions  to be concatenated with the encoded position, using the same encoding as Müller et al. [2021]
- Integrated our work into Müller et al.'s implementation of neural radiance caching and therefore refer to their paper for implementation details
- For photorealistic rendering, the neural radiance cache is typically queried only for indirect path contributions, which masks its reconstruction error behind the first reflection. In contrast, we would like to emphasize the neural radiance cache's error, and thus the improvement that can be obtained by using our multiresolution hash encoding, so we directly visualize the neural radiance cache at the first path vertex. Figure 9 shows that-compared to the triangle wave encoding of Müller et al. [2021]-our encoding results in sharper reconstruction while incurring only a mild performance overhead of 0.7 ms that reduces the frame rate from 147 to 133 FPS at a resolution of 1920 × 1080px. Notably, the neural radiance cache is trained online-during rendering-from a path tracer that runs in the background, which means that the 0.7 ms overhead includes both training and runtime costs of our encoding.

## Neural Radiance and Density Fields (NeRF)
- A volumetric shape is represented in terms of a spatial (3D) density function and a spatiodirectional (5D) emission function, which is represented by a similar neural network architecture as Mildenhall et al. [2020].
- The model is trained by backpropagating through a differentiable ray marcher driven by 2D RGB images from known camera poses.
- The density MLP maps the hash encoded position y = enc(x;  ) to 16 output values, the first of which we treat as log-space density.
- The color MLP adds view-dependent color variation.
- Its input is the concatenation of • the 16 output values of the density MLP, and • the view direction projected onto the first 16 coefficients of the spherical harmonics basis (i.e. up to degree 4).
- This is a natural frequency encoding over unit vectors.
- Its output is an RGB color triplet, for which we use either a sigmoid activation when the training data has low dynamic-range (sRGB) or an exponential activation when it has high dynamic range (linear HDR).
- We prefer HDR training data due to the closer resemblance to physical light transport.
- Our results were generated with a 1-hidden-layer density MLP and a 2-hidden-layer color MLP, both 64 neurons wide.
- When marching along rays for both training and rendering, we would like to place samples such that they contribute somewhat uniformly to the image, minimizing wasted computation.
- Thus, we concentrate samples near surfaces by maintaining an occupancy grid that coarsely marks empty vs. nonempty space.
- In large scenes, we additionally cascade the occupancy grid and distribute samples exponentially rather than uniformly along the ray.
- Appendix E describes these procedures in detail.
- At HD resolutions, synthetic and even real-world scenes can be trained in seconds and rendered at 60 FPS, without the need of caching of the MLP outputs [Garbin et al. 2021;Wizadwongsa et al. 2021;Yu et al. 2021b].
- This high performance makes it tractable to add effects such as anti-aliasing, motion blur and depth of field by brute-force tracing of multiple rays per pixel, as shown in Figure 12.

## Mic
- Our NeRF implementation has a peak signal to noise ratio (PSNR) that is competitive with multiresolution hash encoding ("Ours: Hash") with that of NeRF [Mildenhall et al. 2020], mip-NeRF [Barron et al. 2021a], and NSVF [Liu et al. 2020], which all require on the order of hours to train.
- Our PSNR is competitive with NeRF and NSVF after just 15 s of training, and competitive with mip-NeRF after 1 min to 5 min of training.
- On one hand, our method performs best on scenes with high geometric detail, such as Ficus, Drums, Ship and Lego, achieving the best PSNR of all methods.
- On the other hand, mip-NeRF and NSVF outperform our method on scenes with complex, view-dependent reflections, such as Materials; we attribute this to the much smaller MLP that we necessarily employ to obtain our speedup of several orders of magnitude over these competing implementations.
- Next, we analyze the degree to which our speedup originates from our efficient implementation versus from our encoding. To this end, we additionally report PSNR for a nearly identical version of our implementation: we replace the hash encoding by the frequency encoding and enlarge the MLP to approximately match the architecture of Mildenhall et al. [2020] ("Ours: Frequency"); see Appendix D for details.
- This version of our algorithm approaches NeRF's quality after training for just ∼ 5 min, yet is outperformed by our full method after training for a much shorter duration (5 s-15 s), amounting to a 20-60× improvement caused by the hash encoding and smaller MLP.
- For "Ours: Hash", the cost of each training step is roughly constant at ∼6 ms per step. This amounts to 50 k steps after 5 min at which point the model is well converged.
- We decay the learning rate after 20 k steps by a factor of 0.33, which we repeat every further 10 k steps.
- In contrast, the larger MLP used in "Ours: Frequency" requires ∼30 ms per training step, meaning that the PSNR listed after 5 min corresponds to about 10 k steps. It could thus keep improving slightly if trained for extended periods of time, as in the offline NeRF variants that are often trained for several 100 k steps.
- While we isolated the performance and convergence impact of our hash encoding and its small MLP, we believe an additional study is required to quantify the impact of advanced ray marching schemes (such as ours, coarse-fine [Mildenhall et al. 2020], or DONeRF [Neff et al. 2021]) independently from the encoding and network architecture.
- We report additional information in Section E.3 to aid in such an analysis.

## CONCLUSION
- Many graphics problems rely on task specific data structures
- Our multi-resolution hash encoding provides a practical learning-based alternative that automatically focuses on relevant detail, independent of the task
- Its low overhead allows it to be used even in timeconstrained settings like online training and inference
- In the context of neural network input encodings, it is a drop-in replacement, for example speeding up NeRF by several orders of magnitude and matching the performance of concurrent non-neural 3D reconstruction techniques
- Slow computational processes in any setting, from lightmap baking to the training of neural networks, can lead to frustrating workflows due to long iteration times
- We have demonstrated that single-GPU training times measured in seconds are within reach for many graphics applications, allowing neural approaches to be applied where previously they may have been discounted
- One may desire smoother interpolation than the -linear interpolation that our multiresolution hash encoding uses by default
- In this case, the obvious solution would be using a -quadratic or -cubic interpolation, both of which are however very expensive due to requiring the lookup of 3  and 4  instead of 2  vertices, respectively
- As a low-cost alternative, we recommend applying the smoothstep function, to the -linear interpolation weights
- Crucially, the derivative of the smoothstep, vanishes at 0 and at 1, causing the discontinuity in the derivatives of the encoding to vanish by the chain rule
- The encoding thus becomes  1 -smooth
- However, by this trick, we have merely traded discontinuities for zero-points in the individual levels which are not necessarily more desirable
- So, we offset each level by half of its voxel size 1/(2  ), which prevents the zero derivatives from aligning across all levels
- The encoding is thus able to learn smooth, non-zero derivatives for all spatial locations x
- For higher-order smoothness, higher-order smoothstep functions   can be used at small additional cost
- In practice, the computational cost of the 1st order smoothstep function  1 is hidden by memory bottlenecks, making it essentially free
- However, the reconstruction quality tends to decrease as higher-order interpolation is used
- This is why we do not use it by default
- Future research is needed to explain the loss of quality
- We designed our implementation of NGLOD [Takikawa et al. 2021] such that it closely resembles that of our hash encoding, only differing in the underlying data structure; i.e. using the vertices of an octree around ground-truth triangle mesh to store collision-free feature vectors, rather than relying on hash tables
- This results in a notable difference to the original NGLOD: the looked-up feature vectors are concatenated rather than summed, which in our implementation serendipitously resulted in higher reconstruction quality compared to the summation of an equal number of trainable parameters
- The octree implies a fixed growth factor  = 2, which leads to a smaller number of levels than our hash encoding
- To generate the uniform samples on the surface of the mesh, we compute the area of each triangle in a preprocessing step, normalize the areas to represent a probability distribution, and store the corresponding cumulative distribution function (CDF) in an array
- Then, for each sample, we select a triangle proportional to its area by the inversion method-a binary search of a uniform random number over the CDF array-and sample a uniformly random position on that triangle by standard sample warping
- Lastly, for those surface samples that must be perturbed, we add a random 3D vector, each dimension independently...
