---
title: "Dynamics of a data-driven low-dimensional model of turbulent minimal Couette flow"
date: 2023-01-11T18:50:08.000Z
author: "Alec J. Linot, Michael D. Graham"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2301-04638v1.webp" # image path/url
    alt: "Dynamics of a data-driven low-dimensional model of turbulent minimal Couette flow" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2301.04638)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2301.04638).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/dynamics-of-a-data-driven-low-dimensional).

# Abstract
- Because the Navier-Stokes equations are dissipative, the long-time dynamics of a flow in state space are expected to collapse onto a manifold whose dimension may be much lower than the dimension required for a resolved simulation.
- On this manifold, the state of the system can be exactly described in a coordinate system parameterizing the manifold. Describing the system in this low-dimensional coordinate system allows for much faster simulations and analysis.
- We show, for turbulent Couette flow, that this description of the dynamics is possible using a data-driven manifold dynamics modeling method.
- This approach consists of an autoencoder to find a low-dimensional manifold coordinate system and a set of ordinary differential equations defined by a neural network. Specifically, we apply this method to minimal flow unit turbulent plane Couette flow at $\textit{Re}=400$, where a fully resolved solutions requires $\mathcal{O}(10^5)$ degrees of freedom. Using only data from this simulation we build models with fewer than $20$ degrees of freedom that quantitatively capture key characteristics of the flow, including the streak breakdown and regeneration cycle. At short-times, the models track the true trajectory for multiple Lyapunov times, and, at long-times, the models capture the Reynolds stress and the energy balance. For comparison, we show that the models outperform POD-Galerkin models with $\sim$2000 degrees of freedom.
- Finally, we compute unstable periodic orbits from the models. Many of these closely resemble previously computed orbits for the full system; additionally, we find nine orbits that correspond to previously unknown solutions in the full system.

# Paper Content

## Introduction
- The state dimension in chaotic fluid flows may be up to 10 5
- By modeling the dynamics in a manifold coordinate system, simulations could be performed with a drastically lower-dimensional state representation, significantly speeding up computations
- Nonlinear dimension reduction methods like kernel PCA, diffusion maps, local linear embedding, isometric feature mapping, and t-distributed stochastic neighbor embedding can be used to reduce the dimension without sacrificing accuracy
- The autoencoder is a dimension reduction method that uses a neural network to map the input data into a lower-dimensional "latent space" and another NN to map back to the original state space
- Wan et al. (2018) showed that a recurrent NN can be used to improve the nonlinear Galerkin approximation

## Framework
- DManD models are "exact" if all functions are approximated with NNs
- The autoencoder is a NN structure that reduces dimension and the decoder expands dimension
- A "stabilized" neural ODE is used to add a linear damping term to the NN output

## Results

### Description of Plane Couette Flow Data
- DManD is used to model the dynamics of turbulent PCF in a MFU domain
- The HKW cell is used as a model because it is well studied, it isolates the SSP, and a library of ECS exist for this domain
- The dynamics of the flow is modeled by using the discrete symmetries of point reflections about [, , ] = [0, 0, 0] and rotation by  about the -axis
- The pattern dynamics is computed by using the Fourier shift theorem to set the phase to 0 (i.e. move the low-speed streak to the center of the channel)
- The psuedo-spectral Channelflow code is used to generate turbulent PCF trajectories
- The velocity and pressure fields are projected onto Fourier modes in  and  and Chebyshev polynomials of the first kind in . These coefficients are evolved forward in time first using the multistage SMRK2 scheme (Spalart et al. 1991), then, after taking multiple timesteps, using the multistep Adams-Bashforth Backward-Differentiation 3 scheme (Peyret 2002).
- At each timestep, a pressure boundary condition is found such that incompressibility is satisfied at the wall (  / = 0) using the influence matrix method and tau correction developed by Kleiser & Schumann (1980).

### Dimension Reduction and Dynamic Model Construction

### Short-time tracking
- The DManD model captures the qualitative behavior of the SSP
- The DManD model also shows good quantitative agreement with Hamilton et al. (1995)
- The DManD model can track phase dynamics over long periods of time

### Long-time statistics
- Next, we investigate the ability of the DManD model to capture the long-time dynamics of PCF.
- An obvious prerequisite for models to capture long-time dynamics is the long-time stability of the models.
- As mentioned in Sec. 2, the long-time trajectories of standard neural ODEs often become unstable, which led us to use stabilized neural ODEs with an explicit damping term.
- We quantify this observation by counting, of the 16 models trained at each dimension  ℎ , how many become unstable with and without the presence of an explicit damping term.
- From our training data we know where ℎ should lie, so if it falls far outside this range after some time we can classify the model as unstable.
- In all of the unstable cases || h()|| follows the data over some short time range before eventually growing indefinitely.
- In Fig. 8 we show the number of unstable models with and without damping. With damping, all of the models are stable, whereas without damping almost all models become unstable for  ℎ = 5 − 16, and around half become unstable in the other cases.
- Additionally, with longer runs or with different initial conditions, many of the models without damping labelled as stable here also eventually become unstable.
- This lack of stability happens when inaccuracies in the neural ODE model pushes trajectories off the attractor. Once off the attractor, the model is presented with states unlike the training data leading to further growth in this error.
- In Linot & Graham (2022); Linot et al. (2023) we show more results highlighting this behavior.
- So, although some standard neural ODE models do provide reasonable statistics, using these models presents challenges due to this lack of robustness.
- As such, all other results we show use stabilized neural ODEs.
- While Fig. 8 indicates that stabilized neural ODEs predict h in a similar range to that of the data, it does not quantify the accuracy of these predictions.
- In fact, with few dimensions many of these models do not remain chaotic, landing on fixed points or periodic orbits.
- The first metric we use to quantify the long-time performance of the DManD method is the mean-squared POD coefficient amplitudes ( ||  || 2 ).
- We consider this quantity because Gibson reports it for POD-Galerkin in Gibson (2002) at various levels of truncation.
- In Fig. 9 we show how well the DManD model, with  ℎ = 18, captures this quantity, in comparison to the POD-Galerkin model in Gibson (2002).
- The DManD method, with only 18 degrees of freedom, matches the mean-squared amplitudes to high accuracy, far better than all of the POD-Galerkin models.
- It is not until POD-Galerkin keeps 1024 modes that the results become comparable, which corresponds to ∼ 2000 degrees of freedom because most coefficients are complex.
- Additionally, our method requires only data,  whereas the POD Galerkin approach requires both data for computing the POD and knowledge of the equations of motion for projecting the equations onto these modes.

### Finding ECS in the model
- The DManD model quantitatively captures many of the key characteristics of MFU PCF
- Now that we know this, we want to explore using the model to discover ECS
- In particular, we first investigate if known periodic orbits of the DNS exist in the DManD model, and then we use the DManD model to search for new periodic orbits
- Here we note that because our model predicts phase-aligned dynamics, the periodic orbits of the DManD model are either periodic or relative periodic orbits, depending on the phase evolution
- When searching for periodic orbits we seek an initial condition to a trajectory that repeats after some time period
- This is equivalent to finding the zeros of (3.16) where   (ℎ) is the flow map forward  time units from ℎ: i.e.   (ℎ()) = ℎ( + ).
- We compute   (ℎ) from Eq. 2.9.
- Finding zeros to Eq. 3.16 requires that we find both a point ℎ * on the periodic orbit and a period  * such that  (ℎ * ,  * ) = 0.
- One way to find ℎ * and  * is by using the Newton-Raphson method.
- By performing a Taylor series expansion of  we find near the fixed point ℎ * ,  * of  that where  ℎ is the Jacobian of  with respect to ℎ,   is the Jacobian of  with respect to the
- With this constraint, at Newton step (), the system of equations becomes which, in the standard Newton-Raphson method, is used to update the guesses ℎ (+1) = ℎ () +Δℎ ()  and  (+1) =  () + Δ () .
- Typically, a Newton-Krylov method is used to avoid explicitly constructing the Jacobian (Viswanath 2007).
- However, with DManD, computing the Jacobian is simple, fast, and requires little memory because the state representation is dramatically smaller in the DManD model than in the DNS.
- We compute the Jacobian  ℎ  (ℎ, ) directly by using the same automatic differentiation tools used for training the neural ODE.
- Furthermore, if we had chosen to represent the dynamics in discrete, rather than continuous time, computation of general periodic orbits would not be possible, as the period  can take on arbitrary values and a discrete-time representation would limit  to multiples of the time step.
- When finding periodic orbits of the DManD model we used the Scipy "hybr" method, which uses a modification of the Powell hybrid method (Virtanen et al. 2020), and for finding periodic orbits of the DNS we used the Newton GMRES-Hookstep method built into Channelflow (Gibson et al. 2021).
- In the following trials we only consider DManD models with  ℎ = 18.
- For the HKW cell there exists a library of POs made available by Gibson et al. (2008b).
- To investigate if the DManD model finds POs similar to existing solutions, we took states from the known POs, encoded them, and used this as an initial condition in the DManD Newton solver to Table 2: Details on the RPOs and POs found using initial conditions from the DManD model.
- The first 9 solutions are new and the last 3 had previously been found.

## Conclusion
- The DManD method consists of first finding a low-dimensional parameterization of the manifold on which data lies, and then discovering an ODE to evolve this low-dimensional state representation forward in time.
- In both cases we use NNs to approximate these functions from data.
- We find that an extremely low-dimensional parameterization of this manifold can be found using a hybrid autoencoder approach that corrects upon POD coefficients.
- Then, we use stabilized neural ODEs to accurately evolve the low-dimensional state forward in time.
- The DManD model captures the self-sustaining process and accurately tracks trajectories and the temporal autocorrelation over short time horizons.
- For DManD models with  ℎ > 10 we found excellent agreement between the model and the DNS in computing the mean-squared POD coefficient amplitude, the Reynolds stress, and the joint PDF of power input vs. dissipation.
- For comparison, we showed that a POD-Galerkin model requires ∼ 2000 degrees of freedom to get similar performance in matching the mean-squared POD coefficient amplitudes.
- Finally, we used the DManD model at  ℎ = 18 for PO searches. Using a set of existing POs, we successfully landed on nearby POs in the model.
- Finally, we found 9 previously undiscovered RPOs by first finding solutions in the DManD model and then using those as initial guesses to search in the full DNS.
