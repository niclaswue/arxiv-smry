---
title: "FaceDancer: Pose- and Occlusion-Aware High Fidelity Face Swapping"
date: 2022-10-19T11:31:38.000Z
author: "Felix Rosberg, Eren Erdal Aksoy, Fernando Alonso-Fernandez, Cristofer Englund"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2210-10473v2.webp" # image path/url
    alt: "FaceDancer: Pose- and Occlusion-Aware High Fidelity Face Swapping" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2210.10473)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2210.10473).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/facedancer-pose-and-occlusion-aware-high).

# Abstract
- Adaptive Feature Fusion Attention (AFFA) is embedded in the decoder and adaptively learns to fuse attribute features and features conditioned on identity information without requiring any additional facial segmentation process.
- In IFSR, we leverage the intermediate features in an identity encoder to preserve important attributes such as head pose, facial expression, lighting, and occlusion in the target face, while still transferring the identity of the source face with high fidelity.
- The proposed FaceDancer outperforms other state-of-the-art networks in terms of identity transfer, while having significantly better pose preservation than most of the previous methods.

# Paper Content

## Introduction
- Face swapping is a challenging task that aims to shift the identity of a source face into a target face, while preserving the descriptive face attributes such as facial expression, head pose, and lighting.
- There exist two mainstream approaches for face synthesis: source-oriented and target-oriented methods.
- The former approach initially synthesizes a source face with the attributes captured in the target face, which is then followed by blending the source face into the target counterpart. These techniques still have difficulties in handling lighting, occlusion, and complexity.
- The latter approach directly convert the identity of the target face into one in the source face. These methods particularly rely on Generative Adversarial Networks (GAN) using a one-stage optimization setting.
- In this work, we introduce a novel, target-oriented, and single-stage method, named FaceDancer, to deal with challenges, e.g., lighting, occlusion, pose, and semantic structure.
- FaceDancer is simple, fast, and accurate. Our core contribution is twofold: First, we introduce an Adaptive Feature Fusion Attention (AFFA) module, which adaptively learns during training to produce attention masks that can gate features. Inspired by the recent methods [27] and [39], the AFFA module is embedded in the decoder and learns attribute features without requiring any additional facial segmentation process.
- The incoming feature maps in AFFA are features that have been conditioned on the source identity information, but also the skip connection of the unconditioned target information in the encoder.
- The AFFA module, in a nutshell, allows FaceDancer to learn which conditioned features (e.g. identity information) to discard and which unconditioned features (e.g. background information) to keep in the target face.
- Our experiments show that gating from the AFFA module considerably improves the identity transfer.
- Second, we present an Interpreted Feature Similarity Regularization (IFSR) method for boosting the attribute preservation. IFSR regularizes FaceDancer to enhance the preservation of facial expression, head pose, and lighting while still transferring the identity with high fidelity. More specifically, IFSR explores the similarity between intermediate features in the identity encoder by comparing the cosine distance distributions of these features in the target, source, and generated face triplets learned from a pretrained state-of-the-art identity encoder, ArcFace [12] (See Fig. 2).
- We conduct extensive quantitative and qualitative experiments on the FaceForensic++ [34] and AFLW2000-3D [44] datasets and show that the proposed FaceDancer significantly outperforms other state-of-the-art networks in terms of identity transfer, while maintaining significantly better pose preservation than most of the previous methods.
- To address the scalability of our network, we further apply FaceDancer to low resolution images with harsh distortions and qualitatively show that FaceDancer can still improve the pose preservation in contrast to other methods.

## Related Work
- There are two leading approaches for face swapping: source-oriented and target-oriented.
- Source-oriented approaches first transform the source face to match the expression and posture of the target face, and then blend with the target frame.
- One of the earliest approaches is The Digital Emily project [2] which performs face swapping through expensive and time-consuming 3D scanning of a single actor.
- Target-oriented approaches mostly rely on generative models to manipulate features of an encoded target face, together with a semi-supervised loss function or a regularization method to preserve attributes.
- FaceShifter [27] robustly transfers the identity while maintaining attributes by having an attribute encoder-decoder model trained in a semi-supervised fashion.
- FaceShifter also has a secondary stage to improve the occlusion awareness.
- SimSwap [8] has an encoder-decoder model that utilizes the identity information to manipulate the bottleneck features.
- In order to preserve attributes, SimSwap uses a modified version of the feature matching loss from pix2pixHD [38].
- HifiFace [39] uses a combination of GANs and 3DMMs to achieve state-of-the-art identity performance.
- Although HifiFace produces high resolution photo-realistic face swaps, it, however, seems not to improve the pose considerably and performs worse than SimSwap.
- In addition, HifiFace relies on a 3DMM model, which particularly works well with high resolution images only [18], [13].
- Our approach differs from these methods in that ours rely on the identity encoder for simplicity and can handle harsh image distortions such as artifacts that emerge in low resolution images.

## Method
- FaceDancer network architecture
- AFFA module: transfers the identity of the source face to the target face
- IFSR method: calculates the similarity between the target face and the source face
- Loss functions: minimize the difference between the changed face and the source face

### Network Architecture
- FaceDancer involves a generator and a discriminator forming a conditional GAN model coupled with a mapping network and ArcFace
- The generator G relies on an U-Net like encoder-decoder architecture combined with a mapping network M
- FaceDancer also employs ArcFace, a pretrained state-of-the-art identity encoder, to extract and inject identity information from the source image
- The discriminator D used for the adversarial loss is the same as the one in StarGan-v2 and Hi-fiFace

### The Adaptive Feature Fusion Attention (AFFA) Module
- The AFFA module is inspired by previous works such as the Adaptive Attentional Denormalization layer in FaceShifters [27] and the Semantic Facial Fusion module in HifiFaces [39].
- Unlike the former method where a separate attribute encoder-decoder model exists, we here keep everything condensed within the generator.
- In contrast to the latter method, which utilizes segmentation masks for supervision, we here avoid introducing any additional need to compute such segmentation masks for each training sample by letting AFFA adaptively learn attention masks.
- This way, AFFA can implicitly learn to extract relevant descriptive face features.
- Instead of naively concatenating or adding the two feature maps (h and z a ), AFFA first concatenates the feature maps and then passes them through a few learnable layers (Fig. 2).
- Finally, AFFA produces an attention mask m with the same filter number as in h and z a .

### Interpreted Feature Similarity Regularization (IFSR)
- ArcFace identity encoder is used to regularize the FaceDancer training
- To favor the preservation of facial attributes, FaceDancer is regularized by employing intermediate features captured by ArcFace identity encoder
- To investigate which layers of ArcFace are responsible for facial expressions and, thus, contribute more to the attribute preservation, FaceShifter is used to perform a pre-study on a state-ofthe-art face swapping model
- The motivation for the margin is to regularize the generator to match the mean of the distribution

### Loss Functions
- During training, FaceDancer employs various loss functions: Identity loss, reconstruction loss, perceptual loss, adversarial loss regularized with our IFSR method, and gradient penalty for the discriminator.
- The identity loss is used to transfer the source identity as follows: where I is the identity encoder ArcFace and cos(.) denotes the cosine similarity.
- The reconstruction loss is used to make sure that when the target X t and source X s are the same images, the final result X c should be equal to the target image on a pixel-wise level. This reconstruction loss is defined as follows:
- To further strengthen the above behavior and improve the semantic understanding of the image, a perceptual loss is deployed. The motivation is that deep features as a perceptual loss have shown to be robust in many reconstruction tasks [38], [20], [42].
- The perceptual loss is defined as: otherwise. (5) where P (i) denotes the ith feature map output of the VGG16 model [20] pretrained on Imagenet [10] and n is the final index of outputs before the down sample step within the VGG16 model. In our experiments, n is 4. Furthermore, we utilize the cycle consistence loss to motivate the model to keep important attributes and structures within the target image [43], [25], [39], [9].
- The discriminator is regularized with a gradient penalty term L gp [14]. The total loss function for the generator G is a weighted sum of above losses, formulated as: where λ i = 10, λ r = 5, λ p = 0.2, λ c = 1 and λ if sr = 1. The weighting for L gp (λ gp ) is set to 10.

## Results
- FaceDancer is trained on the datasets VGGFace2 and LS3D-W
- All faces are aligned with five point landmarks extracted with Reti-naFace
- The alignment is performed to match the input into ArcFace
- We keep all images in the data sets
- Arc-Face is pretrained on MS1M with a ResNet50 backbone
- We used the Adam optimizer with β 1 = 0, β 2 = 0.99, a learning rate of 0.0001, and exponential learning rate decay of 0.97 every 100K steps
- The target (X t ) and source (X s ) images are randomly augmented with brightness, contrast, and saturation
- Each configuration is trained for 300K steps for the ablation study
- We further train all the best performing configurations in the ablation studies (B, C, D) up to 500K steps to compare with the recent works using a batch size of 10
- Image resolution for all of our models are 256 × 256

### Quantitative Results
- We perform quantitative evaluation of FaceDancer using the FaceForensics++ dataset
- FaceDancer outperforms all the previous works by leading to the highest identity retrieval performance.
- Regarding the pose metric, we have comparable results, i.e., FaceDancer achieves the second-lowest pose error (2.04) after SimSwap.

### Qualitative Results
- Our model FaceDancer behaves similar to SimSwap, but one can easily notice the substantially improved identity transfer in our results.
- FaceShifter performs good identity transfer and is able to transfer relevant attributes such as facial hair while preserving occlusion and the identity face shape.
- FaceShifter, however, struggles with lighting and gaze direction as it heavily relies on the second stage model.
- FaceController exhibits good identity transferability and decent pose error, however, still fails noticeably often with the gaze direction.
- Our approach FaceDancer deals with all these problems better.
- Finally, HifiFace demonstrates promising results regarding all these metrics, particularly when it comes to the facial shape.
- For instance, HifiFace exhibits better face shape preservation of the identity than our model.
- Otherwise, it is not feasible to compare qualitatively with HifiFace since our model FaceDancer quantitatively performs better.
- Furthermore, to address the scalability of our model, we qualitatively analyze the performance of FaceDancer compared to SimSwap on low resolution face images.
- Fig. 4 shows that FaceDancer has enough capacity to capture the semantic structure of the face images even under low resolution cases.
- FaceDancer is able to maintain the pixelation artifacts, while SimSwap either produces a smooth face or completely fails, as depicted in the first row of Fig. 4.
- FaceDancer also works well on videos without any temporal information.

### Ablation Study
- Baseline 1 employs concatenation and addition in order to fuse feature maps from the decoder and skip connection.
- Baseline 2 employs IFSR and achieves state-of-the-art performance on identity.
- Configuration A improves identity performance but does not use IFSR which leads to poor pose error, expression error, and FID.
- Configuration B employs IFSR and improves the expression and pose problem, however, still struggles with the FID.
- Adding two more AFFA modules in lower resolutions in the decoder slightly disrupts the identity performance, but improves the other metrics further.
- Configuration D fuses more features from the target face.
- Configuration E falls short for identity performance and pose error.

### Analysis of the AFFA Module
- In the section, the FaceDancer module is used to swap faces.
- The FaceDancer module is used at the highest resolution of the decoder, 256.
- At this resolution, the attention maps are far away from fusing the feature maps, and this causes color defects.
- To fix this, a simple concatenation operation is used instead of the AFFA module at the highest resolution.

### Analysis of IFSR
- The IFSR method helps to preserve expression and identity in the ArcFace ResNet50 backbone
- The IFSR method is able to separate the c2t and c2s distributions until block 14, after which the EER jumps to more than 50%

## Conclusion
- FaceDancer is a new singlestage face swapping model that quantitatively reaches state-of-the-art.
- FaceDancer has a novel regularization component IFSR which utilizes intermediate features to preserve attributes such as pose, facial expression, and occlusion.
- Furthermore, the AFFA module in FaceDancer drastically improves identity transfer without a significant trade off for visual quality and attribute preservation when coupled with IFSR.
- FaceDancer is limited in two main aspects, transferring face shape and the need of calculating IFSR margins from a pretrained face swap model.
- Future directions for the latter is to figure out how to calculate the margins adaptively online.
- IFSR can potentially be used to compress complex face swap (or even image translation) models.
