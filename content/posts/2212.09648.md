---
title: "NusaCrowd: Open Source Initiative for Indonesian NLP Resources"
date: 2022-12-19T17:28:22.000Z
author: "Samuel Cahyawijaya, Holy Lovenia, Alham Fikri Aji, Genta Indra Winata, Bryan Wilie, Rahmad Mahendra, Christian Wibisono, Ade Romadhony, Karissa Vincentio, Fajri Koto, Jennifer Santoso, David Moeljadi, Cahya Wirawan, Frederikus Hudi, Ivan Halim Parmonangan, Ika Alfina, Muhammad Satrio Wicaksono, Ilham Firdausi Putra, Samsul Rahmadani, Yulianti Oenang, Ali Akbar Septiandri, James Jaya, Kaustubh D. Dhole, Arie Ardiyanti Suryani, Rifki Afina Putri, Dan Su, Keith Stevens, Made Nindyatama Nityasya, Muhammad Farid Adilazuarda, Ryan Ignatius, Ryandito Diandaru, Tiezheng Yu, Vito Ghifari, Wenliang Dai, Yan Xu, Dyah Damapuspita, Cuk Tho, Ichwanul Muslim Karo Karo, Tirana Noor Fatyanosa, Ziwei Ji, Pascale Fung, Graham Neubig, Timothy Baldwin, Sebastian Ruder, Herry Sujaini, Sakriani Sakti, Ayu Purwarianti"
weight: 2
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Important disclaimer: the following content is AI-generated, please make sure to fact check the presented information by reading the full paper."
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: true
ShowRssButtonInSectionTermList: false
UseHugoToc: false
cover:
    image: "thumbnails/2212-09648v2.webp" # image path/url
    alt: "NusaCrowd: Open Source Initiative for Indonesian NLP Resources" # alt text
    caption: "The full paper is available [here](https://arxiv.org/abs/2212.09648)." # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

# Link to paper
The full paper is available [here](https://arxiv.org/abs/2212.09648).

You can also find the paper on PapersWithCode [here](https://paperswithcode.com/paper/nusacrowd-open-source-initiative-for).

# Abstract
- NusaCrowd brings together 137 datasets and 117 standardized data loaders
- datasets have been assessed manually and automatically and their effectiveness has been demonstrated in multiple experiments
- NusaCrowd's data collection enables the creation of the first zero-shot benchmarks for natural language understanding and generation in Indonesian and its local languages
- NusaCrowd brings the creation of the first multilingual automatic speech recognition benchmark in Indonesian and its local languages

# Paper Content

## Introduction
- Indonesia is one of the most linguistically diverse and populous countries, with over 270 million people living across 18,000+ islands.
- Indonesian NLP research is restrained by various factors, such as language diversity, orthographic variation, resource limitation, and other societal challenges.
- Existing NLP research mainly focuses on highresource languages (Wang et al., 2018;Xu et al., 2020;Ruder, 2022), while other languages with limited data-including most languages spoken in Indonesia-are neglected.
- Specifically, many Indonesian NLP resources are scattered, undocumented, and not publicly available.
- These issues cause a severe data scarcity problem, which further hinders NLP research in Indonesian and its local languages from progressing.
- In this work, we introduce NusaCrowd, an open collaborative effort to gather and unify existing resources in Indonesian languages for public use, and pass on a spirit of openness to existing non-public arXiv:2212.09648v2 [cs.CL] 20 Dec 2022 resources.
- This initiative has successfully collected a total of 137 datasheets with 117 standardized data loaders in the NusaCrowd datahub.
- The quality of the datasets is manually assessed by multiple native speakers and experts in NLP.
- Utilizing the datasets collected in NusaCrowd, we introduce the first zero-shot NLU benchmark (NusaNLU), zeroshot NLG benchmark (NusaNLG), and multilingual ASR benchmark (NusaASR) for Indonesian languages.
- We evaluate various Indonesian and multilingual models on the benchmarks. Our contribution can be summarized as follows:
- We introduce the first large-scale Indonesian standardized corpora, covering 100+ datasets and 200+ tasks, spanning across 19 Indonesian languages in text, speech, and image modalities.
- We develop the first Indonesian multilingual zero-shot benchmarks for natural language understanding (NusaNLU) and natural language generation (NusaNLG), which cover 70+ NLU and NLG tasks in 20+ languages.
- We conduct a comprehensive analysis of the datasets collected in terms of multiple factors. Our analysis reflects the quality and diversity of existing NLP datasets in Indonesian and its local languages.
- For speech, our initiative opens up access to a wide variety of Indonesian ASR corpora with a total of 200+ hours covering 10 Indonesian languages. Using these resources, we build NusaASR and develop various Indonesian monolingual and multilingual ASR models.

## Related Work
- The lack of labeled datasets for Indonesian language research impedes the advancement of NLP research in Indonesian languages
- To address this issue, we utilize unlabeled data by building large LMs to allow zero-shot and few-shot transfer learning
- In the recent years, multiple efforts have worked on LMs in Indonesian languages by exploring and developing different LM structures
- Several efforts build encoder-only LM, such as IndoBERT (Wilie et al., 2020;Koto et al., 2020b), SundaBERT (Wongso et al., 2022), and IndoBERT-Tweet (Koto et al., 2021)
- While in other works, a number of generative models have been proposed, such as In-doT5 and IndoGPT, along with the generation tasks benchmark, IndoNLG (Cahyawijaya et al., 2021b)

## NusaCrowd
- NusaCrowd is a crowdsourcing platform that allows users to submit and vote on datasets
- The NusaCrowd dataset curation process is detailed, including a description of the datasets and the voting process
- The dataset submissions and voting process was successful in gathering a large number of datasets
- The dataset submissions and voting process was successful in gathering a diverse set of datasets

### Overview of NusaCrowd
- NusaCrowd is a crowdsourcing initiative to collect, open-source, and standardize access to datasets in Indonesian and its 700+ local languages
- NusaCrowd aims to address the resource limitation problem in Indonesian NLP through three solutions: 1) providing datasheets of curated, ready-for-use corpora; 2) providing an open-access, standardized, and centralized data hub; and 3) promoting public data access for non-public datasets
- Through promoting public data access, NusaCrowd is able to open up access to 13 previously non-public datasets, some of which are multilingual, covering a total of ∼40 task subsets over 12 languages
- To maintain these solutions, the NusaCrowd framework serves as a gateway for retrieving and loading a wide variety of Indonesian NLP datasets

### NusaCrowd Framework

### Dataset Standardization and Curation
- We standardize the tasks from the datasets collected in NusaCrowd into several categories according to a specific schema, which is defined as the common set of attributes required to perform the task.
- We use the schema to cover similar tasks across the datasets collected.
- We define 13 schemas to cover all the tasks and all the modalities from the collected datasets, e.g., text classification, text generation, image captioning, speech recognition, etc.
- For instance, in the single-label text classification schema (TEXT), each example consists of three attributes (id, text, label) where id denotes a unique row identifier of the dataset, text denotes an input text, and label denotes a discriminative target variable.
- We elaborate on the attributes of each schema in Appendix B.
- To assess the quality of the datasets collected in NusaCrowd, we perform a manual curation process for each datasheet submission based on two criteria, i.e., the language correctness and the annotation process of the dataset.
- We provide the assessment result as metadata on each dataset.
- Since many datasets consist of a large number of samples, the language correctness checking is done both automatically and manually for English, Indonesian, Sundanese, and Javanese using language identification libraries, i.e., langid.py (Lui and Baldwin, 2012), FastText LID (Ooms, 2022), and Google CLD3 (Ooms, 2022).
- While for other local languages, since there is no language identification library available for those languages, the curation is done manually through sampling.
- For the annotation process, we manually check the dataset annotation process from a relevant publication and/or other description, and categorize them into five Figure 3: Summary of tasks, schemas, modalities, and languages 3 in NusaCrowd.
- ∼75% of the datasets are textual language data in Indonesian. The remaining covers vision-language and speech data in Indonesian. The textual language data covers 19 Indonesian languages (Indonesian and 18 local languages), the speech data covers 8 languages (Indonesian and 7 local languages), while vision-language data only covers the Indonesian language.
- The statistics of the dataset annotation and the automatic language correctness are shown in Figure 2 and Table 1, respectively.

### Datasets in NusaCrowd
- There are 137 datasheets collected with 117 dataloaders implemented from the NusaCrowd initiative.
- NusaCrowd provides access to 14 previously private datasets covering various tasks and local languages.
- We list all of these previously private datasets in Appendix I.
- NusaCrowd covers 36 task types, including but not limited to: machine translation, summarization, sentiment analysis, part-of-speech (POS) tagging, question answering, etc., which are standardized into 13 different schemas.
- The datasets in NusaCrowd stem from three modalities-image, text, and speech-with the majority of the data coming from the text modality.
- In terms of languages, NusaCrowd covers 19 Indonesian languages, i.e., Indonesian and 18 local languages, in addition to some non-Indonesian languages such as Japanese, English, Spanish, and Russian, which come into the mix as machine translation language pairs.
- The summary of the datasets collected in NusaCrowd is shown in Figure 3.
- We provide the list of language codes with the complete name and the language family in Appendix A.
- We report the comprehensive details of the datasets in NusaCrowd in Appendix L and the comparison of NusaCrowd with other initiatives in Appendix J.

## NusaCrowd Benchmarks
- To showcase the benefit of NusaCrowd, we develop three different benchmarks from subsets of datasets.
- Specifically, we develop benchmarks for Indonesian and its local languages including a zero-shot NLU benchmark (NusaNLU), a zero-shot NLG benchmark (NusaNLG), and a multilingual ASR benchmark (NusaASR).

### NusaNLU
- Existing benchmarks only cover one language, Indonesian
- NusaNLU covers 12 languages across various tasks, including 3 emotion classification tasks (Saputri et al., 2018a;Yulianti et al., 2021;Riccosan et al., 2022), 18 sentiment analysis tasks (Winata et al., 2022;Nurlaila et al., 2017;Hidayatullah et al., 2020;Wongso et al., 2021;Koto et al., 2020b;Purwarianti and Crisdayanti, 2019), one review 4 Language family information is collected from Glottolog (https://glottolog.org/) 5 Tok Pisin is a pidgin language widely used in Papua New Guinea, a neighboring country to Indonesia.
- score regression task6 , one hate speech detection task (Ibrohim and Budi, 2019), one abusive language detection task (Putri et al., 2021), one next tweet prediction task (Koto et al., 2020b), and one natural language inference (NLI) task (Mahendra et al., 2021a) are covered.
- The datasets in NusaNLU are shown in Figure 4.
- For XLM-R, we employ the intermediate-task training on NLI by predicting the entailment relation between the input text and the label (Phang et al., 2020).
- We explore both XLM-R fine-tuned on XNLI (Conneau et al., 2018) and Indonesian IndoNLI (Mahendra et al., 2021a).
- For XGLM and BLOOMZ, we employ zero-shot prompt-based learning with prompts in English and Indonesian.
- For each language and task, we employ three different prompts and take the average score for the evaluation of each task.
- More details about fine-tuning hyperparameters and the prompt used in the NLU experiments are shown in Appendix C.
- We report the per-language taskaveraged performances of NusaASR experiment in Appendix F.
- Based on the experiment results, single-task training on wav2vec 2.0-pt fails to produce a good result due to the limited training data to adapt from unsupervised contrastive pre-training to the ASR task, while the ASR fine-tuned wav2vec 2.0-ft model yields a decent result in most languages, except for Buginese (bug) with 90.09% WER.
- This result suggests a limited transferability between the language characteristics of Indonesian, Sundanese, and Javanese with Buginese, which supports the analysis from NusaX (Winata et al., 2022) regarding the low overlap between Buginese and other studied Indonesian local languages.
- While for monolingual multi-task training, all models only achieve a good performance in the languages that they are trained on. This shows that a large difference between vocabulary and speech features from one language to another exists.
- The best performance is achieved using multilingual multi-task training, which yields ∼20% WER across all languages.

### NusaNLG
- Recent works in Indonesian NLG benchmarks (Cahyawijaya et al., 2021b;Guntara et al., 2020) employ transformer-based models, both decoder-only (e.g., IndoGPT) and encoder-decoder (e.g., IndoBART) architectures.
- To further broaden NLG research in Indonesian and its local languages, we develop an NLG benchmark, NusaNLG, which covers NLG tasks in 12 languages including English, Indonesian, and 10 local languages.
- NusaNLG incorporates a total of 36 sets across various tasks covering 33 machine translation tasks (Guntara et al., 2020;Cahyawijaya et al., 2021b) and 3 summarization tasks (Kurniawan and Louvan, 2018;Koto et al., 2020a) (Figure 6).
- We use SacreBLEU for machine translation and ROUGE-L for summarization.

### NusaASR
- Zero-shot benchmarks for textual language data
- NusaCrowd extends the NLP benchmark in Indonesian languages to speech
- First multilingual ASR benchmark for Indonesian and its local languages
- Pre-trained wav2vec 2.0 models are used in the experiment
- Three training settings are explored: single-task monolingual training, multi-task monolingual training, and joint multi-task multilingual training

## Discussion

### Impact of NusaCrowd
- NusaCrowd establishes access to 137 datasets, which is an order magnitude higher compared to the existing resource pool and benchmarks.
- NusaCrowd covers more local languages and modalities, which can be beneficial for larger explorations in Indonesian and local languages NLP.
- Unlike the existing resource pool and benchmarks, NusaCrowd presents two solutions to the resource limitation issue in Indonesian NLP, i.e., 1) a standardization over datasets, which is useful for a faster research and development life cycle; and 2) an active resource pool which, unlike prior works, has the flexibility and sustainability for adding and releasing new standardized datasets at ease through collaborative efforts.

### Multilinguality for Extremely Low-Resource Languages
- Multilingual LMs are effective for low-resource languages
- Multilingual LMs are more scalable than monolingual or regional LMs
- Multilingual LMs benefit from positive transfer between potentially related languages

### Viability of Large Models for Indonesian
- Larger LMs have been shown to have better performance
- The available unlabelled data in Indonesian and its local languages are still very limited
- Even in multilingual LMs, the data size of Indonesian and its local languages are considered miniscule
- Computational resources are limited for Indonesian research institutions and industries, even among the top Indonesian universities

## Conclusion
- Dataset utilization: We have collected 137 datasets, yet we have only conducted experiments for a part of those (∼40 datasets), while the remaining datasets remain unexplored.
- Experiment: We do not attempt few-shot and fully-supervised learning experiments in NusaCrowd since prior works have explored these approaches on some of the datasets (Wilie et al., 2020;Koto et al., 2020b;Cahyawijaya et al., 2021b;Winata et al., 2022).
- Task diversity: The majority of datasets in NusaCrowd is skewed towards MT, sentiment, abusive text classification, and ASR. Furthermore, most ASR works come from the same author or research group.
- Language diversity: There are 700+ languages in Indonesia. However, we only focus on a small fraction of these local languages. More focus on underrepresented and unseen languages is an interesting future direction.
- Utilization of datasets: There are 137 datasets listed in NusaCrowd, while we show 3 different use cases for utilizing the collected datasets, there is still a huge potential for utilizing datasets in NusaCrowd.
- Schema serves to define and format the attributes of the dataset returned by a data loader. For each data loader, we implement a source schema, which is responsible to present the dataset in a format similar to its original structure, and a nusantara schema, which supports the standardization data structure across similar tasks. We define the nusantara schemas as follows.
- Labels are in string format unless indicated otherwise.
- Image-text (IMTEXT): This schema could be used for image captioning, text-to-image generation, and vision-language pre-training. It consists of (id, text, image_paths, metadata), where id denotes a unique row identifier of the dataset, text denotes an input text, image_paths denotes a list of paths to the input image sources, and metadata denotes relevant details such as visual concepts and labels (if required).
- Speech-text (SPTEXT): This could be used for speech recognition, text-to-speech (TTS) or speech synthesis, and speech-to-text translation. It consists of (id, path, audio, text, speaker_id, metadata), where id denotes a unique row identifier of the dataset, path denotes the file path to an input audio source, audio denotes the audio data loaded from the corresponding path, text denotes an input text, speaker_id denotes a unique identifier of the speaker, metadata denotes relevant details such as the age and gender of the speaker (if required).
- Speech-to-speech (S2S): This could be used for speech-to-speech translation. It consists of (id, path_1, audio_1, text_1, metadata_1, path_2, audio_2, text_2, metadata_2), where id denotes a unique row identifier of the dataset, path_1 and path_2 denote the file path to a respective input audio source, audio_1 and audio_2 denote the audio data loaded from the corresponding path, text_1 and text_2 denote input texts, and metadata_1 and metadata_2 denote relevant details such as the age of the speaker and their gender (if required).
- Unlabeled text (SSP): This schema could be used for language modeling in self-supervised pre-training. It consists of (id, text), where id denotes a unique row identifier of the dataset and text denotes an input text.
